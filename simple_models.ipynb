{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Standard\\miniconda3\\envs\\mobsterh\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom, beta, pareto\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b48f8",
   "metadata": {},
   "source": [
    "### 1D Binomial mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940301bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_lk(probs, DP, weights, K, NV):\n",
    "    lk = torch.ones(K, len(NV)) # matrix with K rows and as many columns as the number of data\n",
    "    if K == 1:\n",
    "        return torch.log(weights) + dist.Binomial(total_count=DP, probs = probs).log_prob(NV) # simply does log(weights) + log(density)\n",
    "    for k in range(K):\n",
    "        lk[k, :] = torch.log(weights[k]) + dist.Binomial(total_count=DP, probs=probs[k]).log_prob(NV) # put on each column of lk a different data; rows are the clusters\n",
    "    return lk\n",
    "\n",
    "def log_sum_exp(args):\n",
    "    c = torch.amax(args, dim=0)\n",
    "    return c + torch.log(torch.sum(torch.exp(args - c), axis=0)) # sum over the rows (different clusters) to so obtain a single likelihood for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6937ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_model(data, K):\n",
    "    NV = data[:,0].int()\n",
    "    DP = data[:,1].int()\n",
    "\n",
    "    # prior for mixing proportions\n",
    "    alpha = torch.ones(K)\n",
    "\n",
    "    # Mixing proportions\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(alpha)) # i weights non vanno dentro al plate perchè l'output deve essere un vettore di elementi non indipendenti (perchè sommano a 1)\n",
    "\n",
    "    # Prior for success probability of each binomial component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        probs = pyro.sample(\"probs\", dist.Beta(1, 1)) # assume Beta prior for the binomial success probabilities\n",
    "        # print(probs)\n",
    "\n",
    "    # Plate for the data\n",
    "    with pyro.plate(\"plate_data\", len(data)):\n",
    "        pyro.factor(\"lik\", log_sum_exp(binomial_lk(probs, DP, weights, K, NV)).sum()) # .sum() sums over the data because we have a log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914eefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_guide(data, K):\n",
    "\n",
    "    # Mixing proportions\n",
    "    # in pyro.param usa .sample() perchè non vuole semplicemente la prior ma vuole dei sample.\n",
    "    weights_param = pyro.param(\"weights_param\", lambda: dist.Dirichlet(torch.ones(K)).sample(), constraint=constraints.simplex)\n",
    "    weights = pyro.sample(\"weights\", dist.Delta(weights_param).to_event(1))\n",
    "\n",
    "    # Probabilities of success with Beta(1,1) prior\n",
    "    probs_param = pyro.param(\"probs_param\", dist.Beta(torch.ones(K), torch.ones(K)).sample(), constraint=constraints.interval(0.,1.))\n",
    "    print(probs_param)\n",
    "    \n",
    "    # Probability of success for each component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        pyro.sample(\"probs\", dist.Delta(probs_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a312245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset with two binomial components\n",
    "# data: [NV, DP]\n",
    "g1 = torch.ones([100, 2]) * 100 # 33% data from binomial 1\n",
    "g2 = torch.ones([200, 2]) * 200 # 66% data from binomial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4eb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1[:,0] = dist.Binomial(total_count=100, probs=torch.tensor([.2])).sample([100]).squeeze(-1)\n",
    "g2[:,0] = dist.Binomial(total_count=200, probs=torch.tensor([.6])).sample([200]).squeeze(-1)\n",
    "d_example = torch.concat((g1,g2))\n",
    "# d_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67773c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3384, 0.1066], grad_fn=<ClampBackward1>)\n",
      "Iteration 0: Loss = 2220544.0\n",
      "tensor([0.3386, 0.1067], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3388, 0.1068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3390, 0.1069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3393, 0.1070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3395, 0.1071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3397, 0.1072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3399, 0.1073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3402, 0.1074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3404, 0.1075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3406, 0.1076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3408, 0.1077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3411, 0.1078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3413, 0.1079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3415, 0.1080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3417, 0.1081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3420, 0.1082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3422, 0.1083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3424, 0.1084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3426, 0.1085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3429, 0.1086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3431, 0.1087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3433, 0.1088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3435, 0.1089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3438, 0.1090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3440, 0.1091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3442, 0.1092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3444, 0.1093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3447, 0.1094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3449, 0.1095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3451, 0.1096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3453, 0.1097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3456, 0.1098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3458, 0.1099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3460, 0.1100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3462, 0.1101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3465, 0.1102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3467, 0.1103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3469, 0.1104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3471, 0.1105], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3474, 0.1106], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3476, 0.1107], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3478, 0.1108], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3480, 0.1109], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3483, 0.1110], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3485, 0.1111], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3487, 0.1112], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3489, 0.1113], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3492, 0.1114], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3494, 0.1115], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3496, 0.1116], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3498, 0.1117], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3501, 0.1118], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3503, 0.1119], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3505, 0.1120], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3507, 0.1121], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3510, 0.1122], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3512, 0.1123], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3514, 0.1124], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3516, 0.1125], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3518, 0.1127], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3521, 0.1128], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3523, 0.1129], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3525, 0.1130], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3527, 0.1131], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3530, 0.1132], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3532, 0.1133], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3534, 0.1134], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3536, 0.1135], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3539, 0.1136], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3541, 0.1137], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3543, 0.1138], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3545, 0.1139], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3548, 0.1141], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3550, 0.1142], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3552, 0.1143], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3554, 0.1144], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3557, 0.1145], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3559, 0.1146], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3561, 0.1147], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3563, 0.1148], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3566, 0.1149], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3568, 0.1150], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3570, 0.1152], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3572, 0.1153], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3575, 0.1154], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3577, 0.1155], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3579, 0.1156], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3581, 0.1157], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3583, 0.1158], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3586, 0.1159], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3588, 0.1161], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3590, 0.1162], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3592, 0.1163], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3595, 0.1164], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3597, 0.1165], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3599, 0.1166], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3601, 0.1167], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3604, 0.1168], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3606, 0.1170], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3608, 0.1171], grad_fn=<ClampBackward1>)\n",
      "Iteration 100: Loss = 1910124.0\n",
      "tensor([0.3610, 0.1172], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3612, 0.1173], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3615, 0.1174], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3617, 0.1175], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3619, 0.1177], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3621, 0.1178], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3624, 0.1179], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3626, 0.1180], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3628, 0.1181], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3630, 0.1182], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3633, 0.1183], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3635, 0.1185], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3637, 0.1186], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3639, 0.1187], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3641, 0.1188], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3644, 0.1189], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3646, 0.1191], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3648, 0.1192], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3650, 0.1193], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3653, 0.1194], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3655, 0.1195], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3657, 0.1196], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3659, 0.1198], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3662, 0.1199], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3664, 0.1200], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3666, 0.1201], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3668, 0.1202], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3670, 0.1204], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3673, 0.1205], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3675, 0.1206], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3677, 0.1207], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3679, 0.1208], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3682, 0.1210], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3684, 0.1211], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3686, 0.1212], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3688, 0.1213], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3690, 0.1214], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3693, 0.1216], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3695, 0.1217], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3697, 0.1218], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3699, 0.1219], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3702, 0.1221], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3704, 0.1222], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3706, 0.1223], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3708, 0.1224], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3710, 0.1225], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3713, 0.1227], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3715, 0.1228], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3717, 0.1229], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3719, 0.1230], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3722, 0.1232], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3724, 0.1233], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3726, 0.1234], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3728, 0.1235], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3730, 0.1237], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3733, 0.1238], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3735, 0.1239], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3737, 0.1240], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3739, 0.1242], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3741, 0.1243], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3744, 0.1244], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3746, 0.1245], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3748, 0.1247], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3750, 0.1248], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3753, 0.1249], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3755, 0.1250], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3757, 0.1252], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3759, 0.1253], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3761, 0.1254], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3764, 0.1255], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3766, 0.1257], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3768, 0.1258], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3770, 0.1259], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3772, 0.1260], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3775, 0.1262], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3777, 0.1263], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3779, 0.1264], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3781, 0.1266], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3783, 0.1267], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3786, 0.1268], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3788, 0.1269], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3790, 0.1271], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3792, 0.1272], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3795, 0.1273], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3797, 0.1275], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3799, 0.1276], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3801, 0.1277], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3803, 0.1278], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3806, 0.1280], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3808, 0.1281], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3810, 0.1282], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3812, 0.1284], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3814, 0.1285], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3817, 0.1286], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3819, 0.1287], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3821, 0.1289], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3823, 0.1290], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3825, 0.1291], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3828, 0.1293], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3830, 0.1294], grad_fn=<ClampBackward1>)\n",
      "Iteration 200: Loss = 1629919.5\n",
      "tensor([0.3832, 0.1295], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3834, 0.1297], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3836, 0.1298], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3839, 0.1299], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3841, 0.1300], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3843, 0.1302], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3845, 0.1303], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3847, 0.1304], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3849, 0.1306], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3852, 0.1307], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3854, 0.1308], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3856, 0.1310], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3858, 0.1311], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3860, 0.1312], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3863, 0.1314], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3865, 0.1315], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3867, 0.1316], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3869, 0.1318], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3871, 0.1319], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3874, 0.1320], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3876, 0.1322], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3878, 0.1323], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3880, 0.1324], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3882, 0.1326], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3885, 0.1327], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3887, 0.1328], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3889, 0.1330], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3891, 0.1331], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3893, 0.1332], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3895, 0.1334], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3898, 0.1335], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3900, 0.1336], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3902, 0.1338], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3904, 0.1339], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3906, 0.1340], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3909, 0.1342], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3911, 0.1343], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3913, 0.1344], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3915, 0.1346], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3917, 0.1347], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3919, 0.1348], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3922, 0.1350], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3924, 0.1351], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3926, 0.1352], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3928, 0.1354], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3930, 0.1355], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3933, 0.1356], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3935, 0.1358], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3937, 0.1359], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3939, 0.1360], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3941, 0.1362], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3943, 0.1363], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3946, 0.1364], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3948, 0.1366], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3950, 0.1367], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3952, 0.1368], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3954, 0.1370], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3956, 0.1371], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3959, 0.1372], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3961, 0.1374], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3963, 0.1375], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3965, 0.1376], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3967, 0.1378], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3969, 0.1379], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3972, 0.1380], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3974, 0.1382], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3976, 0.1383], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3978, 0.1385], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3980, 0.1386], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3982, 0.1387], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3985, 0.1389], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3987, 0.1390], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3989, 0.1391], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3991, 0.1393], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3993, 0.1394], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3995, 0.1395], grad_fn=<ClampBackward1>)\n",
      "tensor([0.3997, 0.1397], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4000, 0.1398], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4002, 0.1399], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4004, 0.1401], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4006, 0.1402], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4008, 0.1404], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4010, 0.1405], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4013, 0.1406], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4015, 0.1408], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4017, 0.1409], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4019, 0.1410], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4021, 0.1412], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4023, 0.1413], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4025, 0.1414], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4028, 0.1416], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4030, 0.1417], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4032, 0.1418], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4034, 0.1420], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4036, 0.1421], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4038, 0.1422], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4040, 0.1424], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4043, 0.1425], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4045, 0.1427], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4047, 0.1428], grad_fn=<ClampBackward1>)\n",
      "Iteration 300: Loss = 1380752.25\n",
      "tensor([0.4049, 0.1429], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4051, 0.1431], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4053, 0.1432], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4055, 0.1433], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4058, 0.1435], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4060, 0.1436], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4062, 0.1437], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4064, 0.1439], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4066, 0.1440], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4068, 0.1441], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4070, 0.1443], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4073, 0.1444], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4075, 0.1446], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4077, 0.1447], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4079, 0.1448], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4081, 0.1450], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4083, 0.1451], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4085, 0.1452], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4087, 0.1454], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4090, 0.1455], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4092, 0.1456], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4094, 0.1458], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4096, 0.1459], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4098, 0.1460], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4100, 0.1462], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4102, 0.1463], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4104, 0.1465], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4107, 0.1466], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4109, 0.1467], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4111, 0.1469], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4113, 0.1470], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4115, 0.1471], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4117, 0.1473], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4119, 0.1474], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4121, 0.1475], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4123, 0.1477], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4126, 0.1478], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4128, 0.1479], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4130, 0.1481], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4132, 0.1482], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4134, 0.1483], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4136, 0.1485], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4138, 0.1486], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4140, 0.1487], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4142, 0.1489], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4145, 0.1490], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4147, 0.1491], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4149, 0.1493], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4151, 0.1494], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4153, 0.1495], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4155, 0.1497], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4157, 0.1498], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4159, 0.1499], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4161, 0.1501], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4163, 0.1502], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4166, 0.1503], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4168, 0.1505], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4170, 0.1506], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4172, 0.1507], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4174, 0.1509], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4176, 0.1510], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4178, 0.1511], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4180, 0.1513], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4182, 0.1514], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4184, 0.1515], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4186, 0.1517], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4189, 0.1518], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4191, 0.1519], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4193, 0.1521], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4195, 0.1522], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4197, 0.1523], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4199, 0.1525], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4201, 0.1526], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4203, 0.1527], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4205, 0.1529], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4207, 0.1530], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4209, 0.1531], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4211, 0.1533], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4214, 0.1534], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4216, 0.1535], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4218, 0.1537], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4220, 0.1538], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4222, 0.1539], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4224, 0.1541], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4226, 0.1542], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4228, 0.1543], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4230, 0.1544], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4232, 0.1546], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4234, 0.1547], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4236, 0.1548], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4238, 0.1550], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4240, 0.1551], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4243, 0.1552], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4245, 0.1554], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4247, 0.1555], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4249, 0.1556], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4251, 0.1557], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4253, 0.1559], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4255, 0.1560], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4257, 0.1561], grad_fn=<ClampBackward1>)\n",
      "Iteration 400: Loss = 1165661.625\n",
      "tensor([0.4259, 0.1563], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4261, 0.1564], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4263, 0.1565], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4265, 0.1567], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4267, 0.1568], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4269, 0.1569], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4271, 0.1570], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4273, 0.1572], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4275, 0.1573], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4277, 0.1574], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4279, 0.1576], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4282, 0.1577], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4284, 0.1578], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4286, 0.1579], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4288, 0.1581], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4290, 0.1582], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4292, 0.1583], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4294, 0.1584], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4296, 0.1586], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4298, 0.1587], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4300, 0.1588], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4302, 0.1590], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4304, 0.1591], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4306, 0.1592], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4308, 0.1593], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4310, 0.1595], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4312, 0.1596], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4314, 0.1597], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4316, 0.1598], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4318, 0.1600], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4320, 0.1601], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4322, 0.1602], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4324, 0.1603], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4326, 0.1605], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4328, 0.1606], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4330, 0.1607], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4332, 0.1608], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4334, 0.1610], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4336, 0.1611], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4338, 0.1612], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4340, 0.1613], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4342, 0.1615], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4344, 0.1616], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4346, 0.1617], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4348, 0.1618], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4350, 0.1620], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4352, 0.1621], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4354, 0.1622], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4356, 0.1623], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4358, 0.1625], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4360, 0.1626], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4362, 0.1627], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4364, 0.1628], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4366, 0.1630], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4368, 0.1631], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4370, 0.1632], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4372, 0.1633], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4374, 0.1634], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4376, 0.1636], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4378, 0.1637], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4380, 0.1638], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4382, 0.1639], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4384, 0.1640], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4386, 0.1642], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4388, 0.1643], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4390, 0.1644], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4392, 0.1645], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4394, 0.1647], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4396, 0.1648], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4398, 0.1649], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4400, 0.1650], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4402, 0.1651], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4404, 0.1653], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4406, 0.1654], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4408, 0.1655], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4410, 0.1656], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4412, 0.1657], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4414, 0.1659], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4416, 0.1660], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4418, 0.1661], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4420, 0.1662], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4422, 0.1663], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4424, 0.1665], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4426, 0.1666], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4428, 0.1667], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4430, 0.1668], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4432, 0.1669], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4434, 0.1670], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4436, 0.1672], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4438, 0.1673], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4440, 0.1674], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4442, 0.1675], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4444, 0.1676], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4446, 0.1677], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4448, 0.1679], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4449, 0.1680], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4451, 0.1681], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4453, 0.1682], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4455, 0.1683], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4457, 0.1684], grad_fn=<ClampBackward1>)\n",
      "Iteration 500: Loss = 985849.6875\n",
      "tensor([0.4459, 0.1686], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4461, 0.1687], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4463, 0.1688], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4465, 0.1689], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4467, 0.1690], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4469, 0.1691], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4471, 0.1693], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4473, 0.1694], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4475, 0.1695], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4477, 0.1696], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4479, 0.1697], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4481, 0.1698], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4483, 0.1699], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4484, 0.1701], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4486, 0.1702], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4488, 0.1703], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4490, 0.1704], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4492, 0.1705], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4494, 0.1706], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4496, 0.1707], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4498, 0.1709], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4500, 0.1710], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4502, 0.1711], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4504, 0.1712], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4506, 0.1713], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4508, 0.1714], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4509, 0.1715], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4511, 0.1716], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4513, 0.1718], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4515, 0.1719], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4517, 0.1720], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4519, 0.1721], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4521, 0.1722], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4523, 0.1723], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4525, 0.1724], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4527, 0.1725], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4529, 0.1726], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4531, 0.1727], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4532, 0.1729], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4534, 0.1730], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4536, 0.1731], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4538, 0.1732], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4540, 0.1733], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4542, 0.1734], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4544, 0.1735], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4546, 0.1736], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4548, 0.1737], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4550, 0.1738], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4551, 0.1739], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4553, 0.1741], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4555, 0.1742], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4557, 0.1743], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4559, 0.1744], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4561, 0.1745], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4563, 0.1746], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4565, 0.1747], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4567, 0.1748], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4568, 0.1749], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4570, 0.1750], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4572, 0.1751], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4574, 0.1752], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4576, 0.1753], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4578, 0.1754], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4580, 0.1756], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4582, 0.1757], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4583, 0.1758], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4585, 0.1759], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4587, 0.1760], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4589, 0.1761], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4591, 0.1762], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4593, 0.1763], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4595, 0.1764], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4596, 0.1765], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4598, 0.1766], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4600, 0.1767], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4602, 0.1768], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4604, 0.1769], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4606, 0.1770], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4608, 0.1771], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4609, 0.1772], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4611, 0.1773], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4613, 0.1774], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4615, 0.1775], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4617, 0.1776], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4619, 0.1777], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4621, 0.1778], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4622, 0.1779], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4624, 0.1780], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4626, 0.1781], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4628, 0.1782], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4630, 0.1783], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4632, 0.1784], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4633, 0.1785], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4635, 0.1786], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4637, 0.1787], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4639, 0.1788], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4641, 0.1789], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4643, 0.1790], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4644, 0.1791], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4646, 0.1792], grad_fn=<ClampBackward1>)\n",
      "Iteration 600: Loss = 838598.5\n",
      "tensor([0.4648, 0.1793], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4650, 0.1794], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4652, 0.1795], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4654, 0.1796], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4655, 0.1797], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4657, 0.1798], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4659, 0.1799], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4661, 0.1800], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4663, 0.1801], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4665, 0.1802], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4666, 0.1803], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4668, 0.1804], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4670, 0.1805], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4672, 0.1806], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4674, 0.1807], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4675, 0.1808], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4677, 0.1809], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4679, 0.1810], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4681, 0.1811], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4683, 0.1812], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4684, 0.1813], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4686, 0.1814], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4688, 0.1815], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4690, 0.1816], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4692, 0.1817], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4693, 0.1818], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4695, 0.1819], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4697, 0.1820], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4699, 0.1820], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4701, 0.1821], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4702, 0.1822], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4704, 0.1823], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4706, 0.1824], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4708, 0.1825], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4710, 0.1826], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4711, 0.1827], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4713, 0.1828], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4715, 0.1829], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4717, 0.1830], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4718, 0.1831], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4720, 0.1832], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4722, 0.1833], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4724, 0.1833], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4726, 0.1834], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4727, 0.1835], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4729, 0.1836], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4731, 0.1837], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4733, 0.1838], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4734, 0.1839], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4736, 0.1840], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4738, 0.1841], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4740, 0.1842], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4741, 0.1842], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4743, 0.1843], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4745, 0.1844], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4747, 0.1845], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4749, 0.1846], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4750, 0.1847], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4752, 0.1848], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4754, 0.1849], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4756, 0.1850], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4757, 0.1850], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4759, 0.1851], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4761, 0.1852], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4763, 0.1853], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4764, 0.1854], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4766, 0.1855], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4768, 0.1856], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4769, 0.1856], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4771, 0.1857], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4773, 0.1858], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4775, 0.1859], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4776, 0.1860], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4778, 0.1861], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4780, 0.1862], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4782, 0.1862], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4783, 0.1863], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4785, 0.1864], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4787, 0.1865], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4789, 0.1866], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4790, 0.1867], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4792, 0.1867], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4794, 0.1868], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4795, 0.1869], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4797, 0.1870], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4799, 0.1871], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4801, 0.1872], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4802, 0.1872], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4804, 0.1873], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4806, 0.1874], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4807, 0.1875], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4809, 0.1876], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4811, 0.1877], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4813, 0.1877], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4814, 0.1878], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4816, 0.1879], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4818, 0.1880], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4819, 0.1881], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4821, 0.1881], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4823, 0.1882], grad_fn=<ClampBackward1>)\n",
      "Iteration 700: Loss = 720017.5\n",
      "tensor([0.4825, 0.1883], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4826, 0.1884], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4828, 0.1885], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4830, 0.1885], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4831, 0.1886], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4833, 0.1887], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4835, 0.1888], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4836, 0.1889], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4838, 0.1889], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4840, 0.1890], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4841, 0.1891], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4843, 0.1892], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4845, 0.1892], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4846, 0.1893], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4848, 0.1894], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4850, 0.1895], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4852, 0.1896], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4853, 0.1896], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4855, 0.1897], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4857, 0.1898], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4858, 0.1899], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4860, 0.1899], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4862, 0.1900], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4863, 0.1901], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4865, 0.1902], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4867, 0.1902], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4868, 0.1903], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4870, 0.1904], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4872, 0.1905], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4873, 0.1905], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4875, 0.1906], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4877, 0.1907], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4878, 0.1908], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4880, 0.1908], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4881, 0.1909], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4883, 0.1910], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4885, 0.1910], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4886, 0.1911], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4888, 0.1912], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4890, 0.1913], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4891, 0.1913], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4893, 0.1914], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4895, 0.1915], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4896, 0.1916], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4898, 0.1916], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4900, 0.1917], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4901, 0.1918], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4903, 0.1918], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4904, 0.1919], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4906, 0.1920], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4908, 0.1920], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4909, 0.1921], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4911, 0.1922], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4913, 0.1923], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4914, 0.1923], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4916, 0.1924], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4918, 0.1925], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4919, 0.1925], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4921, 0.1926], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4922, 0.1927], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4924, 0.1927], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4926, 0.1928], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4927, 0.1929], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4929, 0.1929], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4930, 0.1930], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4932, 0.1931], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4934, 0.1931], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4935, 0.1932], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4937, 0.1933], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4938, 0.1933], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4940, 0.1934], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4942, 0.1935], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4943, 0.1935], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4945, 0.1936], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4946, 0.1937], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4948, 0.1937], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4950, 0.1938], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4951, 0.1939], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4953, 0.1939], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4954, 0.1940], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4956, 0.1941], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4958, 0.1941], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4959, 0.1942], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4961, 0.1943], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4962, 0.1943], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4964, 0.1944], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4966, 0.1945], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4967, 0.1945], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4969, 0.1946], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4970, 0.1946], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4972, 0.1947], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4973, 0.1948], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4975, 0.1948], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4977, 0.1949], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4978, 0.1950], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4980, 0.1950], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4981, 0.1951], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4983, 0.1951], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4984, 0.1952], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4986, 0.1953], grad_fn=<ClampBackward1>)\n",
      "Iteration 800: Loss = 625878.9375\n",
      "tensor([0.4988, 0.1953], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4989, 0.1954], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4991, 0.1954], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4992, 0.1955], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4994, 0.1956], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4995, 0.1956], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4997, 0.1957], grad_fn=<ClampBackward1>)\n",
      "tensor([0.4998, 0.1957], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5000, 0.1958], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5002, 0.1959], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5003, 0.1959], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5005, 0.1960], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5006, 0.1960], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5008, 0.1961], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5009, 0.1962], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5011, 0.1962], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5012, 0.1963], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5014, 0.1963], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5016, 0.1964], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5017, 0.1964], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5019, 0.1965], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5020, 0.1966], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5022, 0.1966], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5023, 0.1967], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5025, 0.1967], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5026, 0.1968], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5028, 0.1968], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5029, 0.1969], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5031, 0.1970], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5032, 0.1970], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5034, 0.1971], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5035, 0.1971], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5037, 0.1972], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5038, 0.1972], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5040, 0.1973], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5041, 0.1973], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5043, 0.1974], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5044, 0.1975], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5046, 0.1975], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5048, 0.1976], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5049, 0.1976], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5051, 0.1977], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5052, 0.1977], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5054, 0.1978], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5055, 0.1978], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5057, 0.1979], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5058, 0.1979], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5060, 0.1980], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5061, 0.1980], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5063, 0.1981], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5064, 0.1981], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5066, 0.1982], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5067, 0.1983], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5069, 0.1983], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5070, 0.1984], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5071, 0.1984], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5073, 0.1985], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5074, 0.1985], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5076, 0.1986], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5077, 0.1986], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5079, 0.1987], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5080, 0.1987], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5082, 0.1988], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5083, 0.1988], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5085, 0.1989], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5086, 0.1989], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5088, 0.1990], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5089, 0.1990], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5091, 0.1991], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5092, 0.1991], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5094, 0.1992], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5095, 0.1992], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5097, 0.1993], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5098, 0.1993], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5100, 0.1994], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5101, 0.1994], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5102, 0.1994], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5104, 0.1995], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5105, 0.1995], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5107, 0.1996], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5108, 0.1996], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5110, 0.1997], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5111, 0.1997], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5113, 0.1998], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5114, 0.1998], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5115, 0.1999], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5117, 0.1999], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5118, 0.2000], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5120, 0.2000], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5121, 0.2001], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5123, 0.2001], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5124, 0.2001], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5126, 0.2002], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5127, 0.2002], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5128, 0.2003], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5130, 0.2003], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5131, 0.2004], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5133, 0.2004], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5134, 0.2005], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5136, 0.2005], grad_fn=<ClampBackward1>)\n",
      "Iteration 900: Loss = 552035.125\n",
      "tensor([0.5137, 0.2006], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5138, 0.2006], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5140, 0.2006], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5141, 0.2007], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5143, 0.2007], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5144, 0.2008], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5146, 0.2008], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5147, 0.2009], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5148, 0.2009], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5150, 0.2009], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5151, 0.2010], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5153, 0.2010], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5154, 0.2011], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5155, 0.2011], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5157, 0.2012], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5158, 0.2012], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5160, 0.2012], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5161, 0.2013], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5162, 0.2013], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5164, 0.2014], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5165, 0.2014], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5167, 0.2014], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5168, 0.2015], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5169, 0.2015], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5171, 0.2016], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5172, 0.2016], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5174, 0.2016], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5175, 0.2017], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5176, 0.2017], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5178, 0.2018], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5179, 0.2018], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5181, 0.2018], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5182, 0.2019], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5183, 0.2019], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5185, 0.2020], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5186, 0.2020], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5187, 0.2020], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5189, 0.2021], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5190, 0.2021], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5192, 0.2022], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5193, 0.2022], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5194, 0.2022], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5196, 0.2023], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5197, 0.2023], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5198, 0.2023], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5200, 0.2024], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5201, 0.2024], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5203, 0.2025], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5204, 0.2025], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5205, 0.2025], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5207, 0.2026], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5208, 0.2026], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5209, 0.2026], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5211, 0.2027], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5212, 0.2027], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5213, 0.2028], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5215, 0.2028], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5216, 0.2028], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5217, 0.2029], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5219, 0.2029], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5220, 0.2029], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5221, 0.2030], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5223, 0.2030], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5224, 0.2030], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5225, 0.2031], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5227, 0.2031], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5228, 0.2031], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5229, 0.2032], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5231, 0.2032], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5232, 0.2032], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5233, 0.2033], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5235, 0.2033], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5236, 0.2033], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5237, 0.2034], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5239, 0.2034], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5240, 0.2034], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5241, 0.2035], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5243, 0.2035], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5244, 0.2035], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5245, 0.2036], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5247, 0.2036], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5248, 0.2036], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5249, 0.2037], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5251, 0.2037], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5252, 0.2037], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5253, 0.2038], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5255, 0.2038], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5256, 0.2038], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5257, 0.2039], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5259, 0.2039], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5260, 0.2039], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5261, 0.2040], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5262, 0.2040], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5264, 0.2040], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5265, 0.2041], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5266, 0.2041], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5268, 0.2041], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5269, 0.2042], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5270, 0.2042], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5271, 0.2042], grad_fn=<ClampBackward1>)\n",
      "Iteration 1000: Loss = 494832.375\n",
      "tensor([0.5273, 0.2042], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5274, 0.2043], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5275, 0.2043], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5277, 0.2043], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5278, 0.2044], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5279, 0.2044], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5280, 0.2044], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5282, 0.2045], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5283, 0.2045], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5284, 0.2045], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5286, 0.2045], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5287, 0.2046], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5288, 0.2046], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5289, 0.2046], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5291, 0.2047], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5292, 0.2047], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5293, 0.2047], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5294, 0.2047], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5296, 0.2048], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5297, 0.2048], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5298, 0.2048], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5300, 0.2049], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5301, 0.2049], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5302, 0.2049], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5303, 0.2049], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5305, 0.2050], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5306, 0.2050], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5307, 0.2050], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5308, 0.2050], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5310, 0.2051], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5311, 0.2051], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5312, 0.2051], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5313, 0.2052], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5315, 0.2052], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5316, 0.2052], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5317, 0.2052], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5318, 0.2053], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5320, 0.2053], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5321, 0.2053], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5322, 0.2053], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5323, 0.2054], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5324, 0.2054], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5326, 0.2054], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5327, 0.2054], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5328, 0.2055], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5329, 0.2055], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5331, 0.2055], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5332, 0.2055], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5333, 0.2056], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5334, 0.2056], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5336, 0.2056], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5337, 0.2056], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5338, 0.2057], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5339, 0.2057], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5340, 0.2057], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5342, 0.2057], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5343, 0.2058], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5344, 0.2058], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5345, 0.2058], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5346, 0.2058], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5348, 0.2059], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5349, 0.2059], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5350, 0.2059], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5351, 0.2059], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5352, 0.2060], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5354, 0.2060], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5355, 0.2060], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5356, 0.2060], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5357, 0.2060], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5358, 0.2061], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5360, 0.2061], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5361, 0.2061], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5362, 0.2061], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5363, 0.2062], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5364, 0.2062], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5366, 0.2062], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5367, 0.2062], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5368, 0.2062], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5369, 0.2063], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5370, 0.2063], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5372, 0.2063], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5373, 0.2063], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5374, 0.2064], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5375, 0.2064], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5376, 0.2064], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5377, 0.2064], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5379, 0.2064], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5380, 0.2065], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5381, 0.2065], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5382, 0.2065], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5383, 0.2065], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5384, 0.2065], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5386, 0.2066], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5387, 0.2066], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5388, 0.2066], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5389, 0.2066], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5390, 0.2066], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5391, 0.2067], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5393, 0.2067], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5394, 0.2067], grad_fn=<ClampBackward1>)\n",
      "Iteration 1100: Loss = 451140.3125\n",
      "tensor([0.5395, 0.2067], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5396, 0.2067], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5397, 0.2068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5398, 0.2068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5400, 0.2068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5401, 0.2068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5402, 0.2068], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5403, 0.2069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5404, 0.2069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5405, 0.2069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5406, 0.2069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5408, 0.2069], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5409, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5410, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5411, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5412, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5413, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5414, 0.2070], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5415, 0.2071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5417, 0.2071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5418, 0.2071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5419, 0.2071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5420, 0.2071], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5421, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5422, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5423, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5424, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5426, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5427, 0.2072], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5428, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5429, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5430, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5431, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5432, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5433, 0.2073], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5435, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5436, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5437, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5438, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5439, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5440, 0.2074], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5441, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5442, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5443, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5444, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5446, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5447, 0.2075], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5448, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5449, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5450, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5451, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5452, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5453, 0.2076], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5454, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5455, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5456, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5457, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5459, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5460, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5461, 0.2077], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5462, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5463, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5464, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5465, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5466, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5467, 0.2078], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5468, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5469, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5470, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5471, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5473, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5474, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5475, 0.2079], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5476, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5477, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5478, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5479, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5480, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5481, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5482, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5483, 0.2080], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5484, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5485, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5486, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5487, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5488, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5489, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5490, 0.2081], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5491, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5492, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5493, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5495, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5496, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5497, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5498, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5499, 0.2082], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5500, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5501, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5502, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5503, 0.2083], grad_fn=<ClampBackward1>)\n",
      "Iteration 1200: Loss = 418299.0625\n",
      "tensor([0.5504, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5505, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5506, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5507, 0.2083], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5508, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5509, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5510, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5511, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5512, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5513, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5514, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5515, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5516, 0.2084], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5517, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5518, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5519, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5520, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5521, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5522, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5523, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5524, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5525, 0.2085], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5526, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5527, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5528, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5529, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5530, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5531, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5532, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5533, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5534, 0.2086], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5535, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5536, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5537, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5538, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5539, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5540, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5541, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5542, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5543, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5544, 0.2087], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5545, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5546, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5547, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5548, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5549, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5550, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5551, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5551, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5552, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5553, 0.2088], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5554, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5555, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5556, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5557, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5558, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5559, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5560, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5561, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5562, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5563, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5564, 0.2089], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5565, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5566, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5567, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5568, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5569, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5570, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5571, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5571, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5572, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5573, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5574, 0.2090], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5575, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5576, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5577, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5578, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5579, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5580, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5581, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5582, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5583, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5584, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5584, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5585, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5586, 0.2091], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5587, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5588, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5589, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5590, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5591, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5592, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5593, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5594, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5594, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5595, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5596, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5597, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5598, 0.2092], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5599, 0.2093], grad_fn=<ClampBackward1>)\n",
      "Iteration 1300: Loss = 394057.21875\n",
      "tensor([0.5600, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5601, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5602, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5603, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5603, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5604, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5605, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5606, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5607, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5608, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5609, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5610, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5611, 0.2093], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5611, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5612, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5613, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5614, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5615, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5616, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5617, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5618, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5619, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5619, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5620, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5621, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5622, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5623, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5624, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5625, 0.2094], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5625, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5626, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5627, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5628, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5629, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5630, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5631, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5631, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5632, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5633, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5634, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5635, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5636, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5637, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5637, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5638, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5639, 0.2095], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5640, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5641, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5642, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5643, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5643, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5644, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5645, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5646, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5647, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5648, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5648, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5649, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5650, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5651, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5652, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5652, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5653, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5654, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5655, 0.2096], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5656, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5657, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5657, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5658, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5659, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5660, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5661, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5662, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5662, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5663, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5664, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5665, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5666, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5666, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5667, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5668, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5669, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5670, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5670, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5671, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5672, 0.2097], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5673, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5674, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5674, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5675, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5676, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5677, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5678, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5678, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5679, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5680, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5681, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5681, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5682, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5683, 0.2098], grad_fn=<ClampBackward1>)\n",
      "Iteration 1400: Loss = 376515.3125\n",
      "tensor([0.5684, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5685, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5685, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5686, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5687, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5688, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5688, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5689, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5690, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5691, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5692, 0.2098], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5692, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5693, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5694, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5695, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5695, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5696, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5697, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5698, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5698, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5699, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5700, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5701, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5701, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5702, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5703, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5704, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5704, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5705, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5706, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5707, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5707, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5708, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5709, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5710, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5710, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5711, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5712, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5713, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5713, 0.2099], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5714, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5715, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5716, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5716, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5717, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5718, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5719, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5719, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5720, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5721, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5721, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5722, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5723, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5724, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5724, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5725, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5726, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5726, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5727, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5728, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5729, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5729, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5730, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5731, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5731, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5732, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5733, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5734, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5734, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5735, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5736, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5736, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5737, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5738, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5739, 0.2100], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5739, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5740, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5741, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5741, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5742, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5743, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5743, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5744, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5745, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5745, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5746, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5747, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5748, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5748, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5749, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5750, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5750, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5751, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5752, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5752, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5753, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5754, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5754, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5755, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5756, 0.2101], grad_fn=<ClampBackward1>)\n",
      "Iteration 1500: Loss = 364096.84375\n",
      "tensor([0.5756, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5757, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5758, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5758, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5759, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5760, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5760, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5761, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5762, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5762, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5763, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5764, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5764, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5765, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5766, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5766, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5767, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5768, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5768, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5769, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5770, 0.2101], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5770, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5771, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5771, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5772, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5773, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5773, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5774, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5775, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5775, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5776, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5777, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5777, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5778, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5779, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5779, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5780, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5780, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5781, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5782, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5782, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5783, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5784, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5784, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5785, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5785, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5786, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5787, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5787, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5788, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5789, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5789, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5790, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5790, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5791, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5792, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5792, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5793, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5793, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5794, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5795, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5795, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5796, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5796, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5797, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5798, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5798, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5799, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5799, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5800, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5801, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5801, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5802, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5802, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5803, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5804, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5804, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5805, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5805, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5806, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5807, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5807, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5808, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5808, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5809, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5810, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5810, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5811, 0.2102], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5811, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5812, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5812, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5813, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5814, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5814, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5815, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5815, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5816, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5816, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5817, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5818, 0.2103], grad_fn=<ClampBackward1>)\n",
      "Iteration 1600: Loss = 355508.15625\n",
      "tensor([0.5818, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5819, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5819, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5820, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5820, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5821, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5822, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5822, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5823, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5823, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5824, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5824, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5825, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5826, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5826, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5827, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5827, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5828, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5828, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5829, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5829, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5830, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5830, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5831, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5832, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5832, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5833, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5833, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5834, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5834, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5835, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5835, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5836, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5836, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5837, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5838, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5838, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5839, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5839, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5840, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5840, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5841, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5841, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5842, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5842, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5843, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5843, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5844, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5844, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5845, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5845, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5846, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5846, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5847, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5848, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5848, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5849, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5849, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5850, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5850, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5851, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5851, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5852, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5852, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5853, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5853, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5854, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5854, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5855, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5855, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5856, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5856, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5857, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5857, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5858, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5858, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5859, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5859, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5860, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5860, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5861, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5861, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5862, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5862, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5863, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5863, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5864, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5864, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5865, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5865, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5866, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5866, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5867, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5867, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5867, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5868, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5868, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5869, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5869, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5870, 0.2103], grad_fn=<ClampBackward1>)\n",
      "Iteration 1700: Loss = 349716.125\n",
      "tensor([0.5870, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5871, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5871, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5872, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5872, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5873, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5873, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5874, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5874, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5875, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5875, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5876, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5876, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5876, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5877, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5877, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5878, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5878, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5879, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5879, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5880, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5880, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5881, 0.2103], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5881, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5882, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5882, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5882, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5883, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5883, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5884, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5884, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5885, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5885, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5886, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5886, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5886, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5887, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5887, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5888, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5888, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5889, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5889, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5890, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5890, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5890, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5891, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5891, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5892, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5892, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5893, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5893, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5894, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5894, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5894, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5895, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5895, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5896, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5896, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5897, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5897, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5897, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5898, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5898, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5899, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5899, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5900, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5900, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5900, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5901, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5901, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5902, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5902, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5902, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5903, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5903, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5904, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5904, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5905, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5905, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5905, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5906, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5906, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5907, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5907, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5907, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5908, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5908, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5909, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5909, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5909, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5910, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5910, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5911, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5911, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5911, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5912, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5912, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5913, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5913, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5913, 0.2104], grad_fn=<ClampBackward1>)\n",
      "Iteration 1800: Loss = 345913.4375\n",
      "tensor([0.5914, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5914, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5915, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5915, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5915, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5916, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5916, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5916, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5917, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5917, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5918, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5918, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5918, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5919, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5919, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5920, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5920, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5920, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5921, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5921, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5921, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5922, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5922, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5923, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5923, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5923, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5924, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5924, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5924, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5925, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5925, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5926, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5926, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5926, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5927, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5927, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5927, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5928, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5928, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5929, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5929, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5929, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5930, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5930, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5930, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5931, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5931, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5931, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5932, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5932, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5932, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5933, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5933, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5934, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5934, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5934, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5935, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5935, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5935, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5936, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5936, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5936, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5937, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5937, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5937, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5938, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5938, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5938, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5939, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5939, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5939, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5940, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5940, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5940, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5941, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5941, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5941, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5942, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5942, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5942, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5943, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5943, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5943, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5944, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5944, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5944, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5945, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5945, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5945, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5946, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5946, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5946, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5947, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5947, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5947, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5948, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5948, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5948, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5949, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5949, 0.2104], grad_fn=<ClampBackward1>)\n",
      "Iteration 1900: Loss = 343485.875\n",
      "tensor([0.5949, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5950, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5950, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5950, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5951, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5951, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5951, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5952, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5952, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5952, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5953, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5953, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5953, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5953, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5954, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5954, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5954, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5955, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5955, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5955, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5956, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5956, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5956, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5957, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5957, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5957, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5957, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5958, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5958, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5958, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5959, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5959, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5959, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5960, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5960, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5960, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5960, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5961, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5961, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5961, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5962, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5962, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5962, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5963, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5963, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5963, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5963, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5964, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5964, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5964, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5965, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5965, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5965, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5965, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5966, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5966, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5966, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5967, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5967, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5967, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5967, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5968, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5968, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5968, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5969, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5969, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5969, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5969, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5970, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5970, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5970, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5970, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5971, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5971, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5971, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5972, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5972, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5972, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5972, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5973, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5973, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5973, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5973, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5974, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5974, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5974, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5974, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5975, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5975, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5975, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5976, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5976, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5976, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5976, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5977, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5977, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5977, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5977, 0.2104], grad_fn=<ClampBackward1>)\n",
      "tensor([0.5978, 0.2104], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(binom_model, binom_guide, pyro.optim.Adam({\"lr\": 0.001}), pyro.infer.TraceGraph_ELBO())\n",
    "num_iterations = 2000\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(d_example, K=2)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration {}: Loss = {}\".format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41b4989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_param tensor([0.6659, 0.3341], grad_fn=<DivBackward0>)\n",
      "probs_param tensor([0.5978, 0.2104], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Print learned parameters\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5e0c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of success:  [0.5977877  0.21039617]\n",
      "Mmixing proportions:  [0.6659246 0.3340754]\n"
     ]
    }
   ],
   "source": [
    "# Extract learned parameters\n",
    "probs = pyro.param(\"probs_param\").detach().numpy()\n",
    "weights = pyro.param(\"weights_param\").detach().numpy()\n",
    "\n",
    "print(\"Probabilities of success: \", probs)\n",
    "print(\"Mmixing proportions: \", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae4cdced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of data\n",
    "VAF = d_example[:,0]/d_example[:,1]\n",
    "plt.hist(VAF, bins=50, density = True, color='steelblue')\n",
    "\n",
    "# Plot densities\n",
    "x = np.linspace(0.05, 1, 100)\n",
    "num_components = 2\n",
    "n = 150\n",
    "\n",
    "density1 = beta.pdf(x, n*probs[0], n*(1-probs[0])) * weights[0] # sample data from beta distribution with learned parameters\n",
    "plt.plot(x, density1, linewidth=1.5, label=f'Beta1', linestyle='--', color='r')\n",
    "density2 = beta.pdf(x, n*probs[1], n*(1-probs[1])) * weights[1] # sample data from beta distribution with learned parameters\n",
    "plt.plot(x, density2, linewidth=1.5, label=f'Beta2', linestyle='--', color='g')\n",
    "\n",
    "plt.xlabel('VAF')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Beta mixture with 2 components\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10aa25c",
   "metadata": {},
   "source": [
    "### 1D Binomial Pareto model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad62336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pkl data\n",
    "# These data contains a mixture with 1 Pareto and 2 beta components \n",
    "def load_example_data(directory = \"./\"):\n",
    "    flh = open(directory + \"example.pkl\", \"rb\")\n",
    "    inp = pickle.load(flh)\n",
    "    inp = {k: v.float().round() for k, v in zip(inp.keys(), inp.values())}\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9eb773d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "961"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_example_data(\"./\")\n",
    "len(data[\"1:1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "368fe402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1:1': tensor([[  7., 112.],\n",
       "         [  6., 101.],\n",
       "         [  7., 106.],\n",
       "         ...,\n",
       "         [ 47., 114.],\n",
       "         [ 64., 121.],\n",
       "         [ 66., 138.]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d73804e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[\"1:1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4a84796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([961, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db09f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_lk(probs, DP, weights, K, NV):\n",
    "    lk = torch.ones(K, len(NV)) # matrix with K rown and as many columns as the number of data\n",
    "    if K == 1:\n",
    "        return torch.log(weights) + dist.Binomial(total_count=DP, probs = probs).log_prob(NV) # simply does log(weights) + log(density)\n",
    "    for k in range(K):\n",
    "        lk[k, :] = torch.log(weights[k]) + dist.Binomial(total_count=DP, probs=probs[k]).log_prob(NV) # put on each column of lk a different data; rows are the clusters\n",
    "    return lk\n",
    "\n",
    "def pareto_lk(p, NV, DP):\n",
    "    return dist.Binomial(probs=p, total_count=DP).log_prob(NV)\n",
    "\n",
    "def final_lk(pareto, binomial, weights):\n",
    "    if len(binomial.shape) == 1:\n",
    "        dim0, dim1 = 1,binomial.shape[0] # dim0 is the number of beta peaks, dim1 is the number of data (mutations) -> this comes from the binomial_lk() function\n",
    "    else:\n",
    "        dim0, dim1 = binomial.shape[0], binomial.shape[1]\n",
    "    # print(dim0, dim1)\n",
    "    \n",
    "    lk = torch.ones(1 + dim0, dim1) # creates a matrix: rows with number of binomial peaks+1 (pareto), columns with data.\n",
    "                                    # So the rows will represent the components (with correspondent weights) and the columns represent the data\n",
    "    lk[0, :] = torch.log(weights[0]) + pareto\n",
    "    # print(weights[1:].shape, binomial.shape)\n",
    "\n",
    "    w_sum = weights[1:].sum()\n",
    "    lk[1:(1 + dim1), :] = torch.log(w_sum) + binomial.unsqueeze(0)\n",
    "    # lk[1:(1 + dim1), :] = torch.log(weights[1:]) + binomial\n",
    "    return lk\n",
    "\n",
    "\n",
    "def log_sum_exp(args):\n",
    "    c = torch.amax(args, dim=0)\n",
    "    return c + torch.log(torch.sum(torch.exp(args - c), axis=0)) # sum over the rows (different clusters), so obtain a single likelihood for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90f54187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.distributions import Rejector, Pareto\n",
    "# Rejector: Rejection sampled distribution given an acceptance rate function.\n",
    "\n",
    "# BoundedPareto taken form MOBSTERH\n",
    "class BoundedPareto(Rejector):\n",
    "    def __init__(self, scale, alpha, upper_limit, validate_args=False):\n",
    "        propose = Pareto(scale, alpha, validate_args=validate_args)\n",
    "\n",
    "        def log_prob_accept(x):\n",
    "            return (x <= upper_limit).type_as(x).log()\n",
    "        # log_prob_accept: This is a function that computes the logarithm of the acceptance probability for a given value x. \n",
    "        # It checks if x is less than or equal to the upper_limit. \n",
    "        # If x is within the specified range, the function returns the log of 1 (acceptance probability is 1). \n",
    "        # Otherwise, it returns the log of 0 (acceptance probability is 0).\n",
    "\n",
    "        # log_scale = torch.Tensor(alpha) * torch.log(torch.Tensor([scale / upper_limit]))\n",
    "        log_scale = 0\n",
    "        super(BoundedPareto, self).__init__(propose, log_prob_accept, log_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66421ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_pareto_model(data, K):\n",
    "    NV = data[:,0].int()\n",
    "    DP = data[:,1].int()\n",
    "    VAF = NV/DP \n",
    "\n",
    "    # prior for Pareto shape parameter (alpha_pareto)\n",
    "    alpha = pyro.sample(\"alpha_pareto\", dist.LogNormal(0,100))\n",
    "    probs_pareto = pyro.sample(\"probs_pareto\", BoundedPareto(torch.min(VAF) - 1e-5, alpha, 1))\n",
    "    # probs_pareto = pyro.sample(\"probs_pareto\", dist.Pareto(torch.min(VAF) - 1e-5, alpha))\n",
    "\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(torch.ones(K+1)))\n",
    "\n",
    "    # Prior for success probability of each component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        probs = pyro.sample(\"probs\", dist.Beta(1, 1)) # assume Beta prior for the success probabilities\n",
    "        # print(probs)\n",
    "\n",
    "    # Plate for the data\n",
    "    with pyro.plate(\"plate_data\", len(data)):\n",
    "        binomial = binomial_lk(probs, DP, weights[1:], K, NV)\n",
    "        pareto = pareto_lk(probs_pareto, NV, DP)\n",
    "        pyro.factor(\"lik\", log_sum_exp(final_lk(pareto, binomial, weights)).sum()) # .sum() sums over the data because we have a log-likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21ac5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_pareto_guide(data, K):\n",
    "    NV = data[:,0].int()\n",
    "    DP = data[:,1].int()\n",
    "    VAF = NV/DP\n",
    "    \n",
    "    # Mixing proportions to be learned\n",
    "    weights_param = pyro.param(\"weights_param\", lambda: dist.Dirichlet(torch.ones(K+1)).sample(), constraint=constraints.simplex)\n",
    "    weights = pyro.sample(\"weights\", dist.Delta(weights_param).to_event(1))\n",
    "\n",
    "    probs_param = pyro.param(\"probs_param\", dist.Beta(torch.ones(K), torch.ones(K)).sample(), constraint=constraints.interval(0.,1.))\n",
    "\n",
    "    # Pareto\n",
    "    # alpha_param = pyro.param(\"alpha_param\", dist.LogNormal(0,100).sample(), constraint=constraints.positive) # with LogNormal it does not work, check\n",
    "    alpha_param = pyro.param(\"alpha_param\", torch.tensor(0.8), constraint=constraints.positive) # Use 0.8 as starting value\n",
    "    pyro.sample(\"alpha_pareto\", dist.Delta(alpha_param))\n",
    "    \n",
    "    # Using param for this probability it does not learn the right parameters, I do not know why\n",
    "    # probs_pareto_param = pyro.param(\"probs_pareto_param\", BoundedPareto(torch.min(VAF) - 1e-5, alpha_param, 1).sample(), constraint=constraints.interval(0.,1.))\n",
    "    # pyro.sample(\"probs_pareto\", dist.Delta(probs_pareto_param))\n",
    "    pyro.sample(\"probs_pareto\", BoundedPareto(torch.min(VAF) - 1e-5, alpha_param, 1))\n",
    "    \n",
    "    # Probability of success for each beta component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        pyro.sample(\"probs\", dist.Delta(probs_param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78ed6ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 24183418.0\n",
      "Iteration 100: Loss = 38402016.0\n",
      "Iteration 200: Loss = 16382365.0\n",
      "Iteration 300: Loss = 7076681.5\n",
      "Iteration 400: Loss = 4741486.0\n",
      "Iteration 500: Loss = 5123930.0\n",
      "Iteration 600: Loss = 4368314.5\n",
      "Iteration 700: Loss = 4369308.5\n",
      "Iteration 800: Loss = 4719802.5\n",
      "Iteration 900: Loss = 4915904.5\n",
      "Iteration 1000: Loss = 5064776.0\n",
      "Iteration 1100: Loss = 18452452.0\n",
      "Iteration 1200: Loss = 5000326.0\n",
      "Iteration 1300: Loss = 5299770.5\n",
      "Iteration 1400: Loss = 4407922.0\n",
      "Iteration 1500: Loss = 5112594.5\n",
      "Iteration 1600: Loss = 4912262.5\n",
      "Iteration 1700: Loss = 4898350.5\n",
      "Iteration 1800: Loss = 5337990.5\n",
      "Iteration 1900: Loss = 5411963.0\n",
      "Iteration 2000: Loss = 5089210.5\n",
      "Iteration 2100: Loss = 4327175.5\n",
      "Iteration 2200: Loss = 4529639.0\n",
      "Iteration 2300: Loss = 4769827.5\n",
      "Iteration 2400: Loss = 5284553.5\n",
      "Iteration 2500: Loss = 4761371.5\n",
      "Iteration 2600: Loss = 4307914.5\n",
      "Iteration 2700: Loss = 4380011.5\n",
      "Iteration 2800: Loss = 4912142.5\n",
      "Iteration 2900: Loss = 5358834.5\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(binom_pareto_model, binom_pareto_guide, pyro.optim.Adam({\"lr\": 0.01}), pyro.infer.TraceGraph_ELBO())\n",
    "num_iterations = 3000\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(data, K=1)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration {}: Loss = {}\".format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "53555140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_param tensor([0.2457, 0.7543], grad_fn=<DivBackward0>)\n",
      "probs_param tensor([0.4624], grad_fn=<ClampBackward1>)\n",
      "alpha_param tensor(3.0759, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "141e7b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of success binomial component:  [0.4623797]\n",
      "Alpha pareto:  3.0759087\n",
      "Mmixing proportions:  [0.24574329 0.7542567 ]\n"
     ]
    }
   ],
   "source": [
    "# Extract the learned parameters\n",
    "probs_bin = pyro.param(\"probs_param\").detach().numpy()\n",
    "alpha_pareto = pyro.param(\"alpha_param\").detach().numpy() \n",
    "weights = pyro.param(\"weights_param\").detach().numpy()\n",
    "\n",
    "print(\"Probabilities of success binomial component: \", probs_bin)\n",
    "print(\"Alpha pareto: \", alpha_pareto)\n",
    "print(\"Mmixing proportions: \", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d4886e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABgKElEQVR4nO3dd3wUdf7H8dekVxIICUkg9F6kigUUsIA0C3rgCVIUzy6gIGI54VBBPflhAz0L4KGAKKgnKKICgqj0Jr230CEhCenz+2PdhZAEUnZ3dpP38/HYR7KT2Zn3DiH55DvfYpimaSIiIiLipXysDiAiIiJSGipmRERExKupmBERERGvpmJGREREvJqKGREREfFqKmZERETEq6mYEREREa+mYkZERES8mooZERER8WoqZkSAqVOnYhhGnkd0dDQdO3bk22+/LfFxJ02axNSpU50X9AIdO3bMkzc4OJjmzZszceJEcnNzXXLOS1m+fDmjR4/mzJkzbj/3pezduxfDMEr07zB//nxGjx7t9ExlQWmu6+LFizEMg8WLFzs9l5RPKmZELjBlyhR+++03li9fzn/+8x98fX3p2bMn//vf/0p0PFcWMwC1a9fmt99+47fffmPWrFlUrVqVYcOGMWrUKJedszDLly9nzJgxHlfMxMXF8dtvv9G9e/div3b+/PmMGTPGBalExJn8rA4g4kmaNm1KmzZtHM9vueUWKlasyIwZM+jZs6eFyQoWHBzM1Vdf7XjetWtXGjZsyDvvvMNLL72Ev79/iY+dlZWFYRj4+Xn3j4nAwMA818gTpKWlERISYnUMkTJDLTMilxAUFERAQEC+oiAzM5OXXnqJhg0bEhgYSHR0NIMGDeL48eOOfWrWrMmff/7JkiVLHLeCatasCUB6ejpPPfUULVq0ICIigkqVKnHNNdfw9ddflyqvv78/rVu3Ji0tjePHj7Nz504GDRpEvXr1CAkJoWrVqvTs2ZONGzfmeZ292f+///0vTz31FFWrViUwMJCdO3cC8OOPP3LjjTdSoUIFQkJCaNeuHT/99JPj9aNHj2bEiBEA1KpVy/F+7bcRcnNzee211xzXKyYmhv79+3Pw4MHLvqfRo0djGAYbNmzgb3/7m+N6Pfnkk2RnZ7Nt2zZuueUWwsPDqVmzJq+99lqe1198OyQ9PZ2WLVtSt25dkpKSHPsdOXKE2NhYOnbsSE5ODgMHDuTdd98FyHM7b+/evZe8xWIYRp5bU/b8a9as4a677qJixYrUqVMHANM0mTRpEi1atCA4OJiKFSty1113sXv3bpdfF4D9+/fTr18/YmJiCAwMpFGjRrzxxhv5blMePnyY3r17Ex4eTkREBH369OHIkSMF5lq1ahW33norlSpVIigoiJYtW/L5559f9v2IlIaKGZEL5OTkkJ2dTVZWFgcPHmTo0KGkpqZyzz33OPbJzc3ltttuY/z48dxzzz3MmzeP8ePHs3DhQjp27Mi5c+cAmDt3LrVr16Zly5aOW0Fz584FICMjg1OnTjF8+HC++uorZsyYQfv27enVqxeffPJJqd7Drl278PPzo2LFihw+fJioqCjGjx/P999/z7vvvoufnx9XXXUV27Zty/faUaNGsX//ft577z3+97//ERMTw/Tp0+ncuTMVKlRg2rRpfP7551SqVIkuXbo4CprBgwfz+OOPAzBnzhzH+23VqhUADz/8MCNHjuTmm2/mm2++YezYsXz//fdce+21nDhxokjvq3fv3jRv3pwvv/ySBx54gP/7v/9j2LBh3H777XTv3p25c+dyww03MHLkSObMmVPocYKCgvj88885duwY9913H2D7N+3bty+maTJjxgx8fX154YUXuOuuuwAc7+e3334jLi6u6P8YF+jVqxd169Zl9uzZvPfeewA8+OCDDB06lJtuuomvvvqKSZMm8eeff3Lttddy9OhRl16X48ePc+211/LDDz8wduxYvvnmG2666SaGDx/OY4895tjv3Llz3HTTTfzwww+MGzeO2bNnExsbS58+ffJlWbRoEe3atePMmTO89957fP3117Ro0YI+ffq49HarCKaImFOmTDGBfI/AwEBz0qRJefadMWOGCZhffvllnu0rV640gTz7N2nSxOzQocNlz5+dnW1mZWWZ999/v9myZcsiZe7QoYPZpEkTMysry8zKyjIPHz5sPvPMMyZg/u1vfyv0PJmZmWa9evXMYcOGObYvWrTIBMzrr78+z/6pqalmpUqVzJ49e+bZnpOTYzZv3txs27atY9vrr79uAuaePXvy7LtlyxYTMB955JE82//44w8TMJ999tlLvs8XX3zRBMw33ngjz/YWLVqYgDlnzhzHtqysLDM6Otrs1auXY9uePXtMwJwyZUqe18+aNcsEzIkTJ5r//Oc/TR8fH/OHH37Is8+jjz5qFvRjsrBjmqZpAuaLL76YL/8///nPPPv99ttvBb6vAwcOmMHBwebTTz9d4PW4+LglvS7275U//vgjz+sffvhh0zAMc9u2baZpmubkyZNNwPz666/z7PfAAw/kuwYNGzY0W7ZsaWZlZeXZt0ePHmZcXJyZk5Njmub577dFixZd8j2KFJVaZkQu8Mknn7By5UpWrlzJd999x4ABA3j00Ud55513HPt8++23REZG0rNnT7Kzsx2PFi1aEBsbW+QRGrNnz6Zdu3aEhYXh5+eHv78/H330EVu2bHHsk5ubm+ccOTk5eY7x559/4u/vj7+/P/Hx8bzxxhv07duXDz74AIDs7GxeeeUVGjduTEBAAH5+fgQEBLBjx44857G788478zxfvnw5p06dYsCAAXly5Obmcsstt7By5UpSU1Mv+T4XLVoEwMCBA/Nsb9u2LY0aNcpzu+pSevToked5o0aNMAyDrl27Orb5+flRt25d9u3bd9nj9e7dm4cffpgRI0bw0ksv8eyzz3LzzTcXKUtJXHxtv/32WwzDoF+/fnmubWxsLM2bNy/y91FJr8vPP/9M48aNadu2bZ7XDxw4ENM0+fnnnwHbv194eDi33nprnv0ubK0E2LlzJ1u3bqVv374Aed5Tt27dSExMLLA1UMQZvLtnn4iTNWrUKF8H4H379vH000/Tr18/IiMjOXr0KGfOnCEgIKDAYxTltsmcOXPo3bs3f/vb3xgxYgSxsbH4+fkxefJkPv74Y8d+9913H9OmTXM879ChQ55fcnXq1GHmzJkYhkFQUBC1atXK07H0ySef5N1332XkyJF06NCBihUr4uPjw+DBgx23wy508S0U+60O++2Wgpw6dYrQ0NBCv37y5MkCjw0QHx9fpMIDoFKlSnmeBwQEEBISQlBQUL7tycnJRTrmfffdx+TJkwkICOCJJ54o0mtKqqBra5omVapUKXD/2rVrF+m4Jb0uJ0+edPThulB8fLzj6/aPBWWMjY3N89z+vTJ8+HCGDx9eYNai3lIUKS4VMyKXccUVV7BgwQK2b99O27ZtqVy5MlFRUXz//fcF7h8eHn7ZY06fPp1atWoxa9YsDMNwbM/IyMiz3+jRo/P0X7j42EFBQXmKr4LO079/f1555ZU820+cOEFkZGS+/S/MAlC5cmUA3n777UJHBBX2y9guKioKgMTERKpVq5bna4cPH3acw91SU1O59957qV+/PkePHmXw4MFF7oBtLxQu/veyFwAFKejaGobB0qVLCQwMzLd/QducKSoqisTExHzbDx8+7Mhn32/FihX59ru4A7B9/1GjRtGrV68Cz9mgQYNSZRYpjIoZkctYt24dANHR0YCtWX/mzJnk5ORw1VVXXfK1gYGBBbaAGIZBQEBAnl9wR44cyffLtGbNmgX+9VxUhmHk+6U4b948Dh06RN26dS/7+nbt2hEZGcnmzZvzFFUFsZ/n4vd7ww03ALbC6sorr3RsX7lyJVu2bOG5554r0ntxtoceeoj9+/ezYsUKtm7dyl133eXoPGt34XsKDg52bK9SpQpBQUFs2LAhzzGLMxqtR48ejB8/nkOHDtG7d+9Svpviu/HGGxk3bhxr1qxxdNQG261WwzDo1KkTAJ06deLzzz/nm2++yXOr6bPPPstzvAYNGlCvXj3Wr1+fr3gWcTUVMyIX2LRpE9nZ2YDtr+w5c+awcOFC7rjjDmrVqgXA3Xffzaeffkq3bt0YMmQIbdu2xd/fn4MHD7Jo0SJuu+027rjjDgCaNWvGzJkzmTVrFrVr1yYoKIhmzZrRo0cP5syZwyOPPMJdd93FgQMHGDt2LHFxcezYscNp76dHjx5MnTqVhg0bcsUVV7B69Wpef/31fC0khQkLC+Ptt99mwIABnDp1irvuuouYmBiOHz/O+vXrOX78OJMnT3a8V4A333yTAQMG4O/vT4MGDWjQoAH/+Mc/ePvtt/Hx8aFr167s3buXF154gYSEhDzFg7t8+OGHTJ8+nSlTptCkSROaNGnCY489xsiRI2nXrp2jH4n9Pb366qt07doVX19frrjiCgICAujXrx8ff/wxderUoXnz5qxYsSLfL/hLadeuHf/4xz8YNGgQq1at4vrrryc0NJTExESWLVtGs2bNePjhh13y/gGGDRvGJ598Qvfu3fnXv/5FjRo1mDdvHpMmTeLhhx+mfv36APTv35//+7//o3///rz88svUq1eP+fPns2DBgnzHfP/99+natStdunRh4MCBVK1alVOnTrFlyxbWrFnD7NmzXfZ+pJyzugeyiCcoaDRTRESE2aJFC3PChAlmenp6nv2zsrLMf//732bz5s3NoKAgMywszGzYsKH54IMPmjt27HDst3fvXrNz585meHi4CZg1atRwfG38+PFmzZo1zcDAQLNRo0bmBx984BihUhT20UyXcvr0afP+++83Y2JizJCQELN9+/bm0qVLzQ4dOuQZZWUfXTJ79uwCj7NkyRKze/fuZqVKlUx/f3+zatWqZvfu3fPtP2rUKDM+Pt708fHJM1olJyfHfPXVV8369eub/v7+ZuXKlc1+/fqZBw4cuOz7tF+T48eP59k+YMAAMzQ09LLX5eKRRxs2bDCDg4PNAQMG5Hldenq62bp1a7NmzZrm6dOnTdM0zYyMDHPw4MFmdHS0aRhGntFaSUlJ5uDBg80qVaqYoaGhZs+ePc29e/cWOprp4vx2H3/8sXnVVVeZoaGhZnBwsFmnTh2zf//+5qpVq1x6XUzTNPft22fec889ZlRUlOnv7282aNDAfP311x2jjuwOHjxo3nnnnWZYWJgZHh5u3nnnneby5csLHNG1fv16s3fv3mZMTIzp7+9vxsbGmjfccIP53nvvOfbRaCZxNsM0TdP9JZSIiIiIc2hotoiIiHg1FTMiIiLi1VTMiIiIiFdTMSMiIiJeTcWMiIiIeDUVMyIiIuLVyvykebm5uRw+fJjw8PB804mLiIiIZzJNk7NnzxIfH4+Pz6XbXsp8MXP48GESEhKsjiEiIiIlcODAgcvOWl7mixn7wnwHDhygQoUKFqcRERGRokhOTiYhIaFIi/eW+WLGfmupQoUKKmZERES8TFG6iKgDsIiIiHg1FTMiIiLi1VTMiIiIiFcr831mREREiio3N5fMzEyrY5QL/v7++Pr6OuVYKmZERESAzMxM9uzZQ25urtVRyo3IyEhiY2NLPQ+cihkRESn3TNMkMTERX19fEhISLjtJm5SOaZqkpaVx7NgxAOLi4kp1PBUzIiJS7mVnZ5OWlkZ8fDwhISFWxykXgoODATh27BgxMTGluuWk0lNERMq9nJwcAAICAixOUr7YC8esrKxSHUfFjIiIyF+0hp97Oet6q5gRERERr6ZiRkRERLyaihkREREvNXDgQAzDcDyioqK45ZZb2LBhQ7GOcfvttxf73ImJidxzzz00aNAAHx8fhg4dWuxjOIuKGRERES92yy23kJiYSGJiIj/99BN+fn706NHD5efNyMggOjqa5557jubNm7v8fJeiYkZERMSLBQYGEhsbS2xsLC1atGDkyJEcOHCA48ePA3Do0CH69OlDxYoViYqK4rbbbmPv3r0AjB49mmnTpvH11187WncWL14MwMiRI6lfvz4hISHUrl2bF154Ic+oo5o1a/Lmm2/Sv39/IiIi3P2289A8MyW078w+tp7YSmxYLM1jra1IRUTERVJTC/+ary8EBRVtXx8f+GtelUvuGxpavHwXSUlJ4dNPP6Vu3bpERUWRlpZGp06duO666/jll1/w8/PjpZdectyKGj58OFu2bCE5OZkpU6YAUKlSJQDCw8OZOnUq8fHxbNy4kQceeIDw8HCefvrpUmV0BRUzJTR782xGLBzBvVfcyyd3fGJ1HBERcYWwsMK/1q0bzJt3/nlMDKSlFbxvhw7wV4sHADVrwokT+fczzWJH/Pbbbwn7K2dqaipxcXF8++23+Pj4MHPmTHx8fPjwww8dw6CnTJlCZGQkixcvpnPnzgQHB5ORkUFsbGye4z7//PMXxK3JU089xaxZs1TMlCWBvoEAZORkWJxERETKs06dOjF58mQATp06xaRJk+jatSsrVqxg9erV7Ny5k/Dw8DyvSU9PZ9euXZc87hdffMHEiRPZuXMnKSkpZGdnU6FCBZe9j9JQMVNCAb62WSIzc7S6qohImZWSUvjXLp5+/691hgp08VpPf/VZcYbQ0FDq1q3reN66dWsiIiL44IMPyM3NpXXr1nz66af5XhcdHV3oMX///XfuvvtuxowZQ5cuXYiIiGDmzJm88cYbTsvtTCpmSijQ76+WmWy1zIiIlFnF6cPiqn2LyTAMfHx8OHfuHK1atWLWrFnExMQU2qoSEBDgWM7B7tdff6VGjRo899xzjm379u1zWebS0mimErK3zOg2k4iIWCkjI4MjR45w5MgRtmzZwuOPP05KSgo9e/akb9++VK5cmdtuu42lS5eyZ88elixZwpAhQzh48CBg6w+zYcMGtm3bxokTJ8jKyqJu3brs37+fmTNnsmvXLt566y3mzp2b79zr1q1j3bp1pKSkcPz4cdatW8fmzZvdfQnUMlNS9j4zus0kIiJW+v7774mLiwNsI5AaNmzI7Nmz6dixIwC//PILI0eOpFevXpw9e5aqVaty4403OlpqHnjgARYvXkybNm1ISUlh0aJF3HbbbQwbNozHHnuMjIwMunfvzgsvvMDo0aPznLtly5aOz1evXs1nn31GjRo1HEO/3cUwzRJ0nfYiycnJREREkJSU5NSOS//b9j9unXkrV8ZfyYoHVjjtuCIi4n7p6ens2bOHWrVqEXThcGtxqUtd9+L8/lbLTAk1jWnKxC4TiQuPszqKiIhIuaZipoRqVazFkKuHWB1DRESk3FMHYBEREfFqapkpodTMVNYeWYuBQbvq7ayOIyIiUm6pmCmhPWf2cN2U64gOiebYiEtMlCQiIiIupdtMJaQZgEVERDyDipkS0tpMIiIinkHFTAmpZUZERMQzqJgpIfvaTLlmLtm52RanERERKb9UzJSQvWUG1DojIiJiJRUzJWTvMwNaOVtERKwxcOBADMPAMAz8/f2pXbs2w4cPJzU11WXnXLx4MYZhcObMGZedo7g0NLuE/Hz8eKnTSwT6BTpuOYmIiLjbLbfcwpQpU8jKymLp0qUMHjyY1NRUJk+eXKzjmKZJTk4Ofn7eVxpY2jLzyy+/0LNnT+Lj4zEMg6+++qrQfR988EEMw2DixIluy3cphmHw3PXPMfza4YT4h1gdR0REyqnAwEBiY2NJSEjgnnvuoW/fvnz11VdMnz6dNm3aEB4eTmxsLPfccw/Hjp2fF83ewrJgwQLatGlDYGAgS5cuxTRNXnvtNWrXrk1wcDDNmzfniy++AGDv3r106tQJgIoVK2IYBgMHDgQgIyODJ554gpiYGIKCgmjfvj0rV650yzWwtPxKTU2lefPmDBo0iDvvvLPQ/b766iv++OMP4uPj3ZhORETKu9TMwm/X+Pr4EuQXVKR9fQwfgv2DL7tvaEBoCVLmFRwcTFZWFpmZmYwdO5YGDRpw7Ngxhg0bxsCBA5k/f36e/Z9++mn+/e9/U7t2bSIjI3n++eeZM2cOkydPpl69evzyyy/069eP6Oho2rdvz5dffsmdd97Jtm3bqFChAsHBwY7jfPnll0ybNo0aNWrw2muv0aVLF3bu3EmlSpVK/b4uxdJipmvXrnTt2vWS+xw6dIjHHnuMBQsW0L17dzclK5pNxzaRlpVGk+gmTvkGFBERzxI2LqzQr3Wr141598xzPI/5dwxpWWkF7tuhRgcWD1zseF7zzZqcSDuRbz/zRbPkYYEVK1bw2WefceONN3Lfffc5tteuXZu33nqLtm3bkpKSQljY+ff1r3/9i5tvvhmwNTJMmDCBn3/+mWuuucbx2mXLlvH+++/ToUMHR2ESExNDZGSk43WTJ09m6tSpjt/rH3zwAQsXLuSjjz5ixIgRpXpfl+PRN8Zyc3O59957GTFiBE2aNCnSazIyMsjION8hNzk52VXxuGX6LRw6e4g1/1hDy7iWLjuPiIhIYb799lvCwsLIzs4mKyuL2267jbfffpu1a9cyevRo1q1bx6lTp8jNzQVg//79NG7c2PH6Nm3aOD7fvHkz6enpjuLGLjMzk5YtC/89t2vXLrKysmjX7vxahf7+/rRt25YtW7Y4660WyqOLmVdffRU/Pz+eeOKJIr9m3LhxjBkzxoWpzrMPz9YswCIiZVPKqJRCv+br45vn+bHhha/T52Pk7aK6d8jeUuW6UKdOnZg8eTL+/v7Ex8fj7+9PamoqnTt3pnPnzkyfPp3o6Gj2799Ply5dyMzMO51IaOj5Owv2gmfevHlUrVo1z36BgYUPdjFNW4uSYRj5tl+8zRU8tphZvXo1b775JmvWrCnWhRg1ahRPPvmk43lycjIJCQmuiOgYxaR5ZkREyqbidCFw1b6XPVZoKHXr1s2zbevWrZw4cYLx48c7fgeuWrXqssdq3LgxgYGB7N+/nw4dOhS4T0CA7Q/5nJwcx7a6desSEBDAsmXLuOeeewDIyspi1apVDB06tCRvq1g8tphZunQpx44do3r16o5tOTk5PPXUU0ycOJG9e/cW+LrAwMBLVo/O5GiZ0TwzIiLiQapXr05AQABvv/02Dz30EJs2bWLs2LGXfV14eDjDhw9n2LBh5Obm0r59e5KTk1m+fDlhYWEMGDCAGjVqYBgG3377Ld26dSM4OJiwsDAefvhhRowYQaVKlahevTqvvfYaaWlp3H///S5/vx5bzNx7773cdNNNebZ16dKFe++9l0GDBlmUKi/7xHlqmREREU8SHR3N1KlTefbZZ3nrrbdo1aoV//73v7n11lsv+9qxY8cSExPDuHHj2L17N5GRkbRq1Ypnn30WgKpVqzJmzBieeeYZBg0aRP/+/Zk6dSrjx4939HU9e/Ysbdq0YcGCBVSsWNHVbxfDtN/oskBKSgo7d+4EoGXLlkyYMIFOnTo5qrqL1axZk6FDhxarySo5OZmIiAiSkpKoUKGCs6ID0P7j9vx64Fe+7P0lvRr1cuqxRUTEfdLT09mzZw+1atUiKCjo8i8Qp7jUdS/O729LW2ZWrVrlmHwHcPR1GTBgAFOnTrUoVdGpz4yIiIj1LC1mOnbsSHEahgrrJ2OVe6+4l+uqX0eT6KINGxcRERHn89g+M95gYIuBVkcQEREp97RqtoiIiHg1tcyUwpGUI5xMO0l0aDQxoTFWxxERkVKycExMueSs662WmVJ47qfnaDq5KR+t+cjqKCIiUgq+vrbZfC+eHVdcKy3NtpaVv79/qY6jlplSsI9m0nIGIiLezc/Pj5CQEI4fP46/vz8+Pvpb35VM0yQtLY1jx44RGRnpKCZLSsVMKdhnANbQbBER72YYBnFxcezZs4d9+/ZZHafciIyMJDY2ttTHUTFTCvYZgLWcgYiI9wsICKBevXq61eQm/v7+pW6RsVMxUwpqmRERKVt8fHw0A7AX0k3BUlCfGREREeupmCkFtcyIiIhYT7eZSqFt1bY8dc1TXBl/pdVRREREyi0VM6XQsWZHOtbsaHUMERGRck23mURERMSrqWWmFNKy0jiWegw/Hz+qVahmdRwREZFySS0zpTBv+zxqvVmLvnP6Wh1FRESk3FIxUwr2odkazSQiImIdFTOlYB+arRmARURErKNiphTsyxmoZUZERMQ6KmZKwdEyoxmARURELKNiphTUZ0ZERMR6KmZKQX1mRERErKd5ZkohOiSah1o/RMXgilZHERERKbdUzJRCXHgck3tMtjqGiIhIuabbTCIiIuLVVMyUQq6Zy4m0Exw+exjTNK2OIyIiUi7pNlMppGamEv16NABpz6YR7B9scSIREZHyRy0zpWAfzQQani0iImIVFTOlcGExo4nzRERErKFiphQMw8Dfxx9Qy4yIiIhVVMyUkn0WYE2cJyIiYg0VM6Vkv9WklhkRERFrqJgpJfvK2eozIyIiYg0NzS6lPk36cDbzLJFBkVZHERERKZdUzJTS/93yf1ZHEBERKdd0m0lERES8moqZUsrIziApPUkdgEVERCxiaTHzyy+/0LNnT+Lj4zEMg6+++srxtaysLEaOHEmzZs0IDQ0lPj6e/v37c/jwYesCF+CGT24g8tVI5u+Yb3UUERGRcsnSYiY1NZXmzZvzzjvv5PtaWloaa9as4YUXXmDNmjXMmTOH7du3c+utt1qQtHD2odmaZ0ZERMQalnYA7tq1K127di3waxERESxcuDDPtrfffpu2bduyf/9+qlev7o6Il2Ufmq3bTCIiItbwqtFMSUlJGIZBZGRkoftkZGSQkXG+lSQ5OdmlmRwtM5pnRkRExBJe0wE4PT2dZ555hnvuuYcKFSoUut+4ceOIiIhwPBISElyay76cgVpmRERErOEVxUxWVhZ33303ubm5TJo06ZL7jho1iqSkJMfjwIEDLs2mPjMiIiLW8vjbTFlZWfTu3Zs9e/bw888/X7JVBiAwMJDAwEA3pVOfGREREat5dDFjL2R27NjBokWLiIqKsjpSPm2rtiUtK40GlRtYHUVERKRcsrSYSUlJYefOnY7ne/bsYd26dVSqVIn4+Hjuuusu1qxZw7fffktOTg5HjhwBoFKlSgQEBFgVO4+H2jzEQ20esjqGiIhIuWWYpmladfLFixfTqVOnfNsHDBjA6NGjqVWrVoGvW7RoER07dizSOZKTk4mIiCApKemyt6hERETEMxTn97elLTMdO3bkUrWUhXVWsWTnZmOaJv6+/lZHERERKXe8YjSTJxu7ZCz+Y/15/LvHrY4iIiJSLqmYKSVNmiciImItFTOlZC9mNDRbRETEGipmSsk+A7AmzRMREbGGiplSUsuMiIiItVTMlJJ9BmD1mREREbGGiplSUsuMiIiItTx6OQNvkBCRQI/6PWgW08zqKCIiIuWSpTMAu4NmABYREfE+xfn9rdtMIiIi4tVUzIiIiIhXUzFTSqsPrybopSBqv1nb6igiIiLlkoqZUvLz8SMjJ4P07HSro4iIiJRLKmZKSWsziYiIWEvFTCnZlzPQPDMiIiLWUDFTSo6WGa3NJCIiYgkVM6VkX84gKzeLMj5lj4iIiEdSMVNK9pYZ0K0mERERK2g5g1IK8guiU81OBPgGkGvmWh1HRESk3FExU0qBfoH8POBnq2OIiIiUW7rNJCIiIl5NxYyIiIh4NRUzTlDv7XqEjwtn24ltVkcREREpd1TMOMHZjLOkZKZoFmARERELqJhxAvsswJo4T0RExP1UzDiBfa4ZzTMjIiLifipmnMA+C7BuM4mIiLifihknUMuMiIiIdVTMOIH6zIiIiFhHMwA7QfMqzfE1fIkIirA6ioiISLmjYsYJ3uvxntURREREyi3dZhIRERGvpmJGREREvJqKGSd44rsniHsjjvdXvW91FBERkXJHxYwTJGckcyTlCEkZSVZHERERKXdUzDiBfdI8zTMjIiLifpYWM7/88gs9e/YkPj4ewzD46quv8nzdNE1Gjx5NfHw8wcHBdOzYkT///NOasJdgnzRP88yIiIi4n6XFTGpqKs2bN+edd94p8OuvvfYaEyZM4J133mHlypXExsZy8803c/bsWTcnvTT7pHlqmREREXE/S+eZ6dq1K127di3wa6ZpMnHiRJ577jl69eoFwLRp06hSpQqfffYZDz74oDujXpKjZUZrM4mIiLidx/aZ2bNnD0eOHKFz586ObYGBgXTo0IHly5cX+rqMjAySk5PzPFxNfWZERESs47HFzJEjRwCoUqVKnu1VqlRxfK0g48aNIyIiwvFISEhwaU6A+PB4WsS2ID483uXnEhERkbw8fjkDwzDyPDdNM9+2C40aNYonn3zS8Tw5OdnlBc0DrR/ggdYPuPQcIiIiUjCPLWZiY2MBWwtNXFycY/uxY8fytdZcKDAwkMDAQJfnExEREc/gsbeZatWqRWxsLAsXLnRsy8zMZMmSJVx77bUWJhMRERFPYmkxk5KSwrp161i3bh1g6/S7bt069u/fj2EYDB06lFdeeYW5c+eyadMmBg4cSEhICPfcc4+VsfP5autX1H2rLv3n9rc6ioiISLlj6W2mVatW0alTJ8dze1+XAQMGMHXqVJ5++mnOnTvHI488wunTp7nqqqv44YcfCA8Ptypygc5lnWPX6V1Uj6hudRQREZFyx9JipmPHjpimWejXDcNg9OjRjB492n2hSkCT5omIiFjHY/vMeBNNmiciImIdFTNOoEnzRERErKNixgm00KSIiIh1VMw4gfrMiIiIWMdjJ83zJuEB4dStVJeECq5fOkFERETyUjHjBE1imrDj8R1WxxARESmXdJtJREREvJqKGREREfFqKmac4NS5U7R4rwWN3218yUkARURExPnUZ8YJDAzWH10PQHZuNv6+/hYnEhERKT9K1DKzZ88eZ+fwavZ5ZkCzAIuIiLhbiYqZunXr0qlTJ6ZPn056erqzM3kd+zwzoLlmRERE3K1Excz69etp2bIlTz31FLGxsTz44IOsWLHC2dm8hp+PHz6G7VJqFmARERH3KlEx07RpUyZMmMChQ4eYMmUKR44coX379jRp0oQJEyZw/PhxZ+f0ePZbTWqZERERca9SjWby8/Pjjjvu4PPPP+fVV19l165dDB8+nGrVqtG/f38SExOdldPj2RebVJ8ZERER9ypVMbNq1SoeeeQR4uLimDBhAsOHD2fXrl38/PPPHDp0iNtuu81ZOT1e9Yjq1IioYXUMERGRcscwSzAxyoQJE5gyZQrbtm2jW7duDB48mG7duuHjc7422rlzJw0bNiQ7O9upgYsrOTmZiIgIkpKSqFChgqVZREREpGiK8/u7RPPMTJ48mfvuu49BgwYRGxtb4D7Vq1fno48+KsnhRURERIqsRC0z3kQtMyIiIt6nOL+/S9RnZsqUKcyePTvf9tmzZzNt2rSSHNLrDfp6EFd+cCXLDyy3OoqIiEi5UqJiZvz48VSuXDnf9piYGF555ZVSh/JGm49vZtXhVZxMO2l1FBERkXKlRMXMvn37qFWrVr7tNWrUYP/+/aUO5Y3s88xoaLaIiIh7laiYiYmJYcOGDfm2r1+/nqioqFKH8kb2eWY0aZ6IiIh7laiYufvuu3niiSdYtGgROTk55OTk8PPPPzNkyBDuvvtuZ2f0Co6WGS1nICIi4lYlGpr90ksvsW/fPm688Ub8/GyHyM3NpX///uW2z4x9sUm1zIiIiLhXiYqZgIAAZs2axdixY1m/fj3BwcE0a9aMGjXK7wy4Ws5ARETEGiUqZuzq169P/fr1nZXFq0UERhAVHIW/j7/VUURERMqVEk2al5OTw9SpU/npp584duwYubm5eb7+888/Oy1gaWnSPBEREe/j8uUMhgwZwtSpU+nevTtNmzbFMIwSBRUREREprRIVMzNnzuTzzz+nW7duzs4jIiIiUiwlGpodEBBA3bp1nZ3Fq3205iM6TevE23+8bXUUERGRcqVExcxTTz3Fm2++SRlfo7JY9iXtY/HexWw7uc3qKCIiIuVKiW4zLVu2jEWLFvHdd9/RpEkT/P3zjuCZM2eOU8J5E8fQbE2aJyIi4lYlKmYiIyO54447nJ3Fq9lnAM7M1aR5IiIi7lSiYmbKlCnOzuH17DMAq2VGRETEvUrUZwYgOzubH3/8kffff5+zZ88CcPjwYVJSUpwWzptoBmARERFrlKiY2bdvH82aNeO2227j0Ucf5fjx4wC89tprDB8+3GnhsrOzef7556lVqxbBwcHUrl2bf/3rX/km6fMEjttMWptJRETErUo8aV6bNm1Yv349UVFRju133HEHgwcPdlq4V199lffee49p06bRpEkTVq1axaBBg4iIiGDIkCFOO48zBPsHE+QXhJ9PqVaIEBERkWIq8WimX3/9lYCAgDzba9SowaFDh5wSDOC3337jtttuo3v37gDUrFmTGTNmsGrVKqedw1nubno3dze92+oYIiIi5U6JbjPl5uaSk5OTb/vBgwcJDw8vdSi79u3b89NPP7F9+3YA1q9fz7Jlyy4583BGRgbJycl5HiIiIlJ2laiYufnmm5k4caLjuWEYpKSk8OKLLzp1iYORI0fy97//nYYNG+Lv70/Lli0ZOnQof//73wt9zbhx44iIiHA8EhISnJZHREREPE+JVs0+fPgwnTp1wtfXlx07dtCmTRt27NhB5cqV+eWXX4iJiXFKuJkzZzJixAhef/11mjRpwrp16xg6dCgTJkxgwIABBb4mIyODjIzzI4qSk5NJSEhw+arZm45t4pkfnyE2LJYPb/3QZecREREpD4qzanaJihmAc+fOMWPGDNasWUNubi6tWrWib9++BAcHlyh0QRISEnjmmWd49NFHHdteeuklpk+fztatW4t0jOJcjNJYfmA57T5uR52Kddj5xE6XnUdERKQ8KM7v7xIPvQkODua+++7jvvvuK+khListLQ0fn7x3wnx9fT16aLbmmREREXGvEhUzn3zyySW/3r9//xKFuVjPnj15+eWXqV69Ok2aNGHt2rVMmDDBpQVUSdknzdM8MyIiIu5VottMFStWzPM8KyuLtLQ0AgICCAkJ4dSpU04Jd/bsWV544QXmzp3LsWPHiI+P5+9//zv//Oc/8w0LL4y7bjNtO7GNhu82JCIwgjPPnHHZeURERMoDl99mOn36dL5tO3bs4OGHH2bEiBElOWSBwsPDmThxYp6RU57KvjaTWmZERETcq8RrM12sXr16jB8/3uNm5nUX9ZkRERGxhtOKGbB1zj18+LAzD+k17H1mDAyyc7MtTiMiIlJ+lOg20zfffJPnuWmaJCYm8s4779CuXTunBPM2lYIrkf1CNr4+vlZHERERKVdKVMzcfvvteZ4bhkF0dDQ33HADb7zxhjNyeR3DMPA1VMiIiIi4W4mKGU+c58UqXcbOu+w+C17o7oYkIiIi5VOJJ82T/DbmvkEO52hsPE6AEWF1HBERkXKhRMXMk08+WeR9J0yYUJJTeKVj/E4O56jPfQSgYkZERMQdSlTMrF27ljVr1pCdnU2DBg0A2L59O76+vrRq1cqxn2EYzknpJXzwJ4dz5KC5ZkRERNylRMVMz549CQ8PZ9q0aY7ZgE+fPs2gQYO47rrreOqpp5wa0lv4EkwWyeSQbnUUERGRcqNE88y88cYbjBs3Ls+yBhUrVuSll14qt6OZAPwJASCbVIuTiIiIlB8lKmaSk5M5evRovu3Hjh3j7NmzpQ7lrfwIBSCbNIuTiIiIlB8lKmbuuOMOBg0axBdffMHBgwc5ePAgX3zxBffffz+9evVydkav4aeWGREREbcrUZ+Z9957j+HDh9OvXz+ysrJsB/Lz4/777+f11193akBvcr5l5pzFSURERMoPwzRNs6QvTk1NZdeuXZimSd26dQkNDXVmNqcozhLiJXHhpHnZ5jl88MPH8M+zjybNExERKZ7i/P4u1UKTiYmJJCYmUr9+fUJDQylFXVQm+BnB+QoZERERca0SFTMnT57kxhtvpH79+nTr1o3ExEQABg8eXG6HZYuIiIg1SlTMDBs2DH9/f/bv309ISIhje58+ffj++++dFs7bnDb/ZGPuG+w2P7c6ioiISLlRog7AP/zwAwsWLKBatWp5tterV499+/Y5JZg3SucEiSyiotmM2kZvq+OIiIiUCyVqmUlNTc3TImN34sQJAgMDSx3KW50fmq15ZkRERNylRMXM9ddfzyeffOJ4bhgGubm5vP7663Tq1Mlp4byNJs0TERFxvxLdZnr99dfp2LEjq1atIjMzk6effpo///yTU6dO8euvvzo7o9fQpHkiIiLuV6KWmcaNG7Nhwwbatm3LzTffTGpqKr169WLt2rXUqVPH2Rm9xoW3mcr7MHURERF3KXbLTFZWFp07d+b9999nzJgxrsjktey3mUyyySUTX8pv/yERERF3KXbLjL+/P5s2bcIwDFfk8Wp+BAO266J+MyIiIu5RottM/fv356OPPnJ2Fq9nGD50NKZzkzGXQKOi1XFE3Mc04eRJq1OISDlVog7AmZmZfPjhhyxcuJA2bdrkW5NpwoQJTgnnjQKMCKsjiLjX8uUwbBisWAEjRsD48eBTqpVSRESKpVjFzO7du6lZsyabNm2iVatWAGzfvj3PPrr9JFJO7N0LI0fC5xfMeP3661C5Mjz9tGWxRKT8KVYxU69ePRITE1m0aBFgW77grbfeokqVKi4J5432mV+TbO4kwehGpNHI6jgizmea8K9/wbhxkJEBhgH33w9XXAGffAIPPmh1QhEpZ4pVzFw83Pi7774jNVVzqlzopLmWE6yiEs2IRMWMlEEpKbBjB2Rmwg03wIQJ0Ly57WuPPAK+vuf3TU2Fi25Di4g4W6lubGsulfw0C7CUeeHhMH067NkDP/54vpCBvIXMG2/A1VdDVpb7M4pIuVKsYsYwjHx9YtRHJi/b8GwVM1IO1Khhu8VUkNRUeOUV2LQJ5sxxby4RKXeKfZtp4MCBjsUk09PTeeihh/KNZppTjn94OVpmzFT7lDMiZUNODowaBQ88APXqXXrf0FB44gkYPdrWQtO7d+GFj4hIKRWrZWbAgAHExMQQERFBREQE/fr1Iz4+3vHc/ijP/AzdZpIyauZM22ildu1sHX8v5+GHITAQVq60Dd8WEXGRYrXMTJkyxVU5ygz7+kxZWmxSypLsbLAvXzJ0qK1IuZyYGLj3XvjwQ1sn4XbtXBpRRMovzWzlZOoALGXSp5/aRjBFRcHjjxf9dUOH2j7OnQu7d7skmoiIihkni+EaOhj/paXxT6ujiDhHVpZtXhmwTYYXHl701zZpAl262Oameest1+QTkXLP44uZQ4cO0a9fP6KioggJCaFFixasXr3a6liF8jOCCDQq4msEWB1FxDk++cTWqhIdDY8+WvzXjxhh6zT8j384P5uICCVcm8ldTp8+Tbt27ejUqRPfffcdMTEx7Nq1i8jISKujiZQf775r+zhyZMkmwLvxRttDRMRFPLqYefXVV0lISMjT8bhmzZrWBSqCLDOFneZ0csmgic8Qq+OIlE5Ojm2W35QUGDDA6jQiIgXy6NtM33zzDW3atOFvf/sbMTExtGzZkg8++OCSr8nIyCA5OTnPw71MDvAth1hIrpnt5nOLOJmvL/z737B9u20BydJYtw769YPZs50STUTEzqOLmd27dzN58mTq1avHggULeOihh3jiiSf45JNPCn3NuHHj8sx5k5CQ4MbE4PvX0GyAbA3PFjlv7lzbqKhL/P8VESkJjy5mcnNzadWqFa+88gotW7bkwQcf5IEHHmDy5MmFvmbUqFEkJSU5HgcOHHBjYvAxfPElCNDwbPFyJ07AggW2BSWd4a67bB9//BHS9H9DRJzHo4uZuLg4GjdunGdbo0aN2L9/f6GvCQwMpEKFCnke7mafOE/FjHi1OXPglluga1fnHK9pU9t6Tunp8NNPzjmmiAgeXsy0a9eObdu25dm2fft2atSoYVGiojk/cZ5uM4kXs6+xdvPNzjmeYUDPnrbPv/nGOccUEcHDi5lhw4bx+++/88orr7Bz504+++wz/vOf//BoSea6cCO1zIjXO3PmfOvJHXc477j2YubbbyE313nHFZFyzaOLmSuvvJK5c+cyY8YMmjZtytixY5k4cSJ9+/a1OtolnS9m1DIjXmrePNt6TI0bQ4MGzjtuhw4QFgZHjoAHT34pIt7Fo+eZAejRowc9evSwOkaxNDWGAQb+FGPadxFPYr/F5MxWGbAtUHnLLbBhA5w86dxji0i55fHFjDcKNCpZHUGk5NLS4LvvbJ/36uX840+bBiEhl99PRKSIPPo2k4hYYPFiOHfONvKoZUvnH1+FjIg4mVpmXOCUuYGj5nIqGHWoajhpJIiIu3TtCuvXw+HDthFIrpKRAcePQ7VqrjuHiJQLaplxgbPs4QDfcsJcY3UUkeIzDLjiClvfFlf56ivb8ggPPOC6c4hIuaFixgU0z4zIZTRoYFu88uef4exZq9OIiJdTMeMCmmdGvNaECbbFIJcsce15GjaEOnVsSyUsXOjac4lImadixgXOt8yomBEv88UXtsUgd+927XkMA2691fb5//7n2nOJSJmnYsYF/HWbSbxRSgqsXGn7vFMn15/PPhvwvHmQk+P684lImaVixgV0m0m80rJltll/a9SAmjVdf7727SEiwjaiae1a159PRMosFTMuYL/NlMM5TFN/cYqXWLTI9tEdrTIA/v5w/fW2zxcvds85RaRM0jwzLuBPGO2M9/4qalQvipdwdzEDMGgQtGsH3bu775wiUuaomHEBw/AlFE0EJl4kOfn8wo/uLGacvfaTiJRLKmZEBA4dsk2Ul5oKCQlWpxERKRYVMy6yz/yGc2YiCYaaz8ULNGpk64SbkeH+cx89Cj/9ZJsRuHNn959fRLyeOnS4SKK5iP38jzQOWx1FpOgCA91/zunToW9feOst959bRMoEFTMuouHZ4jUyMiDNwu/Tjh1tH5cu1XwzIlIiKmZcRMWMeI3vv4eKFWHgQGvO36IFVKhg64S8bp01GUTEq6mYcREtNileY9Ei2xpJwcHWnN/XV/PNiEipqJhxEUfLjKliRjycFfPLXMx+bhUzIlICKmZcxN4yk6XbTOLJTpyADRtsn9v7rljBfu5fflG/GREpNhUzLuJn2PvMqGVGPNiSJbaPTZpATIx1OZo3t63TlJwMf/5pXQ4R8UqaZ8ZF4rmBaKMN/kRYHUWkcJ5wiwls/Wa+/hrq1YP4eGuziIjXUTHjIgFGBAEqZMTT2fuoWF3MAHToYHUCEfFSKmZEyivThPvus83vct11VqcRESkx9ZlxkQzzNDtz/8vO3E+tjiJSMMOAJ5+EuXMhOtrqNDbvvAO33KL5ZkSkWFTMuEg2KexmFvv5xuooIt7jhx9gwQLbWk0iIkWkYsZFzk+adw7TNC1OI1KA77+H3bttt5s8hX2ItuabEZFiUDHjIvZJ8yCXlMwUS7OI5JOZCXfcAXXqwPbtVqc5z953Z/lyyM21NouIeA0VMy7iQyAGvgAkZyRbnEbkImvWQHo6REVB/fpWpzmvRQsICYFTp2DrVqvTiIiXUDHjIoZhOG41JWUkWZxG5CK//mr7eO21to7AnsLfH66+2vb5smXWZhERr6Gh2S7kRzBZJJOUrmJGPIy9mGnf3tocBWnfHn7+2VbM/OMfBe7SZey8yx5mwQvdnZ1MRDyUihkXUsuMeCTTPF/MtGvnttMWuQBp1852q8mTWoxExKOpmHGhZsYIDOD6GtdbHUXkvF274NgxCAiA1q2tTpPfDTfAmTO2W04iIkWgYsaFwowEAEL8Qy6zp4gb2Vtl2rSBoCBrsxTETz+WRKR49FNDpLzp0QO+/NLWMuPpMjIgMNDqFCLi4VTMuNBJcz2nzY3M2w7d66szoniIqCjo1cvqFAWy96upd2gHT3/5Bhn+gTz28JsWpxIRT+dVQ7PHjRuHYRgMHTrU6ihFcspcz25msmDXAqujiHiVk+GVqH7iILWP7CEkPc3qOCLi4bymZWblypX85z//4YorrrA6SpH5GSFgajSTeJDff7etf9S58/n5XJygKCOViuNUhSgSK1Yh7vRRGh7cypq6rZx6fBEpW7yiZSYlJYW+ffvywQcfULFiRavjFJljaLbmmRFP8dVX8OKL8MEHVie5rD+rNwag6b7NFicREU/nFcXMo48+Svfu3bnpppsuu29GRgbJycl5HlYJoAIAx1KPWZZBJA8L5pcpqU01mgDQeL+KGRG5NI+/zTRz5kzWrFnDypUri7T/uHHjGDNmjItTFU0Q0QAcSD5gcRIRbCOD7P+PPHHm34vYW2YaHdyGb042Ob4e/+NKRCzi0S0zBw4cYMiQIUyfPp2gIs6HMWrUKJKSkhyPAwesKyTsxczhs4fJysmyLIcIYFtcMiMDoqOhXj2r01zWgcrVOBscRlBWBnWO7LY6joh4MI/+U2f16tUcO3aM1hfMUpqTk8Mvv/zCO++8Q0ZGBr6+vnleExgYSKCHzEsRQAQ++JNrZnHo7CFqRta0OpKUZ/aFGz1tcclCmD4+LGrWAf/sLDL8PeP/tIh4Jo8uZm688UY2btyYZ9ugQYNo2LAhI0eOzFfIeBrD8KEN45j5eC8SKiRYHUfKOy/qL2P3bo+HrY4gIl7Ao4uZ8PBwmjZtmmdbaGgoUVFR+bZ7qkijIbUq1rI6hgjY/zDwgv4yIiLF4dF9ZkTEibZts/Wb8cTFJS/BJyeHeod2UCFVUxyISME8umWmIIsXL7Y6QrEkmTt4/ufnqVOxDoNaDrI6jpRnfn7QsqXVKYrt5f++SKvd65hw2xMsaN3Z6jgi4oHUMuNiKezh5aUv8/nmz62OIuKVtlWrD0DTfX9anEREPJWKGRcLIgaA/Un7LU4i5dott8CgQXDwoNVJis0+eZ6KGREpjIoZF7PPNbM/aT+maVqcRsqlY8dgwQKYOhVCQ61OU2ybExqRY/gQf/oIUcknrI4jIh5IxYyLBVEZgJTMFM6kn7E2jJRPy5fbPjZpAl60tpldWlAIu2NtIwLVOiMiBVEx42K+RiDRIedbZ0Tczj5ZnhcPybbfamq2V8WMiOTndaOZvFFGWgRwnIH/+ZIYo+A+Cwte6O7eUFJ+eOFkeRfbWLMpd/z+jVpmRKRAKmbcIIgYktlJOsetjiLlzblzsHq17XMvbpnZWKMJU2/ox8aa3jFZpoi4l4oZN6hvDKI+9xFElNVRpLxZuRKysiAuDmrWtDpNiSWHRjCj491WxxARD6Vixg1CjDirI0h5lZICjRtD06ZesbikiEhJqJgRKcu6dbM9cnKsTlJqQRnnaLNzNbGnj/FF+15WxxERD6Jixg0yzST2md+QTSqNfB6yOo6URx6+wnxRRKQl88Ks8WT7+PK/tt3ICAiyOpKIeAgNzXYDk1z2MIsDzCPXzLY6jpQX585BZqbVKZzmaGQMxyKi8cvNodGBrVbHEREPomLGDQKIwAd/wCSDk1bHkfJi2jSIjIQnn7Q6iXMYBptqNAagmYZoi8gFVMy4gWH4OGYCPqfh2eIuv/5qa50JD7c6idNsrGEbmq35ZkTkQipm3MS+RlM6xyxOIuVGGZj592L2mYAbHdiKX3aWxWlExFOomHET++rZmjhP3GLfPti719bx9+qrrU7jNPujE0gKqUBgdib1Du+0Oo6IeAgVM27iaJkxVcyIGyxebPt45ZVl6jbThf1m6iWqmBERGw3NdpMgIxpM9ZkRN1m0yPaxY0dLY7jClJsG8F7Xf3AsMsbqKCLiIVTMuEkVrqWScYWWNBDXM83zxUynTtZmcYED0QlWRxARD6Nixk38jTD8CbM6hpQHOTnw6KOwZIlXr5QtIlJU6jMjUtb4+cHTT8O8eRAaanUal7hy+0rGTB9Dr1/nWh1FRDyAihk32mN+wcbcN0g1D1kdRcSrRSed4OrtK7lm6x9WRxERD6Bixo2Omr+SyCJSOWh1FCmrTBM+/xwOle2CeW2dFgA0OriVwMx0a8OIiOXUZ8aNgogmmR2aOE9cZ+dO6NMHAgIgKQmCSr8YY5ex85wQzLkSK8ZyJLIKsWeO0mzfn6yq19rqSCJiIbXMuJHmmhGXs49iuvpqpxQyHsswWFu7OQAtd62zNouIWE7FjBsFG/YlDVTMiIuU4SHZF1tb569iZvc6a4OIiOVUzLiRvWVGE+eJS5Tx+WUutq6WrZipc2QPESlnrA0jIpZSnxk3Or/YpIoZcYGtW+HoUdvtpauusjqNyyWFRbK1an0y/AOJSEsmKSzS6kgiYhEVM25kX2wyk9Pkmtn4GLr84kT2Vplrrinb/WUuMPSBf2P6qIFZpLzTb1M3CiCC9saHBBGlQkacz764ZDm4xWSnQkZEQMWMWxmGQQixVseQsuqtt6BXL2jVyuokblchNYlsXz/SgsrmjMcicmn6s0akrIiNhbvvhvr1rU7iVkO/fovZr/al48ZfrI4iIhZRy4ybJZs72Wd+TQAVaODzgNVxRLzesQhbx/qWu9cz/8quju1FmexvwQvdXZZLRNxHLTNulk0aiSziKMutjiJlyciRMH48HDlidRK3W1u7BQAtdq/HyM21NoyIWELFjJtVoB7gQzrHSTdPWB1HyoLUVHjzTRg1Ck6dsjqN222rWp/UwGAqnDtLnSO7rY4jIhbw6GJm3LhxXHnllYSHhxMTE8Ptt9/Otm3brI5VKn5GMOHUACCJ7RankTLhp58gIwNq1YJGjaxO43a5vr6s/2sCvbbbV1qcRkSs4NHFzJIlS3j00Uf5/fffWbhwIdnZ2XTu3JnU1FSro5VKBA0ASDK3WpxEyoRvv7V97NEDDMPaLBb5raFtksBrt/xucRIRsYJHdwD+/vvv8zyfMmUKMTExrF69muuvv96iVKUXYTTkoPk9Z/DuVibxAKaZt5gpp/5o0JYcw4d6ibuIOXOMY5ExVkcSETfy6GLmYklJSQBUqlTJ4iSlE/lXy0wyOx0zAWvkhZTI2rWQmAihodChg9VpLJMUGsHM6//GoaiqJAeHWx1HRNzMa4oZ0zR58sknad++PU2bNi10v4yMDDIyMhzPk5OT3RGvWEKoij8VCKQSmZx2rNkkUmz2VpnOnSEw0NosFvvkxnutjiAiFvGaYuaxxx5jw4YNLFu27JL7jRs3jjFjxrgpVckYhg8dmIaP4W91FPF2587ZWmXK8S0mERGP7gBs9/jjj/PNN9+waNEiqlWrdsl9R40aRVJSkuNx4MABN6UsHhUy4hTjxsGJE/D3v1udxCPEnjrCXcu+pM2O1VZHERE38uiWGdM0efzxx5k7dy6LFy+mVq1al31NYGAggV7U3K7Vs6XUyskK2UVx87qf6Ld4BssaXcOqeq2tjiMibuLRv0UfffRRPvvsM77++mvCw8M58tfsphEREQQHB1ucrnRyzSxWmc+RzE6uZyoBRgWrI+WjTske7vhxiFZ/qwstb3Q1/RbPoM3ONQRmppMRoEJPpDzw6NtMkydPJikpiY4dOxIXF+d4zJo1y+popeZj+JNJMrlkkqQh2lJcGRlQu7ZtkrzDh61O4zF2xdbmSGQMQVkZtNy93uo4IuImHt0yY5qm1RFcKpIGpHGQJHMb0caVVscpkaK03oBacJzul18gJQWSkmyrZYuNYfBbw6u54/dvuHbLb/z+12R6IlK2eXTLTFkXYfw1E7BaZqS47EOyu3cHH/03vtDyRlcDcPW2Ffjk5FicRkTcQT8FLRRBQ8BWzJimVvuVItKsv5e0qXoTkoPDiUhLpsn+zVbHERE3UDFjoTBq4EMg2aSRykGr44i3WLMGdu+2jWK68Uar03icXF9ffm/QlnT/QOJPJVodR0TcwKP7zJR1PoYvEWY9TrOJJLYSRnWrI4k3mDbN9vH22yEsrMSHKWp/J2/08c0DeafHwxrNJFJOqJixWGWjDX5mGAFcfr0pdbYVMjNhxgzb5/37W5vFg50Or2h1BBFxIxUzFqtl3AWG1SnEa/j6wvTpMGcO3Hyz1Wk8n2kSe/ooRyppxJdIWaY+MyLexNcXunSB998HP/0tcimh51KYNPkJPnz7ISJSk6yOIyIupGLGQ6SZRzhm/mZ1DJEyIzU4jBwfX/xzsrlx3c9WxxERF1Ix4wGSzV0sMwez0ZxAtpludRzxVNOnw9NPwzbNS1RU37XuAsAta36wDWkXkTJJ7dQeIJzaBBPHORI5xq/Eo+G2UoA334RVq6BaNWjQwOo0XmFxsw48+P2H1Dh+gMb7t7C5RuM8X9f6YyJlg1pmPIBhGFQ1bAXMIXOhxWnEI23ebCtk/Pzg73+3Oo3XSAsKYUnT6wDouuYHi9OIiKuomPEQttYYg9NsIs08YnUc8TT2uWW6d9dK2cX0/V+3mq7ftJSQ9FSL04iIK6iY8RBBRjRRtADgsPmjtWHEs+Tk2PrLgOaWKYHNCQ3ZF12doKwMrvvzV6vjiIgLqM+MB4k3buKkuZbD/EQd8+8Yhq/LzlWWZ38tc378EQ4fhkqVbC0zUjyGwUc3D8A0fFhVr5XVaUTEBVTMeJAYrsGPULJIIZXDhJFgdSTxBJMn2z7+/e8QGGhtFi/1R8OrrI4gIi6kYsaD+BoBtOZfhFEDX0Nrygi24cTNmsGSJfDoo1anKRMCsjLI9FdRKFKWqJjxMBGGhtzKBQwDxo6FUaMgJKTIL9NtxAKYJr2XfkHvX7/k6YGvsDuuttWJRMRJ1AHYQ+WaOZwxNTma/KUYhYwUwjCofXQP4edSGPDTf61OIyJOpJYZD5RlnmWV+Typ7Oca3iHUqFqs1+uv8jLi5Zfh6qvhhhtsLTRSav/t1Jfr/1zG1dtX0mj/FrZUb2R1JBFxArXMeCA/wgggglyy2GK+i6lp2MufzZvhhRfgpptgxw6r05QZhypX5YcWNwEw6MdPtMSBSBmhYsYDGYZBI+MRfAjgFBtIZJHVkcTdXn7Z9ov2jjugfn2r05Qpn3a8m0xfP5rv3UjL3eutjiMiTqBixkOFGLHUMWzT1m8zPyTTTLY4kbjNtm0wc6bt8xdesDZLGXQ8MoZ5V3YFYKBaZ0TKBPWZ8WA1uINEFpPCPnaYU2hiDLE6krjDyy9Dbi7ceiu0bGl1mjJp5vW96br6B+od3kntI3suObKpqH3QtCCliHVUzHgwH8OPxjzGCnMEh1hInHkDlYxmVscqEa1OXERr18Knn9o+V6uMy5wJq8iE24ewK642BytXszqOiJSSihkPF2k0opp5CynsI4AIq+OIK2VnQ79+tlaZu+6CNm2sTlSmLWl2vdURRMRJVMx4gQbGA/jgj2Goi1OZ5ucHr70Gzz9/fgkDcYumezcRkJ3Fmrq6rSfijVTMeAFfI+/U64fNn4iiNYFGpDWBXES3orAtJNmtm+aVcaPWO1YzdvoYzgaH8fAjb3OqQpTVkUSkmFTMeJkD5ndsMd8ljJq04WUCjPJ166lMFjynTkFaGlT7q++GChm32lDrCvZUqUndI7sZ+eUbjBowllwf161YLyLOp2LGy1TiCgKpRAp7WW0+TyvGlrkWmnLFNOHhh+GHH+C//4UePS77Es3w7FxZfv6M6/0077w3lBZ7NtBn6RfM6NDH6lgiUgzqhOFlQo2qtDFeJoBIzrKH5eYjHDGXWR1LSmrqVPj8c0hJgSpVrE5Tbh2sXI13uj8MwL2LPqW5JtMT8SoqZrxQqJHAlcY4wqhJFslsMMezIfdVMs0kq6NJcXzyCQwebPv8n/+EK6+0Nk8592OLG/ixeSd8c3MZO30MV239w+pIIlJEus3kpUKNBK7m/9htzmIPn3OEZSTQU8O3vcXkyfDII7bP77sPnn0W0C0kSxkGb976GKHpqVyzbQX1D+/kj4ZXWZ1KRIpAxYwX8zH8qWv0I8a8mtP8SUWjseNrJ8zVVKQZvkaAhQmlQP/+N4wYYfv8iSfg//4PfNRI6gky/QMZe/ezdNq4hB+b32B1HBEpIv0ELQMqGHWpYdzmeJ5qHmKNOZql5n3sMmeQbp6wMJ3kkZsLv/9u+/zZZ2HiRBUyHibH148fW9zoGFUWmJlOzz++xS87y+JkIlIYtcyUQekcJ4jKpHOcXean7OJTKpj1qWJcSwzXEGpUtTpi+ZOVBf7+tsLls89g7lzooxEzns7IzeW5z1/lqu0rue33//Fet3+wql7rAvctk9MGiHgJ/UlYBkUZLWhvfEgzYwSRNAYMktnODnMqv5oPctJc69g3x0zH1KrBrnPqlK1vTMeOtlYZgIAAFTJewvTx4afmHTkdGknCyUO8/N8XGf3ZWOJOJVodTUQu4BUtM5MmTeL1118nMTGRJk2aMHHiRK677jqrY3k0H8OXODoQZ3QgwzzNMX7nmLmcJHb8VeDY7DCnkcgSws3ahFGdMKM6oVQnjAT8CMMowxO4ufQv6f37YcYMeP11OHnStm3xYrhB/TC8zZJmHVhZrw39Fs/gtt//xzVb/6D1jtUsuqIj89p0ZVtCA6sjipR7Hl/MzJo1i6FDhzJp0iTatWvH+++/T9euXdm8eTPVq1e3Op5XCDQqkkBXEoyu5JiZeToFJ7GDLJI5xTpOsQ4uaKTxI5SOTMfH8AfgmPkH2aQQSCUCqEgAkfgTjo/hWbOlWjYi6PRpmDnTVsQsXXp+e5Mm8M47ttYZ8UppQaH855bBfNe6Cw/P/w+td62ly9ofOVi5mqOYCcxMJ8fHl2w/f4vTipQ/hunh9xiuuuoqWrVqxeQLFt5r1KgRt99+O+PGjbvs65OTk4mIiCApKYkKFSo4PZ+3D6XNNbM4y25S2EeKuZ8UbI8MThBARTr6/Nex78rcZznNhnzH8COEACJpZ7zvaMnZb/6PNDMRP0LwNYLwJQhfgvElEF+CiDbOrwidYZ4il2x88P/rEYAPfh6xsGaBLTNZWXDkCGzbBmFhdFloa3mpe3gn7743FIBcw2Bjjab81LwTP7a4gRxfj/+7QYrKNGm6709u2LCYGdf35nhkDAA9Vszjwe8+YE9sLbbH12N71bociqrK8YhoToVVLHKRo341IjbF+f3t0T9hMzMzWb16Nc8880ye7Z07d2b58uUWpbrArl2021x4js0JjTgdXhGAKqePUjdxV6H7bq1Wn5MVKgMQnXSc+od2FLrv9vi6jh+glc6eotGBrYVHjK3NkUqxAESknKHp/s2F7BnGnipdORxl6xwcnHaCWodWUDHr/PtLiw4lMagWKb4pJAWcI90nBYBs0gjMhvY7fzufMeE79ofutz25qFz2zfXln9tHOp5/VnU228Lzv18j1wc/04dntw/H56/uXfOqLGBn6G58TB9yfQLI8g/BwAcf04eIc6n0398Hf9P2S2N5xZXsCd2Hj2mQ5RfE2ZBIDHwwMIg7dYzbD3UkJMcP39xc1kVuZXfoIXxzTc4FhpJYKR7w4akFP2F8O49n91Sl0sFTcPgw30ccZ2l18DHBaNSInTEtMAyDXbEw+K4EGp1rz5qGXTgRUZnT5ibOMBdM++06A4Pzt+7i6ESgYfseSTJ3cIbN+faxi+Eaggzb98hZc+9f+zquluPoAFG0ItiwfY+kmoc4zaYC9rWpyBWEGLbvkTTzyEX75vkXoSKNCDHiAUg3T3CqgOLWLoL6hBq29aYyzNO2lr9ChFOXMCMBgEwzmZOsKfD8AGHUINyoCUCWmcIJVhd63FASqGDUBiDbPMcJVha6bwjxVDDqApBjZnKcwifNS6oRw6aajwGQa2ZzjN846PMbXzXMBnZA2g4SdkD17VAtGa46ZPDQo++wN7o6R/mVpvv+pNaRPWT4B5Lt60+2ry85Pr6E5YTBO3ugXz+IjGTOljnk7N4JBw78NbrKAB/bxxi/CDqENYGbb4bISL7Z9g2Z+3bDwYMXXDLbNavoG8qNYVdAhw4QFcX8HfNJ27/Ldjv0IhV8gukc3gLat4eYGBbsXMDZgzthz97819cnkK7hreCaayAujp92/8SZgztgV/6fdYGGPz0qtLFNDpmQwJK9SzhxcBvsyP9/3xcfbo+4Clq1gpo1WbZ/GUcPbYOtBf+suzPiGrjiCqhbl98P/s6hQ1tgc8E/626r0Ba/pldAgwasPLSS/Yc3w6aCv+d7hLchsHEzaNyYtYlr2X34T9hQ8OzQt4S3JLR+U7jiCjYc3cCOw5tg3doC9705rDkV6jSGVq3YfHwzWxI3wupVAPn+73cKa0rFmo3gyivZfnI7m45sgBUrCjzudaGNiK7eCK6+ml2ndrH+6Przoycvcm1IA2KrNoD27dl7Zi9rEtfAypWQk5Nv36tC6lE1tj506MDB5IOsOLQCVq+2/WEHNG7SkYZtuxV4Hnfx6GLmxIkT5OTkUOWiad6rVKnCkSNHCnxNRkYGGRkZjudJSbZZcZOTk50f8MsvGTrzlUK//K8+ozhepyUADbet4LH57xe676u9nuRow6sBqL1rLUO/eqvQfSf2fJTEZh0AqL53E0Nnv1bovu/dMpiDrToDEH9g6yXzTrmxH/uvuhWA2MSDjPnvpDxfH3rB559d35vP291BFilEn9rBsLmv0fzY+WNHN4MdleBsAGyumsD22DhyyMQ3J5n6h3bnyfHHnbCnNmRedLfKJJdsM5cnZ453bFt1B6ywd1HI+evxlzM+8OjsNwj+a9ufPWBb0wsOmH7+08QQ+GL+ZqLO2Z4P6wxLW124r+0X5ITFQBgMXLodv7++heY1g3fa2nfcAulbHC/bVRfaGm0IM0IgPY3juavYyxcUJtyo51gV/bi5kt3mZ4XuG2zE4meEALZ5hHaYUwrd9wrjGfyNMABOmmvZar5X6L5NjGEEGLa/ek6bm/jTnFjovg2NR4j/ay2wM+YWNpkTCt23nnE/CUYlAJLNHWw03yh03zpGP4IM2/feWXMPG81/F7pvLeNvjkItxTzARvP1QvetTk9CfO4FIM08ygaz8P8rVelMAx/bjMwZ5hk2mK8Wum8sHWnsYyu+ss1zbDBfZUNjuKA7msOt2+C/B02OBASTnZ5mm7E7BojJv2/nXZD8+Hxo1w7q1KHvZ31Jz07PvyPQfh/MmwH8+is0bcrAWQM5fe50gfu2SoRF04CFC6FtWx788kEOJh0scN+GJ+CPD4Gvv4aOHXniqyfYfnJ7gftWPwMb38N2a7VbN4b/bzjrjqwrcN+oNNj9FvDhh/C3v/Hsd8+yfH/BfwyGZEHiG8Dbb0P//oxZMIYfd/9Y4L4ASeOBV1+Fhx5i3I/j+GbbN4Xum/hvCHn2n/DUU0xYMoGZG2cWuu/uNyHqsRHw/PO8u+xdPlrzUaH7bpwE1fs9AuPG8cHyD3hnxTuF7vvHB9Cw50B4800++eMTXv218O+1RVOh1fW94YMPmLl6Ji8uerHQfed9Cu2b94BPP2XOujk8vfDpQved/Tl0rnkDzJ3L/I3zeXT+o4XuO20u3F7xaliwgB+3/Migrwbl+frzO1cyomH7Ql9fUvbf20W6gWR6sEOHDpmAuXz58jzbX3rpJbNBgwYFvubFF180sbUF6KGHHnrooYceXv44cODAZesFj26ZqVy5Mr6+vvlaYY4dO5avtcZu1KhRPPnkk47nubm5nDp1iqioqDI9MsfTJCcnk5CQwIEDB1zSV0kKp2tvHV176+jaW8OV1900Tc6ePUt8fPxl9/XoYiYgIIDWrVuzcOFC7rjjDsf2hQsXcttttxX4msDAQAIDA/Nsi4yMdGVMuYQKFSroB4tFdO2to2tvHV17a7jqukdERBRpP48uZgCefPJJ7r33Xtq0acM111zDf/7zH/bv389DDz1kdTQRERHxAB5fzPTp04eTJ0/yr3/9i8TERJo2bcr8+fOpUaOG1dFERETEA3h8MQPwyCOP8Mgjj1gdQ4ohMDCQF198Md8tP3E9XXvr6NpbR9feGp5y3T1+0jwRERGRS7F+ilURERGRUlAxIyIiIl5NxYyIiIh4NRUzIiIi4tVUzEiJTJo0iVq1ahEUFETr1q1ZunRpofvOmTOHm2++mejoaCpUqMA111zDggUL3Ji2bCnOtb/Qr7/+ip+fHy1atHBtwDKsuNc+IyOD5557jho1ahAYGEidOnX4+OOP3ZS2bCnutf/0009p3rw5ISEhxMXFMWjQIE6ePOmmtGXHL7/8Qs+ePYmPj8cwDL766qvLvmbJkiW0bt2aoKAgateuzXvvFb42nNOUfgUlKW9mzpxp+vv7mx988IG5efNmc8iQIWZoaKi5b9++AvcfMmSI+eqrr5orVqwwt2/fbo4aNcr09/c316xZ4+bk3q+4197uzJkzZu3atc3OnTubzZs3d0/YMqYk1/7WW281r7rqKnPhwoXmnj17zD/++MP89ddf3Zi6bCjutV+6dKnp4+Njvvnmm+bu3bvNpUuXmk2aNDFvv/12Nyf3fvPnzzefe+4588svvzQBc+7cuZfcf/fu3WZISIg5ZMgQc/PmzeYHH3xg+vv7m1988YVLc6qYkWJr27at+dBDD+XZ1rBhQ/OZZ54p8jEaN25sjhkzxtnRyrySXvs+ffqYzz//vPniiy+qmCmh4l777777zoyIiDBPnjzpjnhlWnGv/euvv27Wrl07z7a33nrLrFatmssylgdFKWaefvpps2HDhnm2Pfjgg+bVV1/twmSmqdtMUiyZmZmsXr2azp0759neuXNnli9fXqRj5ObmcvbsWSpVquSKiGVWSa/9lClT2LVrFy+++KKrI5ZZJbn233zzDW3atOG1116jatWq1K9fn+HDh3Pu3Dl3RC4zSnLtr732Wg4ePMj8+fMxTZOjR4/yxRdf0L17d3dELtd+++23fP9WXbp0YdWqVWRlZbnsvF4xA7B4jhMnTpCTk5Nv1fIqVarkW928MG+88Qapqan07t3bFRHLrJJc+x07dvDMM8+wdOlS/Pz0372kSnLtd+/ezbJlywgKCmLu3LmcOHGCRx55hFOnTqnfTDGU5Npfe+21fPrpp/Tp04f09HSys7O59dZbefvtt90RuVw7cuRIgf9W2dnZnDhxgri4OJecVy0zUiKGYeR5bppmvm0FmTFjBqNHj2bWrFnExMS4Kl6ZVtRrn5OTwz333MOYMWOoX7++u+KVacX5vs/NzcUwDD799FPatm1Lt27dmDBhAlOnTlXrTAkU59pv3ryZJ554gn/+85+sXr2a77//nj179miBYjcp6N+qoO3OpD/VpFgqV66Mr69vvr+Ijh07lq8av9isWbO4//77mT17NjfddJMrY5ZJxb32Z8+eZdWqVaxdu5bHHnsMsP2CNU0TPz8/fvjhB2644Qa3ZPd2Jfm+j4uLo2rVqkRERDi2NWrUCNM0OXjwIPXq1XNp5rKiJNd+3LhxtGvXjhEjRgBwxRVXEBoaynXXXcdLL73kstYBgdjY2AL/rfz8/IiKinLZedUyI8USEBBA69atWbhwYZ7tCxcu5Nprry30dTNmzGDgwIF89tlnum9dQsW99hUqVGDjxo2sW7fO8XjooYdo0KAB69at46qrrnJXdK9Xku/7du3acfjwYVJSUhzbtm/fjo+PD9WqVXNp3rKkJNc+LS0NH5+8v958fX2B860E4hrXXHNNvn+rH374gTZt2uDv7++6E7u0e7GUSfZhkh999JG5efNmc+jQoWZoaKi5d+9e0zRN85lnnjHvvfdex/6fffaZ6efnZ7777rtmYmKi43HmzBmr3oLXKu61v5hGM5Vcca/92bNnzWrVqpl33XWX+eeff5pLliwx69WrZw4ePNiqt+C1invtp0yZYvr5+ZmTJk0yd+3aZS5btsxs06aN2bZtW6vegtc6e/asuXbtWnPt2rUmYE6YMMFcu3atY1j8xdfePjR72LBh5ubNm82PPvpIQ7PFc7377rtmjRo1zICAALNVq1bmkiVLHF8bMGCA2aFDB8fzDh06mEC+x4ABA9wfvAwozrW/mIqZ0inutd+yZYt50003mcHBwWa1atXMJ5980kxLS3Nz6rKhuNf+rbfeMhs3bmwGBwebcXFxZt++fc2DBw+6ObX3W7Ro0SV/fhd07RcvXmy2bNnSDAgIMGvWrGlOnjzZ5TkN01Sbm4iIiHgv9ZkRERERr6ZiRkRERLyaihkRERHxaipmRERExKupmBERERGvpmJGREREvJqKGREREfFqKmZERETEq6mYERGP0bNnz0IXIf3tt98wDIM1a9YA8I9//ANfX19mzpyZb9/Ro0djGEa+x48//ujS/CJiDRUzIuIx7r//fn7++Wf27duX72sff/wxLVq0oFWrVqSlpTFr1ixGjBjBRx99VOCxmjRpQmJiYp7H9ddf7+q3ICIWUDEjIh6jR48exMTEMHXq1Dzb7cXL/fffD8Ds2bNp3Lgxo0aN4tdff2Xv3r35juXn50dsbGyeR0BAgBvehYi4m4oZEfEYfn5+9O/fn6lTp3LhsnGzZ88mMzOTvn37AvDRRx/Rr18/IiIi6NatG1OmTLEqsoh4ABUzIuJR7rvvPvbu3cvixYsd2z7++GN69epFxYoV2bFjB7///jt9+vQBoF+/fkyZMoXc3Nw8x9m4cSNhYWGOR9u2bd35NkTEjVTMiIhHadiwIddeey0ff/wxALt27WLp0qXcd999gK1VpkuXLlSuXBmAbt26kZqamq9zb4MGDVi3bp3j8eWXX7r3jYiI26iYERGPc//99/Pll1+SnJzMlClTqFGjBjfeeCM5OTl88sknzJs3Dz8/P/z8/AgJCeHUqVP5OgIHBARQt25dxyMhIcGidyMiruZndQARkYv17t2bIUOG8NlnnzFt2jQeeOABDMNg/vz5nD17lrVr1+Lr6+vYf+vWrfTt25eTJ08SFRVlYXIRsYJaZkTE44SFhdGnTx+effZZDh8+zMCBAwHbLabu3bvTvHlzmjZt6njceeedREdHM336dGuDi4glVMyIiEe6//77OX36NDfddBPVq1fn6NGjzJs3jzvvvDPfvoZh0KtXr0LnnBGRss0wLxz/KCIiIuJl1DIjIiIiXk3FjIiIiHg1FTMiIiLi1VTMiIiIiFdTMSMiIiJeTcWMiIiIeDUVMyIiIuLVVMyIiIiIV1MxIyIiIl5NxYyIiIh4NRUzIiIi4tVUzIiIiIhX+388kXw54z1CVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of data\n",
    "NV = data[:,0]\n",
    "DP = data[:,1]\n",
    "VAF = NV/DP\n",
    "plt.hist(VAF, bins=30, density=True, color='steelblue')\n",
    "\n",
    "# Plot densities\n",
    "x = np.linspace(torch.min(VAF), 1, 100)\n",
    "num_components = 2\n",
    "n = torch.mean(DP)\n",
    "\n",
    "density1 = beta.pdf(x, n*probs_bin[0], n*(1-probs_bin[0])) * weights[1]\n",
    "plt.plot(x, density1, linewidth=1.5, label=f'Beta1', linestyle='--', color='r')\n",
    "density2 = pareto.pdf(x, alpha_pareto, scale = torch.min(VAF)) * weights[0]\n",
    "plt.plot(x, density2, linewidth=1.5, label=f'Pareto', linestyle='--', color='g')\n",
    "\n",
    "plt.title(\"Beta-Pareto mixture model\")\n",
    "plt.xlabel('VAF')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd069c",
   "metadata": {},
   "source": [
    "Using K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c615aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 12135873.0\n",
      "Iteration 100: Loss = 5437715.0\n",
      "Iteration 200: Loss = 4983635.0\n",
      "Iteration 300: Loss = 4991059.5\n",
      "Iteration 400: Loss = 7214270.0\n",
      "Iteration 500: Loss = 4057910.5\n",
      "Iteration 600: Loss = 4157029.0\n",
      "Iteration 700: Loss = 3780703.25\n",
      "Iteration 800: Loss = 3729275.5\n",
      "Iteration 900: Loss = 3719068.25\n",
      "Iteration 1000: Loss = 3730468.75\n",
      "Iteration 1100: Loss = 4717405.0\n",
      "Iteration 1200: Loss = 3740127.75\n",
      "Iteration 1300: Loss = 3810319.0\n",
      "Iteration 1400: Loss = 3761866.75\n",
      "Iteration 1500: Loss = 3797735.75\n",
      "Iteration 1600: Loss = 3769837.0\n",
      "Iteration 1700: Loss = 3795896.25\n",
      "Iteration 1800: Loss = 3776173.5\n",
      "Iteration 1900: Loss = 3759757.5\n",
      "Iteration 2000: Loss = 3808933.75\n",
      "Iteration 2100: Loss = 3714008.75\n",
      "Iteration 2200: Loss = 3719598.0\n",
      "Iteration 2300: Loss = 3715442.75\n",
      "Iteration 2400: Loss = 3743003.25\n",
      "Iteration 2500: Loss = 3789244.25\n",
      "Iteration 2600: Loss = 3749779.75\n",
      "Iteration 2700: Loss = 3748694.5\n",
      "Iteration 2800: Loss = 3740845.0\n",
      "Iteration 2900: Loss = 3788058.5\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "pyro.clear_param_store()\n",
    "# svi = pyro.infer.SVI(binom_model, binom_guide, pyro.optim.Adam({\"lr\": 0.001}), pyro.infer.TraceEnum_ELBO())\n",
    "svi = pyro.infer.SVI(binom_pareto_model, binom_pareto_guide, pyro.optim.Adam({\"lr\": 0.01}), pyro.infer.TraceGraph_ELBO())\n",
    "num_iterations = 3000\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(data, K=2)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration {}: Loss = {}\".format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ba2c847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_param tensor([0.1447, 0.2189, 0.6364], grad_fn=<DivBackward0>)\n",
      "probs_param tensor([0.1781, 0.4926], grad_fn=<ClampBackward1>)\n",
      "alpha_param tensor(5.0964, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "baaa039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of success binomial component:  [0.17814167 0.49264684]\n",
      "Alpha pareto:  5.0964003\n",
      "Mixing proportions:  [0.14466944 0.21890073 0.6364298 ]\n"
     ]
    }
   ],
   "source": [
    "# Extract the learned parameters\n",
    "probs_bin = pyro.param(\"probs_param\").detach().numpy()\n",
    "alpha_pareto = pyro.param(\"alpha_param\").detach().numpy() \n",
    "weights = pyro.param(\"weights_param\").detach().numpy()\n",
    "\n",
    "print(\"Probabilities of success binomial component: \", probs_bin)\n",
    "print(\"Alpha pareto: \", alpha_pareto)\n",
    "print(\"Mixing proportions: \", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "128e470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of data\n",
    "NV = data[:,0]\n",
    "DP = data[:,1]\n",
    "VAF = NV/DP\n",
    "plt.hist(VAF, bins=30, density=True, color='steelblue')\n",
    "\n",
    "# Plot densities\n",
    "x = np.linspace(torch.min(VAF), 1, 100)\n",
    "n = torch.mean(DP)\n",
    "\n",
    "# Sample from beta and pareto distributions with the learned parameters\n",
    "density1 = beta.pdf(x, n*probs_bin[0], n*(1-probs_bin[0])) * weights[1]\n",
    "plt.plot(x, density1, linewidth=1.5, label=f'Beta1', linestyle='--', color='r')\n",
    "density2 = beta.pdf(x, n*probs_bin[1], n*(1-probs_bin[1])) * weights[2]\n",
    "plt.plot(x, density2, linewidth=1.5, label=f'Beta2', linestyle='--', color='b')\n",
    "density_pareto = pareto.pdf(x, alpha_pareto, scale = torch.min(VAF)) * weights[0]\n",
    "plt.plot(x, density_pareto, linewidth=1.5, label=f'Pareto', linestyle='--', color='g')\n",
    "\n",
    "plt.title(\"Beta-Pareto mixture model\")\n",
    "plt.xlabel('VAF')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ba4cc",
   "metadata": {},
   "source": [
    "### Multidimensional binomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a9eb27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "# m_example : [NV_s1, NV_s2]\n",
    "# DP is fixed inside the model\n",
    "d1 = torch.ones([1000, 2])\n",
    "d2 = torch.ones([2000, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aef41f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3000, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 26.],\n",
       "        [ 8., 26.],\n",
       "        [10., 30.],\n",
       "        ...,\n",
       "        [54., 82.],\n",
       "        [63., 89.],\n",
       "        [72., 95.]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[:,0] = dist.Binomial(total_count=100, probs=torch.tensor([.1])).sample([1000]).squeeze(-1) # S1 for component 1\n",
    "d1[:,1] = dist.Binomial(total_count=100, probs=torch.tensor([.3])).sample([1000]).squeeze(-1) # S2 for component 1\n",
    "\n",
    "d2[:,0] = dist.Binomial(total_count=150, probs=torch.tensor([.4])).sample([2000]).squeeze(-1) # S1 for component 2\n",
    "d2[:,1] = dist.Binomial(total_count=150, probs=torch.tensor([.6])).sample([2000]).squeeze(-1) # S2 for component 2\n",
    "\n",
    "m_example = torch.concat((d1,d2))\n",
    "print(m_example.shape)\n",
    "m_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9356fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  90.],\n",
       "        [ 62.,  78.],\n",
       "        [ 51., 103.],\n",
       "        ...,\n",
       "        [ 13.,  23.],\n",
       "        [ 11.,  22.],\n",
       "        [  4.,  28.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle elements\n",
    "idx = torch.randperm(m_example.shape[0])\n",
    "m_example = m_example[idx]\n",
    "m_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9903c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "print(100*0.2)\n",
    "print(150*.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a1d4df7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24060fcf620>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDs0lEQVR4nO3de3RU9bn/8c8kIROCSSAgmUQgBIuFGC+IiiiIpwpHpdbWdWrrhcLRw6JeWlBbEa0FtJBCW+tpaalSf16gSH/9KYqVWmJVLhUFQRQIRcUQEYgpBJNAbpDZvz9wj5lkZjJ7smdmz+T9WitrmT17dr47M3Eevt/neb4uwzAMAQAAOEhKvAcAAADQHgEKAABwHAIUAADgOAQoAADAcQhQAACA4xCgAAAAxyFAAQAAjkOAAgAAHCct3gOIhNfr1YEDB5SVlSWXyxXv4QAAgDAYhqH6+noVFBQoJSX0HElCBigHDhzQwIED4z0MAAAQgX379mnAgAEhz0nIACUrK0vSyRvMzs6O82gAAEA46urqNHDgQN/neCgJGaCYyzrZ2dkEKAAAJJhw0jNIkgUAAI5DgAIAAByHAAUAADgOAQoAAHAcAhQAAOA4BCgAAMBxCFAAAIDjEKAAAADHSchGbQCA7qPVa2hTRY2q65vUPytDFxblKjWFfdiSHQEKAMCxXtlxUHNfKtfB2ibfsfycDM2+plhXluTHcWSINpZ4AACO9MqOg7pt2Va/4ESSqmqbdNuyrXplx8E4jQyxQIACAHCcVq+huS+VywjwmHls7kvlavUGOgPJgAAFAOA4mypqOsyctGVIOljbpE0VNbEbFGKKAAUA4DjV9cGDk0jOQ+IhQAEAOE7/rAxbz0PiIUABADjOhUW5ys/JULBiYpdOVvNcWJQby2EhhghQAACOk5ri0uxriiWpQ5Bifj/7muIu90Np9RrauOewXty2Xxv3HCbp1kHogwIAcKQrS/K1+ObzOvRB8djUB4UeK87mMgwj4cLFuro65eTkqLa2VtnZ2fEeDgAgiqLRSdbssdL+A9C86uKbzyNIiQIrn9/MoABADNCuPXKpKS6NPr2vbdfrrMeKSyd7rIwv9vAaxREBCgBEGUsJzmKlx4qdgRGsIUkWAKKIdu3OQ4+VxECAAgBRQrt2Z6LHSmIgQAGAKKFduzPRYyUxEKAAQJSwlOBMseqxgq4hQAGAKGEpwbnMHiueHP/fvScngxJjh6CKBwCixFxKqKptCpiH4tLJD8REW0pIlpLpK0vyNb7YE7V7SZbfU7wQoABAlJhLCbct2yqX5BekJOpSQrKVTNvdY8WUbL+neGCJBwCiKJmWEiiZDg+/J3vQ6h4AYiDRp/tbvYbGLHgtaFWSuVy1YebXEuq+7MbvKTRa3QOAwwRaSrAjaAl2DbsDIrqvhoffk30IUAAgDuzIUQh2jW+ck69V7x20Nf+Bkunw8HuyDzkoABBjduQoBLvGwdomPbauwvb8B0qmw8PvyT7MoABADIW7k26Wu4cOHWsOuDwT6hrBmNees2qnsjJ66NDRZktLQuGUTOdlu+U1DL24bX9c82zime+TrKXl8UCSLADE0MY9h3XDkrcsPaf98kwk1wh17XCXhF7ZcVDfX7Y16LV6Z/bQ5w3HQ14j2pxQ3mvObkmBS8sTrXrLTlY+v1niAYAYiiT3oP3yjJ35C3YuCbUNTiK9Rlc4pbw3mUrL44klHgCIoUhyD9ou/Ywv9sQkf6H9z9QX/92Va0RzmSXcpbNoj8MU7S613QEBCgDEgJkXUVXbqNxe6TpyrMVyDsnB2iY99c8K5Z7iVm6vHqo5drzT53VF+92WQ5XPhnONaJbVhlve+9Q/K9Qvyx2TgCFaXWq7CwIUAIiyQHkRkXr45V02jMgaO5aUol1WG+712/7+aD3vbOSgAEAUBcuLSCT9szK6vKwU7WWpSK5P63lnI0ABgCgJpxw4t1cP/fo75+rpKRfEbFxWpLikkYV9NLKwjyJdDTGvEU2RjM98Xea+VK5Wb8IVtCY9lngAIEo6y4uQpJpjx+XJzlD5gdoYjcoaryHduXzrFz1OIr/Gb/7xoS75Sr+oteLfUnkkovHRet65CFAAIEqstD2vrGmI8mgit6b8sy5fY9HrH2nR6x/FvRV/tJ4P+7HEAwBRYqXteWFuZpRH4wzxbsUfrefDfsygAMAXrCw7hHOulbbnIwv7aN7qXREvoyS6UG3+JXW6Y3O/U9zyZLv1WV2zpfLtYK3nY7VLNIIjQAEAWWuRHu65qSkuzb6mWLct2yqXArc9n31NsVJTXEpNcWnq2CI9tq4iCneXGMx8kJueeNt3rHdmD0nq0EI/0DJR78weloIT82ear4EplrtEIziWeAB0e1ZapFttp26l7fmIQaErXcwPa6fJz8nQtEuLlJ9j/zLJ5w3HO7TQD7ZM1P68SMR6l2gEx2aBALq1Vq+hMQteC1ptYy4BbJj5NUkK+9z20/6dLQ2EO45f/tc5enPPIf3ujT2W79VON48apAuKcgMuf6z/sFq/f+PjuI4vXFZe33CuwXJPaFY+v1niAdCthdsiPZx276FKVgO1PW9sadX81eXae7hBGWkpYV37lZ0HVeWApm8793+uzZVHNKhPT511Wo5Oyfjy48TlSpwPafP3+uuy3eqTmW5rO/+WE14t3bhXlTUNKszN1KTRg5WeFt2Fi2TKkbEcoKxbt06/+MUvtGXLFh08eFArV67UN7/5Td/jhmFo7ty5evzxx3XkyBGNGjVKv/vd73TmmWf6zmlubtaPfvQjPfvss2psbNTll1+u3//+9xowYIAtNwUA4bJSCmznNac+s1ll5dVhX9O09K1PLD8nGt79tE6StLuqXiVz/q7Cvj3VcsJI2I65i17v+oxU29e9dHW5lqyv8Et6nrd6l6aOLdKsq4u7/LMCsZJHlQgsh3LHjh3TOeeco0WLFgV8fOHChXrkkUe0aNEibd68WR6PR+PHj1d9fb3vnBkzZmjlypVasWKFNmzYoKNHj+rrX/+6WltbI78TAIiAlVJgK+eGEmlw4mSVhxsTNjixi/m6l64u12PrKjpUZHkN6bF1FSpdbW1X6HBYzY1KBJYDlKuuuko/+9nPdN1113V4zDAMPfroo3rggQd03XXXqaSkRE8//bQaGhq0fPlySVJtba2eeOIJ/epXv9IVV1yhESNGaNmyZdq+fbteffXVrt8RAFhglgIHmwR36eS/Qi8sytW5A3uHdc1Q5zW2tCZdcIIv2/m3nPBqyfrQlVhL1leo5YTXtp8dakuFSNr5t3oNbdxzWC9u26+New7HbRsAWxfDKioqVFVVpQkTJviOud1ujRs3Tm+++aYkacuWLTp+/LjfOQUFBSopKfGd015zc7Pq6ur8vgDADmYpsKQOQUr7UuDlb1eGdc1Q582Pwr+eEX9e42S7/aUb93bay8ZrSEs37rXtZ1vNowrllR0HNWbBa7phyVuavmKbbljylsYseC0uMzC2BihVVVWSpLy8PL/jeXl5vseqqqqUnp6uPn36BD2nvdLSUuXk5Pi+Bg4caOewAXRz4ZYCh9uOPtR5ew87t6U9usbKlgV2bm1gVx6V05aJolLF0z6D2zCMTrO6Q50za9Ys3X333b7v6+rqCFIA2OrKknyNL/aErIAY2Ce8dvShzhvcN1PrP+zycOFA/U5x2/IescqO3KjOlonMLr/jiz0xqwqyNUDxeDySTs6S5Od/mTFcXV3tm1XxeDxqaWnRkSNH/GZRqqurdfHFFwe8rtvtltvttnOoALoBq+3KA5UCtzXMkxXWzw10nvkzzx7QW5IzKnFgM6Nr75FIWdlSIRgry0Sx2vXZ1gClqKhIHo9HZWVlGjFihCSppaVFa9eu1YIFCyRJI0eOVI8ePVRWVqbrr79eknTw4EHt2LFDCxcutHM4ALqxaLQrr2loCetntz8v0FiQfA4daw773HDfS+GwsqVCMNEot+8qywHK0aNH9dFHH/m+r6io0LZt25Sbm6tBgwZpxowZmj9/voYOHaqhQ4dq/vz5yszM1I033ihJysnJ0a233qp77rlHffv2VW5urn70ox/prLPO0hVXXGHfnQHotsy19Pb/mjTblbdnrrG3bz3fXiRT6cHGguRjZUdku3dPNvOo2gfCnjCDb7tK6O1kOUB555139B//8R++783ckMmTJ+upp57Svffeq8bGRt1+++2+Rm1r1qxRVtaX01m//vWvlZaWpuuvv97XqO2pp55SamqqDbcEoDsLtZYeTLhr7Fan0iMZCxJP29e91WsoxaWQlTxmSbLdwsmjCsaOZSK7sRcPgKSycc9h3bDkrYifP+miQXK5XEFbk4eaEXFJ+u13z9Vn9c2qrGmQYRiO6fyK6HFJvtm3cN9/D04crn5Zbr8gIh6t8dsy39tS4GWizmYYw2Hl85sABUBSeXHbfk1fsc2Wa6W4FLA1ebBOsIV9e2pfTWOnfTCQePJzMpSe5lLl4cYOj509IFur7hwrKbL3X35OhkpOy9Y/dlX7vXeCvf+iKdrt8tksEEC3ZecaudmaXJLvQ6J0dXnQTrCBPryQuCZdNEjnDz65Y/MTG/bo1V3/Dnje+5/Waeozm7XkexdE9P47WNsUMIE60Psv2rqyTGQ3AhQACaWz3Vo7W0uPxOPrKnS0uVWDcnt22sYcyeNrZ/RXXcsJtbS0Bg1OTGXl1WpsaY3K+2/J+grdM2FYzJZ7Oiu3jxWWeAAkjHCnn4OtpQPRNOmiQXr4m2fplR0H9f0v3n92eXDicN06doit14wHK5/fscu+AYAusNKGO1jr+vycDE27tEj5ObErlUT3Ec1tDOxsjZ8oWOIB4HiRtOEOtZZ+75XDfcff2VtDpQ1sMbhvpu+9arfTeve0/ZpOR4ACwPEibcMdbC297fGrSvL1p7c/ofIGXXbc69WcVTui0jE49imq8ccSDwDHi2Yb7vS0FE0dW2T5eUB7KzZ9GrXZuE8/734VYgQoABzPiW24gVgqzLVv9+NEwRIPgLjqrGxYirwNdzjXbjnhpXQYMWO+V2+5ZLD2HWlUfk6GFryyu9Pn3Tiq0O/7cN7biY4ABUDchFs2HMlureFee+nGveSfIGYMSY3HWzVv9b8sPW/bvs99eVPR7vbqFCzxAIgLK2XDUvDSYU9ORoc9QqxcuzuWbyK+Pm84bvk5Zn6V1b+bRMYMCoCYi6RsWAqvDbfVaw/s0/3W9pF4+p3ijvjvJlERoACIuXDLhp/6Z0WHHV87a8NttSR5WF5WF+4EiI1/fnRI/zpYF/HfTSIiQAEQc+GWAz/88i7ff4e7xm61JLmmsSWs84F4+v0be8I+N5K/GyciBwVAzEVSDhzuGrvVkmRKk5HMEjk3hQAFQMyZZcNWJp7Ndfe5L5WrNUDZTavX0MY9h1VV26jcXulBr+3SyX9Ver2GXty2Xy0trWH9/KH9e+myM/pZGDEQf5393TgZSzwAYi5U2XAowVraByq7DMT8WY3HW3XTE29bGvOH1cf0YfUxS88BnCDY343TMYMCIC6ClQ2Ho22eSbCyy0B6Z/aQFFmZJxBtmempUb1+JFtBxBMzKADipn3Z8KH6Zr8Ev2DMvJFQZZem3F499ODXz1T/LLfu+b/b7Bk4EKZJFw2Sy+XSab17asEr/wrZFLDpeKuW3nKhNn58SL9/4+NOr/3A1cPVP9tt+e8mUTCDAiCuzLLha889TVMuKQqZm2Lmj5gt7TsrKZakmmPH5cnOUIrLpaq6ZnsHDwRhvlcHfbGHzjt7azrtWOw1pA8+q9clXzk1rJ9RXJAd0d9NoiBAAeAYZm6K1HF7+UAt7a2UFCfa9DYSm6GTFTTzVv9Lz2ysVNmu6rCeV1nToENHwwukzfOs/t0kCgIUAI5ipaW9lZLiRJveRuKLpGamMDczot27rfzdJApyUAA4Tjgt7SVruxy3nPDGZOxApFJc0qTRg5Wa4opo9+5w/24SBQEKAEcK1tK+5YRXSzfuVWVNgwpzM/XAVcP1gxXvdrrL8fK3K2MxbCBiU8cWKT3t5MJGZ7t333/1cD31zwrf38Gk0YOVnpbS6VYQiYQABUDCKF1driXrK/ySDVNc0hXF/bVjv/8+JZ52Lb7ZtRhOleI6GZzMurrYd8xcsmnf38eTk6GS07I1fcW7fn8H81bv6nCNREeAAiAhlK4u12PrKjoc9xpSWXm1po4t0teG5QWd2i7MZddiOMf44f2V37un3+xHe4GWbF77V5WWrN/b4VyvId/fR7IEKS7DMBKr962kuro65eTkqLa2VtnZ2fEeDoAoaznh1bAH/xayTDPFJf3r4asC/o9ekhpbWjX8p69EaYSANU9OPl91zScs5YnY8XcQb1Y+v5lBAeB4SzfuDauHxNKNe3Xr2CEBH9+273P7BwZE6L+ffsf33+HuOGzH30EicWaIBQBthJs/Euo8+qDAqcLdcdiOv4NEQoACwPEG9gkvfyTUefRBgVOFu+NwuHlUyZJvRYACwPGGebK6fJ7ZMyUxO0Ig2bXdcTiYSaMHq7NUFbOXSlutXkMb9xzWi9v2a+OewyGDICchBwWA49U0tHT5PLMdeKDeEoBThFqKTE9L0dSxRQGr2Uxte6lIJ3f7bl+qHG7OS7wxgwLA8SJp/R1IsHbggFN09h4eMahP2I+/suOgblu2tcOGmuHmvMQbMygAHM9KS/u2jjad0F1/flefHGnUoD499evvjOjQW6J3zx6a/OTmmNwHEIxLUl62W17D0Ivb9gcsP271Gpr7UnnIa8x9qVzjiz3SF/8d6O/FaHeuU1vhE6AAcLxQyzPBdmv9xqL1ev/TOt/3u6vqVTLn7zp7QLZW3TnW1w78ifUfR/8GgBDM93TTCa9u+uPbvuPtl2I2VdR0mA1pq30eS7jnOrU1Pks8ABKCld1a2wcnbb3/aZ2+sWi97/tkKclE4srJ7CFJ+rzhuN/x9ksx4ZbKV9c3WTrXqZhBAZAwwtmt9WjTiaDBien9T+t0tOmETslIS5qSTCSWBycOV78st/r1cuuev7wn6XiHc9ovxdiVixXpubHGDAqAhGLu1nrtuadp9Ol9O6yf3/Xnd8O6jnleOKWbgF1cOrl0M+WSIl177mlKSXGpqi68pZjOSuXNa19YlGvpXKciQAGQVD450mjpPLN0E4gFQ/75UlaWYsxcLEkdAo/2uVhWznUqAhQASWVQn56Wz/v40LFoDQcIyeqyjZVcLCvnOhE5KACSyq+/M0Ilc/7e6Xk3XjhIL27br949e6isvDoGIwO+zCnJcvfQoWPNyu2ZrhSXOt2heGThl/1NwsnFiuRcp3EZhpFwDRWtbNcMoPsJVcUjSWkpLp1IkHbfgCQ9O/Uix5YDW2Hl85slHgBJZ9WdY3X2gOD/8yM4QaJxcjlwtLDEAyAprbpzrF8n2YF9MrT901p9Vh/evj6Akzi5HDhaCFAAJK2e6am6ZcwQVdc36VB9s17d9e94DwmwJNg2Di0nvFq6ca8qaxpUmJupSaMH+20SmAwIUAAkpUC7uAKJJFg5cOnqci1ZX+GXWDtv9S5NHVukWVcXx3aQUUSAAiDpmLu42pFp4k5LUfMJrw1XAqzxtNuLRzoZnDy2rqLDuV5DvuPJEqQQoABIKuaOr1aDk5O7yWbo8uGn6pOaRg3um6n7ry5WelqKr0QzNzNd3/s/m2wJfJB8fvlfZ+vUU9ya/JT13bHN3Yx/df25OnS0OWA5cMsJr5as7xictLVkfYXumTAsKZZ7CFAAJJXOdnwNxPwI+OnXi9WnV7qvX0T7/8l/8Fk9wQmC2vDRIZ11Wk7Ez5/zjTN1yVf6BX186ca9IfulSCdnUpZu3Ktbxw6JeBxOQYACIKlEUo7pycnQN87J18Mv++es9A6yyywQyAvbDuiFbQcieu4Vxf077ewa7s7bybJDNwEKgKQSbjmmuZts/6wMHTnWrDuWv9thdsTuwOTBicO1Y3+tVkb4IYbkVVZerdLV5SHzR8LdeTtZdugmQAGQVMxdXKtqmwIux5hlm1MuKVJqikutXkNjFrwW1aWbtj+ztuE4AQoCWrK+QmNOP1U1jS0Bc1AmjR6seat3ddoWf9LowdEfbAwkfhYNALRhdRfXSHJWrGq7g+3M596L6s9C4vIa0qQnN2n6im26YclbGrPgNb2y46Dv8XB23p46tigpEmQlAhQAScjKLq6xbiH+yZHGmP48JK6q2ibdtmyrX5Ay6+piTbu0SO33+ktxSdMupQ8KADheuLu49jvFHfWxmDvYji/2aGCfntpdVR/1nwlnMHOd3tlbo6VvfWLpuYb83zvme3fW1cW6Z8IwOskCQFKLQd2wIelgbZPmrNohr5emb91B+1ynq0ry9ae3P+m0TLg9872zqaLGbzfj9LSUpCglDoUABUBSCtTqPj9AZ85Dx5pjNiar/4JGYgqU62TmjwTqAhuO7ribcXLNBwGAvmx13z75NdCafnfcJRbRFSjXSQqePxKO7vg+ZQYFQFIJ1eo+0Jr+yMI+SnHJ8tQ7YHJJyu2Vrp9MHC5PTs+AuU6m9vkjA/tk6o/r96i6viVkWXz73Yy7A9tnUE6cOKGf/OQnKioqUs+ePTVkyBA99NBDfuuuhmFozpw5KigoUM+ePXXZZZdp586ddg8FQDfUWdlw2zV9SdpSeYTgBBEzw5B53yrRt84boNGn9w0anJjM/JGHri3R1EuHaO61JX7Xan/t9rsZdxe2BygLFizQH/7wBy1atEi7du3SwoUL9Ytf/EK//e1vfecsXLhQjzzyiBYtWqTNmzfL4/Fo/Pjxqq8nsx1A14S7Vm+eZ3VtPz8nQ+OL+0c0TY/EleKSxhf3V34YpetWWSmL705sX+LZuHGjrr32Wk2cOFGSNHjwYD377LN65513JJ2cPXn00Uf1wAMP6LrrrpMkPf3008rLy9Py5cs1bdo0u4cEoBsJt2zYPC/ctf07/+MruuQr/XzT9y0nvL5p+uMnvHp2876Ix4zInTcwR70yeqiqtlEfVh+z9dqTLhokl8vlV8bb6jU6LV2PRLhl8d2J7QHKmDFj9Ic//EEffPCBzjjjDL333nvasGGDHn30UUlSRUWFqqqqNGHCBN9z3G63xo0bpzfffDNggNLc3Kzm5i8z7evq6uweNoBkEe5yzRfnhdsa/67xZ/h9WKSmuFRckKN+WW69tG1/V0eNCPXpla7T+mTqtN4ZtgUo5ms+5xslHQKE1BSXX7lvJIIFOYGuHezcaAVKTmJ7gDJz5kzV1tZq2LBhSk1NVWtrq+bNm6cbbrhBklRVVSVJysvL83teXl6eKisrA16ztLRUc+fOtXuoAJJQuGXD5nlma/zblm2VS/7xTbAcgEAlzIiPf/zr37Zfs+3WBHYLt/w91LnfOCdfq947GNY1EpntOSh//vOftWzZMi1fvlxbt27V008/rV/+8pd6+umn/c5zufxfeMMwOhwzzZo1S7W1tb6vffuYSgUQWLhLNm3Ps5IDEKyEGeiMlfL3YOcerG3SY+sqwrpGorN9BuXHP/6x7rvvPn33u9+VJJ111lmqrKxUaWmpJk+eLI/HI+nkTEp+fpv9MKqrO8yqmNxut9zu6LejBuB8nU1th7tk075sM5wcgFAlzEgeZil6lruHDh1rtmUJxUr5u774byvvs2Bt8ROZ7QFKQ0ODUlL8J2ZSU1N9ZcZFRUXyeDwqKyvTiBEjJEktLS1au3atFixYYPdwACSRcKbHI1myMXWWXxCLnY8Rf2Yp+k1PvO071tUlFKvl75G8z4K1xU9Uti/xXHPNNZo3b55efvll7d27VytXrtQjjzyib33rW5JOLu3MmDFD8+fP18qVK7Vjxw5NmTJFmZmZuvHGG+0eDoAkYWV6PFplm92x3ThO6uoSipXy966+z5LlfWr7DMpvf/tbPfjgg7r99ttVXV2tgoICTZs2TT/96U9959x7771qbGzU7bffriNHjmjUqFFas2aNsrKy7B4OgCRgtTusFJ2yzXDzW8YP76+mE15lpKWobFd1p+dPKM5TXrY7KfbqOS3HrV4ZafrgM3tLfuOtq0sokeRGRSpZ2uLbHqBkZWXp0Ucf9ZUVB+JyuTRnzhzNmTPH7h8PIAlZmR5vO7VtR0loW+Hmt0y5uEiHjjWr3ylubd9fq8/qmkOev/jmkZKkV3dVB712orj49L7qc4pbH3wW2aZ4ThbsfRZOya/V3KhQ5waTbG3x2YsHgONZ7Q4bLZ3ltxiSGo+3+uUu9M7s4fvXd2f5MLOvKdb3l22N5i1E3V+2Hoj3EKKu7fss3LJhq7lRwc4NJhnb4rObMQDHi+X0eGeC5bf0zuwhSfq84bjf8dovvs/54nFTd29jnsjM95mVvCjJWm5UsHPzczI07dKiqLTcdxqXYRgJN5tYV1ennJwc1dbWKjs7O97DARBlrV5DYxa81un0+IaZX4vZvx7bTuv3O8Wte/7vNlXVBW4SZ47vl/91TtCyVfMenVYllJ2RpmvPLVBellu/LPsw3sPp4N7//Kqq6ppUkJOhn7+yO6o/q+37TFLI1yvUe9JKF9hk6yRr5fObJR4AjteV0uFojsnMQ9i453DQ4ET6MnchJcWla889LeA5Ti1hrms6oc/qmlR+wJlbjLjTUjSysI8O1YfXQThS7d9nG/ccjigvSrKWGxXsXLvzq5yIAAVAQjCnvNuv93sc0OLbjhwZu/JnUlxSyWnZ2rG/Tl6b5sfXlHdeidRV+TkZKjktW//YVW1p3A+/vCt6g2qj/fvMKXlRyYwABUDCcOqOr3bkyHQ1f+b8wt66qiTft+tu292WD37eGFa5c6w9OHG4+mW51T8rQ0eONeuO5e9GvYLpwYnDdaThuBa9/pGl8bV/nzkpLypZEaAASChOnNqOtL2+lWuEkuKSbrhgkAr6ZPo+RNPTUnTr2CGSpJYTXg178G+2zajY5cZRheqZnurLv4nm8Hwl4JcUSZKe2/pp5+XilxQFDX7teM0RGlU8ANBFZo6M9GWugincHJlQ1+iM15Du+X/v64Ylb2nMgtc6VI+kp6Vo6tgii1eNvuVvn9zBPtr5N+1fg2i/XslY8hsPBCgAYAM72uuHKi0dX9xf4XzWBStxnXV1saZdWtThGikuaXxx/w5lq7FQWdMgKfp5GlbKeO14vZKx5DceKDMGABvZUf4Z7BpmXsneww16Ydunqm9qDfj8UCWubXNTCnMzfTkr5s/886ZP9MJ7nTdbO29Qb/Vyp6kwN1Nrdh5U9dHjnT6nvQcnDtetY4do457DumHJW5af39m1g+WPtBXN1wsdUWYMAHFiR45MsGuYeSUb9xzW0rcqgz4/VIlr29yUQD/zRKs3rADlrivO0NgzTtXGPYe17G3rewiluKRJowdL6lr+TXsuSXnZbg3Lz9aho52XHgf7XVsJOpyYF5UMCFAAIMFEs8S1pqHF0nmRLs9MHVuk9LSTWQah+txYYT636YRXN/3xy+0GArWeDyXc9vWILnJQACDBRLPE1eq1rf6MFJc07dIizbq62O94sHyOXumpcoWZN5MTZLuBYHk5gVhtX4/oYQYFABJMV0pcO1u6sHrtcJZnzHb5g/v28uW8BHJlSb6+NiyvQ46MpJB5M9X1TerXy617/vKepI65MOZmjXNfKtf4Yk/IfJS5L5UHvI9wrwH7EKAAQIKJtPV/OEsXVq8dzvkL/+vssJZGAo3vjxsqNPua4pB5M5K53UBkredNnZU7h3MN2IclHgBIQFZLXK0sXVi9th3ltl1dWonldgO0r48NZlAAIEGF2/o/kqULq9sKdGUbAjuWVmK53QDt62ODAAUAElg4Ja6xWrqItNzWjvHFYrsB2tfHFgEKACS5SJYuYllqa8fSSqR5OXZfA/YhBwUAkpzVpYtYl9ratbRC+/rkwgwKACQ5K0sX8Si1tXNppSu5MHZeA13HDAoAJDkrO+9ayQeJx/jCvd7o0/vq2nNP0+jT+0YUWNhxDXQNAQoAdAPhLl3Eq9SWpRW0xxIPAHQT4SxdxLPUlqUVtEWAAgDdSGelwPEutWVnYJhY4gEA+Jj5IMH21TFEqS1igwAFAAA4DgEKAMDHLDMOxiwzbvUGm2MB7EGAAgDwiUeZMRAIAQoAwIcdfeEUBCgAAB929IVTEKAAAHzMMuNgNToundw0kB19EW0EKAAAH7vbzgORIkABAPih7TycgE6yAIAOaDuPeCNAAQAERNt5xBNLPAAAwHEIUAAAgOMQoAAAAMchQAEAAI5DgAIAAByHAAUAADgOAQoAAHAcAhQAAOA4BCgAAMBxCFAAAIDjEKAAAADHIUABAACOQ4ACAAAchwAFAAA4DgEKAABwHAIUAADgOAQoAADAcQhQAACA4xCgAAAAxyFAAQAAjkOAAgAAHIcABQAAOA4BCgAAcBwCFAAA4DgEKAAAwHGiEqDs379fN998s/r27avMzEyde+652rJli+9xwzA0Z84cFRQUqGfPnrrsssu0c+fOaAwFAAAkINsDlCNHjuiSSy5Rjx499Le//U3l5eX61a9+pd69e/vOWbhwoR555BEtWrRImzdvlsfj0fjx41VfX2/3cAAAQAJyGYZh2HnB++67T//85z+1fv36gI8bhqGCggLNmDFDM2fOlCQ1NzcrLy9PCxYs0LRp0zr9GXV1dcrJyVFtba2ys7PtHD4AAIgSK5/fts+grFq1Sueff76+/e1vq3///hoxYoSWLFnie7yiokJVVVWaMGGC75jb7da4ceP05ptvBrxmc3Oz6urq/L4AAEDysj1A+fjjj7V48WINHTpUf//73/X9739fP/zhD/XMM89IkqqqqiRJeXl5fs/Ly8vzPdZeaWmpcnJyfF8DBw60e9gAAMBBbA9QvF6vzjvvPM2fP18jRozQtGnTNHXqVC1evNjvPJfL5fe9YRgdjplmzZql2tpa39e+ffvsHjYAAHAQ2wOU/Px8FRcX+x0bPny4PvnkE0mSx+ORpA6zJdXV1R1mVUxut1vZ2dl+XwAAIHnZHqBccskl2r17t9+xDz74QIWFhZKkoqIieTwelZWV+R5vaWnR2rVrdfHFF9s9HAAAkIDS7L7gXXfdpYsvvljz58/X9ddfr02bNunxxx/X448/Lunk0s6MGTM0f/58DR06VEOHDtX8+fOVmZmpG2+80e7hAACABGR7gHLBBRdo5cqVmjVrlh566CEVFRXp0Ucf1U033eQ7595771VjY6Nuv/12HTlyRKNGjdKaNWuUlZVl93AAAEACsr0PSizQBwUAgMQT1z4oAAAAXUWAAgAAHIcABQAAOA4BCgAAcBwCFAAA4DgEKAAAwHEIUAAAgOMQoAAAAMchQAEAAI5DgAIAAByHAAUAADgOAQoAAHAcAhQAAOA4BCgAAMBxCFAAAIDjEKAAAADHIUABAACOQ4ACAAAchwAFAAA4DgEKAABwHAIUAADgOAQoAADAcQhQAACA4xCgAAAAxyFAAQAAjkOAAgAAHIcABQAAOA4BCgAAcBwCFAAA4DgEKAAAwHEIUAAAgOMQoAAAAMchQAEAAI5DgAIAAByHAAUAADgOAQoAAHAcAhQAAOA4BCgAAMBxCFAAAIDjEKAAAADHIUABAACOQ4ACAAAchwAFAAA4DgEKAABwHAIUAADgOGnxHkB30eo1tKmiRtX1TeqflaELi3IlqcOx1BRXnEcKAED8EaDEwCs7DmruS+U6WNvkO9Y7s4ck6fOG475j+TkZmn1Nsa4syY/5GAEAcBKWeKLslR0HdduyrX7BiXQyMGkbnEhSVW2Tblu2Va/sOBjLIQIA4DgEKFHU6jU096VyGWGeb54396VytXrDfRYAAMmHJZ4o2lRR02HmpDOGpIO1TXrqnxXql+UmNwUA0C0RoERRdb214KSth1/e5ftvclMAAN0NSzxR1D8rw5brkJsCAOhuCFCi6MKiXOXnZKirizNOy01p9RrauOewXty2Xxv3HHbEmAAAyYUlnihKTXFp9jXFum3ZVrmksJNlAzFzUzZV1Gj06X1tGqF1gUqmWYICANiNGZQou7IkX4tvPk+eHHuWe7qS19JVwUqmWYICANiNGZQYuLIkX+OLPdpUUaOquiY9/Nedqjl2vPMnBtDvFLfNowtPqJJpQ5JLJ5egxhd7qDgCAHQZAUqMpKa4NPr0vtq453DEwYkklR+o1aGjzX7lxy0nvFq6ca8qaxpUmJupSaMHKz3N3smxzkqmnbIEBQBIDgQoMdbVJZp5q//l++/8nAyVnJatf+yqVts81Xmrd2nq2CLNurq4Sz+rrXDHHc8lKABA8iBAiTG7So+lkzMWgWY1vIb02LoKSbItSAl33HbeHwCg+yJJNsZGFvZRrFI0lqyvUMsJry3X6qxk2qWTMzrmLs0AAHRF1AOU0tJSuVwuzZgxw3fMMAzNmTNHBQUF6tmzpy677DLt3Lkz2kNxhC2VRxSrtiFeQ1q6ca8t1zJLpoMN3ZA0+5piEmQBALaIaoCyefNmPf744zr77LP9ji9cuFCPPPKIFi1apM2bN8vj8Wj8+PGqr6+P5nAcIdY5GpU1DTH9eQAA2CFqAcrRo0d10003acmSJerTp4/vuGEYevTRR/XAAw/ouuuuU0lJiZ5++mk1NDRo+fLl0RqOY8Q6R2Ngn0xbrmOWGQdjlhnTVRYAYIeoBSh33HGHJk6cqCuuuMLveEVFhaqqqjRhwgTfMbfbrXHjxunNN98MeK3m5mbV1dX5fSUasz18VW2jcnuld7n9fbhe2PapHnxhuxpbWv3GEU6b+pYTXj2x/mP99MUdmrNqR9hlxgAAdFVUqnhWrFihrVu3avPmzR0eq6qqkiTl5eX5Hc/Ly1NlZWXA65WWlmru3Ln2DzRGArWHj5WdB+q180C9lr71ic4ekK1/17eE1aa+dHW5lqyvsJwvQ5kxAMAOts+g7Nu3T9OnT9eyZcuUkRF8OcPl8p9DMAyjwzHTrFmzVFtb6/vat2+frWOOpmDt4ePh/U/rwmpTX7q6XI+tsx6cSJQZAwDsYXuAsmXLFlVXV2vkyJFKS0tTWlqa1q5dq9/85jdKS0vzzZyYMymm6urqDrMqJrfbrezsbL+vRBCqPbwpKyNVky4q1L3/eUbMxtVW+52SW054tWR9heXruCR5st3asb9WP31xh55Y/7FtJc4AgO7H9iWeyy+/XNu3b/c79t///d8aNmyYZs6cqSFDhsjj8aisrEwjRoyQJLW0tGjt2rVasGCB3cOJq87aw0tSfVOrlr4VeGkrVtrmj5QfqLU8c2Lu1PxZfbPmrd7lOx6NjrYAgO7B9gAlKytLJSUlfsd69eqlvn37+o7PmDFD8+fP19ChQzV06FDNnz9fmZmZuvHGG+0eTlwlWj5GdX1TRGXJmempOtbSKqNdYBONjrYAgO4hLq3u7733XjU2Nur222/XkSNHNGrUKK1Zs0ZZWVnxGE7UJFo+Rm5mugpzwytLnnTRIJ0/OFe5mema/OSmkOcuWV+heyYMs30DQwBA8nIZRvt/9zpfXV2dcnJyVFtb6+h8lFavoTELXlNVbVPIPBSnuGL4qfJk99Sytz8JeZ5L0jO3XKiahha9s7dGS98Kfb4kPThxuG4dO8SmkQIAEpGVz282C4wisz38bcu2+vI0nOzVXf8O67zM9FRN+j+hZ03ao6MtAMAK5tyj7MqSfC2++Tx5chJruSeUY180fbMi3KUjAAAkZlBi4sqSfI0v9mhTRY0OHGnQj557v0NCaTJLcUmTRg+O9zAAAAmEACVCLSe8WrpxryprGlSYm6lJowcrPS1FjS2tmr+6XHsPN2hw30zdf3Wxeqan+p5XcfhYtwpOJOnWMYO1pfKIquub1D8rQxcW5bLrMQAgJJJkIxCoDXyKSxqY21OVhxs7nB+oxXx3kOKSLh/eXzv214XVXh8AkNysfH4ToFhktoFHYJMuGiSXy6XC3Ez1z87QD599t0NysDl3svjm8whSAKAboYrHZq1ew5c/8ngEbeC7A5ekvGy3BuX20r4jDfIa0s/+GrjNv/HF+XNfKtf4Yk9Yyz3ma8AyEQB0DwQonYjnTsSJJFCr+87ON9vrjz69b8hzA70GLBMBQHKjzDgEJ+1EnAgiWSzsbDuAYK9BoF2YAQDJgwAliHB2IkbXhdoOINRr0H4XZgBAciFACSKcnYgROZdOLtNcWJQb9JzOXoO2y0QAgORCgBJEou1EnEjM1NbZ1xSHTHQN9zXgtQKA5EOSbBCJthNxIvGEmeAa7mvAawUAyYcAJYgLi3KVn5ORMDsRO93MK7+qg7VNfl13O9PZa+DSyWAn1DIRACAxscQThLkTsfTlkgQit+CV3XpmY6UefnmXxv3i9bCqb0K9BuEuEwEAEhMBSgjJuBOxE1gpEQ72GnhyMuhECwBJjFb3YTC7mL7xr8/0GJ1kbWEuz2yY+TU6yQJAN0Gr+wh19iG440BtHEeXXMwS4V+X7dYlXzm104AjNcXVoeMsQQsAJC9mUL4QrJ36N87J16r3DtITJcqstq6n/T0AJB52M7bIbKeecL+IJGJlh+Ngrxe7JAOAs1n5/O72SbK0tHeGzlrXt3oNbdxzWCu3fqr7V+6g/T0AJLlun4NCS3vnCLbDsZUdpa3skgwAcK5uH6DQJt152r4mkS6/8boCQGLr9ks8tEl3HvM16cryG68rACS2bh+gmO3UKU6Nv/Y7HEey/BbOLskAAOfr9gEKLe2dw5B/63qryzS0vweA5NHtAxQpeDv1/JwMTbu0SPm0uo8Lq8s0tL8HgORBH5Q2gnUmNY8f+LxRP/p/7ynxfmOJoX37+1avoTELXgu5o3Rurx568OtnypNNJ1kAcDpa3UcoUDv1tioOHSU4iaL2JcLm8ttty7bKJfkFKWYYMv9bZzFjAgBJiAClE1Z6cMAebXNPzOW39q+Bh7b2AJDUCFBCoAV+fLTPPbmyJF/jiz1sDAgA3QgBShC0wI89MwfF6zX04rb9foFIZ8tvAIDkQoASBC3wY8vMMWk83qqbnnjbd5wdigGge6LMOAhapcdW78wekqTPG477Ha+qbdJty7bqlR0H4zEsAECcEKAE0a+XO95D6Bbu/I/T9af/GSV3WuC3IjsUA0D3RIASDPmXUeWS1LdXuk4/9RT962Cdquqag57btvwYANA9kIMSxKGjwT8w0XWGpMPHWnTX/30v7Oew7AYA3QczKEGwG67z8JoAQPfBDEoQ5i7HodqsI3ZSXNLIwj5+x4JtTRCM1fMBAPFDgBJEqDbriD2vIW2pPOLrhRKow2+okmSr5wMA4oslnhCC7XKM+DBzUMwOv+371AQrSbZ6PgAg/ghQOnFlSb42zPyanp16kX717XPkYkUgbvpnZYTs8BuoJNnq+QAAZyBACUOr11D5gVo9u+kTdjOOA5dOLsdcWJTbaYff9iXJVs8HADgDOSidKF1driXrK8Q/sOPHkDT7mmKlprjCLjU2z7N6PgDAGQhQQihdXa7H1lXEexhoI9xSY/M8q+cDAJyBJZ4gWk54tWQ9wYkTuPRlnohZ/h0sFajtcpAky+cDAJyBACWIpRv3sqzjEG3zRMzyb6njbgTm9+ZykCTL5wMAnIEAJYjKmoZ4DwHtmHkiwcq/PTkZWnzzeR36mlg9HwAQf+SgBFGYmxnvISSV+68apiMNLVq89uOIr9E2T+TKknyNL/aE3RnW6vkAgPgiQAli0ujBmrd6F8s8NnG5pNxe7sieq5OzHe3zRFJTXL7OsuGwej4AIH5Y4gkiPS1FU8cWxXsYSWPfkUbtO2J92Yw8EQDonphBCWHW1SeTK+mD0nWRLpl52C8HALoll2EkXm/Uuro65eTkqLa2VtnZ2VH/eS0nvFq6ca8qDh/Ti9sO6GjTCTYPtGjXQ1cqNcWlYQ/+LWSwl+KSnp5yoWoaW8gTAYAkY+XzmxmUMKSnpejWsUMkSWO+0o8djiOwbd/nGn16X00dWxSy+d3UsUUa+9VTYzgyAIATkYNiETscR8YsEZ51dbGmXVqk9pMiKS5p2qVFvmU1AED3xhJPhFq9hq9k9Z29NVr61idxGUeieHbqRX4VNOayWWVNgwpzMzVp9GClpxEvA0AyY4knxq4YlkeAEkKKSxpZ2MfvWNtls7baBn7koABA90WAEoFXdhzU3JfKdbCWHXDD4TWkLZVHOu1BEuj3mk8VDwB0S8ypW/TKjoO6bdlWghOLzByUYIL9Xqtqm3Tbsq16ZcfBaA4PAOAwzKBY0Oo1NPelcqp3JN144UClpabIMIywlrfatqlvL9Tv1dCXuxmPL/aw3AMA3QQBigWbKmqYOflCUb9TNPXSIWr1Gnp1V7WqapsCBhjB2tS31dnvte1uxrSqB4DuwfYlntLSUl1wwQXKyspS//799c1vflO7d+/2O8cwDM2ZM0cFBQXq2bOnLrvsMu3cudPuodius2WK7sRsW5+a4tLsa4qDzioZ6rxNfbi/V37/ANB92B6grF27VnfccYfeeustlZWV6cSJE5owYYKOHTvmO2fhwoV65JFHtGjRIm3evFkej0fjx49XfX293cOxVahliu7Gzt2ew/298vsHgO4j6n1Q/v3vf6t///5au3atLr30UhmGoYKCAs2YMUMzZ86UJDU3NysvL08LFizQtGnTOr1mvPqgtHoNjVnwWtDljO6ibTv6fr3cuucv76mqLvDshrnEs2Hm14LOonT2ew3nGgAA57Py+R31Kp7a2lpJUm7uyRyEiooKVVVVacKECb5z3G63xo0bpzfffDPgNZqbm1VXV+f3FQ/mcob05S673VFGj1RNenKTpq/YppueeDtocCL5548EE+r3ym7GANA9RTVAMQxDd999t8aMGaOSkhJJUlVVlSQpLy/P79y8vDzfY+2VlpYqJyfH9zVw4MBoDjukZG113zuzh9/3mempcrWLB8zvG1paLV+/s/yRYL9XT06GFt98Hn1QAKCbiWoVz5133qn3339fGzZs6PCYq92nn2EYHY6ZZs2apbvvvtv3fV1dXdyDlPHFHl/H00P1zXr45V1xG09XuST17JGq3916ng4da/Z1cG31Gr529AP7ZOqP6/fos/qWiH5GOPkj7X+vdJIFgO4ragHKD37wA61atUrr1q3TgAEDfMc9Ho+kkzMp+flf/qu4urq6w6yKye12y+12R2uoEUlNcflKXlu9hv64oSJhc1PMZZiUFJeuPfc03/HUFJevHf3GPYcjCk7CKTNuq+3vFQDQfdm+xGMYhu688049//zzeu2111RUVOT3eFFRkTwej8rKynzHWlpatHbtWl188cV2DycmkiU3JdQyTCQlvuSPAAAiZXuAcscdd2jZsmVavny5srKyVFVVpaqqKjU2Nko6ubQzY8YMzZ8/XytXrtSOHTs0ZcoUZWZm6sYbb7R7ODETLIciPydDZw8InKnstN17Qy3DRFLiS/4IACBSti/xLF68WJJ02WWX+R1/8sknNWXKFEnSvffeq8bGRt1+++06cuSIRo0apTVr1igrK8vu4cRUqByKxpZWzV9drr2HGzS4b6buv7pY6WkpvnPNct3P6uxZJnJJyspI0zfOLVBhbqae2LA36LXDWYa5sChX+TkZIUuB87Ld+tX15+rQ0WbyRwAAXRL1PijREK8+KNFmbpgnyfZclt6ZPfR5w3G52l3bDB/CmekINj4r1wAAdF+O6oOC8EWzhLm24bgkKaddObGVZRhKgQEAscIMigO1eg3LJcwPThyu3FPcevivO1Vz7HjAc+xahmk7PpZyAADhsvL5zW7GDmSlhNnMH5lySZE2VdQEDU6kk8syVXXNSnH5lxN3ZXwAAEQDSzwOZ6UNPLsCAwCSBQFKAgg394NdgQEAyYIlngQRThv4cEqBrXR1BQAgXghQEkhnuR/mctBty7YGLSemqysAIBGwxJNkKAUGACQDZlCSELsCAwASHQFKkqIUGACQyFjiAQAAjkOAAgAAHIcABQAAOA4BCgAAcBwCFAAA4DgEKAAAwHEIUAAAgOMQoAAAAMchQAEAAI6TkJ1kDePkNnh1dXVxHgkAAAiX+bltfo6HkpABSn19vSRp4MCBcR4JAACwqr6+Xjk5OSHPcRnhhDEO4/V6deDAAWVlZcnlCr0BXl1dnQYOHKh9+/YpOzs7RiOMve5wn9xjcuAekwP3mBxifY+GYai+vl4FBQVKSQmdZZKQMygpKSkaMGCApedkZ2cn7Rusre5wn9xjcuAekwP3mBxieY+dzZyYSJIFAACOQ4ACAAAcJ+kDFLfbrdmzZ8vtdsd7KFHVHe6Te0wO3GNy4B6Tg5PvMSGTZAEAQHJL+hkUAACQeAhQAACA4xCgAAAAxyFAAQAAjpP0Acrvf/97FRUVKSMjQyNHjtT69evjPaSIrVu3Ttdcc40KCgrkcrn0wgsv+D1uGIbmzJmjgoIC9ezZU5dddpl27twZn8FGqLS0VBdccIGysrLUv39/ffOb39Tu3bv9zkn0+1y8eLHOPvtsX2Ok0aNH629/+5vv8US/v0BKS0vlcrk0Y8YM37FEv885c+bI5XL5fXk8Ht/jiX5/pv379+vmm29W3759lZmZqXPPPVdbtmzxPZ7o9zl48OAOr6PL5dIdd9whKfHvT5JOnDihn/zkJyoqKlLPnj01ZMgQPfTQQ/J6vb5zHHmfRhJbsWKF0aNHD2PJkiVGeXm5MX36dKNXr15GZWVlvIcWkdWrVxsPPPCA8dxzzxmSjJUrV/o9/vOf/9zIysoynnvuOWP79u3Gd77zHSM/P9+oq6uLz4Aj8J//+Z/Gk08+aezYscPYtm2bMXHiRGPQoEHG0aNHfeck+n2uWrXKePnll43du3cbu3fvNu6//36jR48exo4dOwzDSPz7a2/Tpk3G4MGDjbPPPtuYPn2673ii3+fs2bONM8880zh48KDvq7q62vd4ot+fYRhGTU2NUVhYaEyZMsV4++23jYqKCuPVV181PvroI985iX6f1dXVfq9hWVmZIcl4/fXXDcNI/PszDMP42c9+ZvTt29f461//alRUVBh/+ctfjFNOOcV49NFHfec48T6TOkC58MILje9///t+x4YNG2bcd999cRqRfdoHKF6v1/B4PMbPf/5z37GmpiYjJyfH+MMf/hCHEdqjurrakGSsXbvWMIzkvc8+ffoYf/zjH5Pu/urr642hQ4caZWVlxrhx43wBSjLc5+zZs41zzjkn4GPJcH+GYRgzZ840xowZE/TxZLnPtqZPn26cfvrphtfrTZr7mzhxonHLLbf4HbvuuuuMm2++2TAM576OSbvE09LSoi1btmjChAl+xydMmKA333wzTqOKnoqKClVVVfndr9vt1rhx4xL6fmtrayVJubm5kpLvPltbW7VixQodO3ZMo0ePTrr7u+OOOzRx4kRdccUVfseT5T4//PBDFRQUqKioSN/97nf18ccfS0qe+1u1apXOP/98ffvb31b//v01YsQILVmyxPd4stynqaWlRcuWLdMtt9wil8uVNPc3ZswY/eMf/9AHH3wgSXrvvfe0YcMGXX311ZKc+zom5GaB4Th06JBaW1uVl5fndzwvL09VVVVxGlX0mPcU6H4rKyvjMaQuMwxDd999t8aMGaOSkhJJyXOf27dv1+jRo9XU1KRTTjlFK1euVHFxse9/Bol+f5K0YsUKbd26VZs3b+7wWDK8jqNGjdIzzzyjM844Q5999pl+9rOf6eKLL9bOnTuT4v4k6eOPP9bixYt199136/7779emTZv0wx/+UG63W9/73veS5j5NL7zwgj7//HNNmTJFUnK8TyVp5syZqq2t1bBhw5SamqrW1lbNmzdPN9xwgyTn3mfSBigml8vl971hGB2OJZNkut8777xT77//vjZs2NDhsUS/z69+9avatm2bPv/8cz333HOaPHmy1q5d63s80e9v3759mj59utasWaOMjIyg5yXyfV511VW+/z7rrLM0evRonX766Xr66ad10UUXSUrs+5Mkr9er888/X/Pnz5ckjRgxQjt37tTixYv1ve99z3deot+n6YknntBVV12lgoICv+OJfn9//vOftWzZMi1fvlxnnnmmtm3bphkzZqigoECTJ0/2nee0+0zaJZ5+/fopNTW1w2xJdXV1hygxGZjVA8lyvz/4wQ+0atUqvf766xowYIDveLLcZ3p6ur7yla/o/PPPV2lpqc455xz97//+b9Lc35YtW1RdXa2RI0cqLS1NaWlpWrt2rX7zm98oLS3Ndy+Jfp9t9erVS2eddZY+/PDDpHkd8/PzVVxc7Hds+PDh+uSTTyQlz9+jJFVWVurVV1/V//zP//iOJcv9/fjHP9Z9992n7373uzrrrLM0adIk3XXXXSotLZXk3PtM2gAlPT1dI0eOVFlZmd/xsrIyXXzxxXEaVfQUFRXJ4/H43W9LS4vWrl2bUPdrGIbuvPNOPf/883rttddUVFTk93iy3Gd7hmGoubk5ae7v8ssv1/bt27Vt2zbf1/nnn6+bbrpJ27Zt05AhQ5LiPttqbm7Wrl27lJ+fnzSv4yWXXNKhzP+DDz5QYWGhpOT6e3zyySfVv39/TZw40XcsWe6voaFBKSn+H/epqam+MmPH3md8cnNjwywzfuKJJ4zy8nJjxowZRq9evYy9e/fGe2gRqa+vN959913j3XffNSQZjzzyiPHuu+/6yqZ//vOfGzk5Ocbzzz9vbN++3bjhhhviXiZm1W233Wbk5OQYb7zxhl/pX0NDg++cRL/PWbNmGevWrTMqKiqM999/37j//vuNlJQUY82aNYZhJP79BdO2iscwEv8+77nnHuONN94wPv74Y+Ott94yvv71rxtZWVm+/78k+v0ZxskS8bS0NGPevHnGhx9+aPzpT38yMjMzjWXLlvnOSYb7bG1tNQYNGmTMnDmzw2PJcH+TJ082TjvtNF+Z8fPPP2/069fPuPfee33nOPE+kzpAMQzD+N3vfmcUFhYa6enpxnnnnecrV01Er7/+uiGpw9fkyZMNwzhZKjZ79mzD4/EYbrfbuPTSS43t27fHd9AWBbo/ScaTTz7pOyfR7/OWW27xvSdPPfVU4/LLL/cFJ4aR+PcXTPsAJdHv0+wT0aNHD6OgoMC47rrrjJ07d/oeT/T7M7300ktGSUmJ4Xa7jWHDhhmPP/643+PJcJ9///vfDUnG7t27OzyWDPdXV1dnTJ8+3Rg0aJCRkZFhDBkyxHjggQeM5uZm3zlOvE+XYRhGXKZuAAAAgkjaHBQAAJC4CFAAAIDjEKAAAADHIUABAACOQ4ACAAAchwAFAAA4DgEKAABwHAIUAADgOAQoAADAcQhQAACA4xCgAAAAxyFAAQAAjvP/AcNU4E3tWgjLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "plt.scatter(m_example[:,0], m_example[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c31add00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'VAF 2d spectrum')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot normalized data (as they were the VAF)\n",
    "plt.scatter(m_example[:,0]/130, m_example[:,1]/130)\n",
    "plt.title(\"VAF 2d spectrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1689b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite binomial likelihood for the multidimensional case\n",
    "def m_binomial_lk(probs, DP, weights, K, NV):\n",
    "    lk = torch.ones(K, len(NV)) # matrix with K rows and as many columns as the number of data\n",
    "    if K == 1:\n",
    "        return torch.log(weights) + dist.Binomial(total_count=DP, probs = probs).log_prob(NV).sum(axis=1) # simply does log(weights) + log(density)\n",
    "    for k in range(K):\n",
    "        lk[k, :] = torch.log(weights[k]) + dist.Binomial(total_count=DP, probs=probs[k]).log_prob(NV).sum(axis=1) #sums over the data dimensions\n",
    "                                                                                                                 # put on each column of lk a different data; rows are the clusters\n",
    "    return lk\n",
    "\n",
    "def log_sum_exp(args):\n",
    "    c = torch.amax(args, dim=0)\n",
    "    return c + torch.log(torch.sum(torch.exp(args - c), axis=0)) # sum over the rows (different clusters), so obtain a single likelihood for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "75fbf6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_binom_model(data, K):\n",
    "    NV = data\n",
    "    DP = 150 # al momento lo fisso qui, poi sarà preso dai dati\n",
    "    D = data.shape[1] # number of dimensions (samples)\n",
    "\n",
    "    # Prior for the mixing weights\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(torch.ones(K)))\n",
    "\n",
    "    # Prior for success probabilities (each probability has 2 dimensions) for each component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        probs = pyro.sample(\"probs\", dist.Beta(1, 1).expand([D]).to_event(1)) # assume Beta prior for the success probabilities\n",
    "        # probs = pyro.sample(\"probs\", dist.Beta(torch.ones(K, d), torch.ones(K, d)))\n",
    "\n",
    "    # Data generation\n",
    "    with pyro.plate(\"plate_data\", len(data)):\n",
    "        pyro.factor(\"lik\", log_sum_exp(m_binomial_lk(probs, DP, weights, K, NV)).sum()) # .sum() sums over the data because we have a log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "df43f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_binom_guide(data, K):\n",
    "    D = data.shape[1] # number of dimensions (samples)\n",
    "    \n",
    "    weights_param = pyro.param(\"weights_param\", lambda: dist.Dirichlet(torch.ones(K)).sample(), constraint=constraints.simplex)\n",
    "    pyro.sample(\"weights\", dist.Delta(weights_param).to_event(1))\n",
    "\n",
    "    probs_param = pyro.param(\"probs_param\", dist.Beta(torch.ones(K, D), torch.ones(K,D)).sample(), constraint=constraints.interval(0.,1.))\n",
    "    print(probs_param)\n",
    "    \n",
    "    # Probability of success for each component\n",
    "    with pyro.plate(\"plate_probs\", K):\n",
    "        pyro.sample(\"probs\", dist.Delta(probs_param).to_event(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e3f7214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4266, 0.7208],\n",
      "        [0.1579, 0.4877]], grad_fn=<ClampBackward1>)\n",
      "Iteration 0: Loss = 191236512.0\n",
      "tensor([[0.4264, 0.7206],\n",
      "        [0.1578, 0.4875]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4261, 0.7204],\n",
      "        [0.1577, 0.4872]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4259, 0.7202],\n",
      "        [0.1575, 0.4870]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4256, 0.7200],\n",
      "        [0.1574, 0.4867]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4254, 0.7198],\n",
      "        [0.1573, 0.4865]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4252, 0.7196],\n",
      "        [0.1571, 0.4862]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4249, 0.7194],\n",
      "        [0.1570, 0.4860]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4247, 0.7192],\n",
      "        [0.1569, 0.4857]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4244, 0.7190],\n",
      "        [0.1567, 0.4855]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4242, 0.7188],\n",
      "        [0.1566, 0.4852]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4239, 0.7186],\n",
      "        [0.1565, 0.4850]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4237, 0.7184],\n",
      "        [0.1563, 0.4847]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4235, 0.7182],\n",
      "        [0.1562, 0.4845]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4232, 0.7180],\n",
      "        [0.1561, 0.4842]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4230, 0.7178],\n",
      "        [0.1560, 0.4840]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4227, 0.7176],\n",
      "        [0.1558, 0.4837]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4225, 0.7174],\n",
      "        [0.1557, 0.4835]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4223, 0.7172],\n",
      "        [0.1556, 0.4832]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4220, 0.7170],\n",
      "        [0.1554, 0.4830]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4218, 0.7168],\n",
      "        [0.1553, 0.4827]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4216, 0.7166],\n",
      "        [0.1552, 0.4825]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4213, 0.7164],\n",
      "        [0.1550, 0.4822]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4211, 0.7162],\n",
      "        [0.1549, 0.4820]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4209, 0.7160],\n",
      "        [0.1548, 0.4817]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4206, 0.7158],\n",
      "        [0.1546, 0.4815]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4204, 0.7156],\n",
      "        [0.1545, 0.4812]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4202, 0.7154],\n",
      "        [0.1544, 0.4810]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4199, 0.7152],\n",
      "        [0.1543, 0.4807]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4197, 0.7150],\n",
      "        [0.1541, 0.4805]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4195, 0.7148],\n",
      "        [0.1540, 0.4802]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4193, 0.7146],\n",
      "        [0.1539, 0.4800]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4190, 0.7144],\n",
      "        [0.1537, 0.4797]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4188, 0.7142],\n",
      "        [0.1536, 0.4795]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4186, 0.7140],\n",
      "        [0.1535, 0.4792]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4184, 0.7138],\n",
      "        [0.1534, 0.4790]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4181, 0.7136],\n",
      "        [0.1532, 0.4787]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4179, 0.7134],\n",
      "        [0.1531, 0.4785]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4177, 0.7132],\n",
      "        [0.1530, 0.4782]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4175, 0.7130],\n",
      "        [0.1528, 0.4780]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4173, 0.7128],\n",
      "        [0.1527, 0.4777]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4171, 0.7126],\n",
      "        [0.1526, 0.4775]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4168, 0.7124],\n",
      "        [0.1525, 0.4773]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4166, 0.7122],\n",
      "        [0.1523, 0.4770]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4164, 0.7120],\n",
      "        [0.1522, 0.4768]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4162, 0.7118],\n",
      "        [0.1521, 0.4765]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4160, 0.7115],\n",
      "        [0.1519, 0.4763]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4158, 0.7113],\n",
      "        [0.1518, 0.4760]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4156, 0.7111],\n",
      "        [0.1517, 0.4758]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4154, 0.7109],\n",
      "        [0.1516, 0.4755]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4152, 0.7107],\n",
      "        [0.1514, 0.4753]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4150, 0.7105],\n",
      "        [0.1513, 0.4750]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4148, 0.7103],\n",
      "        [0.1512, 0.4748]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4146, 0.7101],\n",
      "        [0.1511, 0.4745]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4144, 0.7099],\n",
      "        [0.1509, 0.4743]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4142, 0.7097],\n",
      "        [0.1508, 0.4741]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4140, 0.7095],\n",
      "        [0.1507, 0.4738]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4138, 0.7093],\n",
      "        [0.1506, 0.4736]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4136, 0.7091],\n",
      "        [0.1504, 0.4733]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4135, 0.7089],\n",
      "        [0.1503, 0.4731]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4133, 0.7087],\n",
      "        [0.1502, 0.4728]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4131, 0.7085],\n",
      "        [0.1501, 0.4726]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4129, 0.7083],\n",
      "        [0.1499, 0.4723]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4127, 0.7082],\n",
      "        [0.1498, 0.4721]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4125, 0.7080],\n",
      "        [0.1497, 0.4718]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4124, 0.7078],\n",
      "        [0.1496, 0.4716]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4122, 0.7076],\n",
      "        [0.1494, 0.4714]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4120, 0.7074],\n",
      "        [0.1493, 0.4711]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4118, 0.7072],\n",
      "        [0.1492, 0.4709]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4117, 0.7070],\n",
      "        [0.1491, 0.4706]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4115, 0.7068],\n",
      "        [0.1490, 0.4704]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4113, 0.7066],\n",
      "        [0.1488, 0.4701]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4112, 0.7064],\n",
      "        [0.1487, 0.4699]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4110, 0.7062],\n",
      "        [0.1486, 0.4697]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4108, 0.7060],\n",
      "        [0.1485, 0.4694]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4107, 0.7058],\n",
      "        [0.1483, 0.4692]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4105, 0.7056],\n",
      "        [0.1482, 0.4689]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4103, 0.7054],\n",
      "        [0.1481, 0.4687]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4102, 0.7052],\n",
      "        [0.1480, 0.4684]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4100, 0.7050],\n",
      "        [0.1479, 0.4682]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4099, 0.7048],\n",
      "        [0.1477, 0.4680]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4097, 0.7046],\n",
      "        [0.1476, 0.4677]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4096, 0.7044],\n",
      "        [0.1475, 0.4675]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4094, 0.7042],\n",
      "        [0.1474, 0.4672]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4093, 0.7040],\n",
      "        [0.1472, 0.4670]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4091, 0.7038],\n",
      "        [0.1471, 0.4667]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4090, 0.7036],\n",
      "        [0.1470, 0.4665]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4088, 0.7034],\n",
      "        [0.1469, 0.4663]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4087, 0.7032],\n",
      "        [0.1468, 0.4660]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4085, 0.7030],\n",
      "        [0.1467, 0.4658]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4084, 0.7028],\n",
      "        [0.1465, 0.4655]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4083, 0.7026],\n",
      "        [0.1464, 0.4653]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4081, 0.7024],\n",
      "        [0.1463, 0.4651]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4080, 0.7022],\n",
      "        [0.1462, 0.4648]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4078, 0.7020],\n",
      "        [0.1461, 0.4646]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4077, 0.7018],\n",
      "        [0.1459, 0.4643]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4076, 0.7016],\n",
      "        [0.1458, 0.4641]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4075, 0.7014],\n",
      "        [0.1457, 0.4638]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4073, 0.7012],\n",
      "        [0.1456, 0.4636]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4072, 0.7011],\n",
      "        [0.1455, 0.4634]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4071, 0.7009],\n",
      "        [0.1453, 0.4631]], grad_fn=<ClampBackward1>)\n",
      "Iteration 100: Loss = 164276800.0\n",
      "tensor([[0.4069, 0.7007],\n",
      "        [0.1452, 0.4629]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4068, 0.7005],\n",
      "        [0.1451, 0.4626]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4067, 0.7003],\n",
      "        [0.1450, 0.4624]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4066, 0.7001],\n",
      "        [0.1449, 0.4622]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4065, 0.6999],\n",
      "        [0.1448, 0.4619]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4063, 0.6997],\n",
      "        [0.1446, 0.4617]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4062, 0.6995],\n",
      "        [0.1445, 0.4615]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4061, 0.6993],\n",
      "        [0.1444, 0.4612]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4060, 0.6991],\n",
      "        [0.1443, 0.4610]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4059, 0.6989],\n",
      "        [0.1442, 0.4607]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4058, 0.6987],\n",
      "        [0.1441, 0.4605]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4057, 0.6985],\n",
      "        [0.1439, 0.4603]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4056, 0.6983],\n",
      "        [0.1438, 0.4600]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4055, 0.6981],\n",
      "        [0.1437, 0.4598]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4054, 0.6979],\n",
      "        [0.1436, 0.4595]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4053, 0.6978],\n",
      "        [0.1435, 0.4593]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4052, 0.6976],\n",
      "        [0.1434, 0.4591]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4051, 0.6974],\n",
      "        [0.1433, 0.4588]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4050, 0.6972],\n",
      "        [0.1431, 0.4586]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4049, 0.6970],\n",
      "        [0.1430, 0.4584]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4048, 0.6968],\n",
      "        [0.1429, 0.4581]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4047, 0.6966],\n",
      "        [0.1428, 0.4579]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4046, 0.6964],\n",
      "        [0.1427, 0.4576]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4045, 0.6962],\n",
      "        [0.1426, 0.4574]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4044, 0.6960],\n",
      "        [0.1425, 0.4572]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4043, 0.6958],\n",
      "        [0.1423, 0.4569]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4042, 0.6956],\n",
      "        [0.1422, 0.4567]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4041, 0.6954],\n",
      "        [0.1421, 0.4565]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4040, 0.6953],\n",
      "        [0.1420, 0.4562]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4040, 0.6951],\n",
      "        [0.1419, 0.4560]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4039, 0.6949],\n",
      "        [0.1418, 0.4558]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4038, 0.6947],\n",
      "        [0.1417, 0.4555]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4037, 0.6945],\n",
      "        [0.1416, 0.4553]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4036, 0.6943],\n",
      "        [0.1414, 0.4550]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4036, 0.6941],\n",
      "        [0.1413, 0.4548]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4035, 0.6939],\n",
      "        [0.1412, 0.4546]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4034, 0.6937],\n",
      "        [0.1411, 0.4543]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4033, 0.6935],\n",
      "        [0.1410, 0.4541]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4033, 0.6933],\n",
      "        [0.1409, 0.4539]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4032, 0.6932],\n",
      "        [0.1408, 0.4536]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4031, 0.6930],\n",
      "        [0.1407, 0.4534]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4031, 0.6928],\n",
      "        [0.1406, 0.4532]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4030, 0.6926],\n",
      "        [0.1404, 0.4529]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4029, 0.6924],\n",
      "        [0.1403, 0.4527]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4028, 0.6922],\n",
      "        [0.1402, 0.4525]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4028, 0.6920],\n",
      "        [0.1401, 0.4522]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4027, 0.6918],\n",
      "        [0.1400, 0.4520]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4027, 0.6916],\n",
      "        [0.1399, 0.4518]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4026, 0.6915],\n",
      "        [0.1398, 0.4515]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4025, 0.6913],\n",
      "        [0.1397, 0.4513]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4025, 0.6911],\n",
      "        [0.1396, 0.4511]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4024, 0.6909],\n",
      "        [0.1395, 0.4508]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4024, 0.6907],\n",
      "        [0.1394, 0.4506]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4023, 0.6905],\n",
      "        [0.1392, 0.4504]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4022, 0.6903],\n",
      "        [0.1391, 0.4501]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4022, 0.6901],\n",
      "        [0.1390, 0.4499]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4021, 0.6900],\n",
      "        [0.1389, 0.4497]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4021, 0.6898],\n",
      "        [0.1388, 0.4494]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4020, 0.6896],\n",
      "        [0.1387, 0.4492]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4020, 0.6894],\n",
      "        [0.1386, 0.4490]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4019, 0.6892],\n",
      "        [0.1385, 0.4487]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4019, 0.6890],\n",
      "        [0.1384, 0.4485]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4018, 0.6888],\n",
      "        [0.1383, 0.4483]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4018, 0.6886],\n",
      "        [0.1382, 0.4480]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4017, 0.6885],\n",
      "        [0.1381, 0.4478]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4017, 0.6883],\n",
      "        [0.1379, 0.4476]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4016, 0.6881],\n",
      "        [0.1378, 0.4473]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4016, 0.6879],\n",
      "        [0.1377, 0.4471]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4016, 0.6877],\n",
      "        [0.1376, 0.4469]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4015, 0.6875],\n",
      "        [0.1375, 0.4466]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4015, 0.6873],\n",
      "        [0.1374, 0.4464]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4014, 0.6872],\n",
      "        [0.1373, 0.4462]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4014, 0.6870],\n",
      "        [0.1372, 0.4460]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4014, 0.6868],\n",
      "        [0.1371, 0.4457]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4013, 0.6866],\n",
      "        [0.1370, 0.4455]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4013, 0.6864],\n",
      "        [0.1369, 0.4453]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4012, 0.6862],\n",
      "        [0.1368, 0.4450]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4012, 0.6860],\n",
      "        [0.1367, 0.4448]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4012, 0.6859],\n",
      "        [0.1366, 0.4446]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4011, 0.6857],\n",
      "        [0.1365, 0.4443]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4011, 0.6855],\n",
      "        [0.1364, 0.4441]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4011, 0.6853],\n",
      "        [0.1363, 0.4439]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4010, 0.6851],\n",
      "        [0.1362, 0.4437]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4010, 0.6849],\n",
      "        [0.1360, 0.4434]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4010, 0.6848],\n",
      "        [0.1359, 0.4432]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4009, 0.6846],\n",
      "        [0.1358, 0.4430]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4009, 0.6844],\n",
      "        [0.1357, 0.4427]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4009, 0.6842],\n",
      "        [0.1356, 0.4425]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4008, 0.6840],\n",
      "        [0.1355, 0.4423]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4008, 0.6839],\n",
      "        [0.1354, 0.4421]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4008, 0.6837],\n",
      "        [0.1353, 0.4418]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4008, 0.6835],\n",
      "        [0.1352, 0.4416]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4007, 0.6833],\n",
      "        [0.1351, 0.4414]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4007, 0.6831],\n",
      "        [0.1350, 0.4411]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4007, 0.6829],\n",
      "        [0.1349, 0.4409]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4007, 0.6828],\n",
      "        [0.1348, 0.4407]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4006, 0.6826],\n",
      "        [0.1347, 0.4405]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4006, 0.6824],\n",
      "        [0.1346, 0.4402]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4006, 0.6822],\n",
      "        [0.1345, 0.4400]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4006, 0.6820],\n",
      "        [0.1344, 0.4398]], grad_fn=<ClampBackward1>)\n",
      "Iteration 200: Loss = 143092448.0\n",
      "tensor([[0.4005, 0.6819],\n",
      "        [0.1343, 0.4395]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4005, 0.6817],\n",
      "        [0.1342, 0.4393]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4005, 0.6815],\n",
      "        [0.1341, 0.4391]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4005, 0.6813],\n",
      "        [0.1340, 0.4389]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4005, 0.6811],\n",
      "        [0.1339, 0.4386]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4004, 0.6810],\n",
      "        [0.1338, 0.4384]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4004, 0.6808],\n",
      "        [0.1337, 0.4382]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4004, 0.6806],\n",
      "        [0.1336, 0.4380]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4004, 0.6804],\n",
      "        [0.1335, 0.4377]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4004, 0.6802],\n",
      "        [0.1334, 0.4375]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6801],\n",
      "        [0.1333, 0.4373]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6799],\n",
      "        [0.1332, 0.4371]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6797],\n",
      "        [0.1331, 0.4368]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6795],\n",
      "        [0.1330, 0.4366]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6793],\n",
      "        [0.1329, 0.4364]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4003, 0.6792],\n",
      "        [0.1328, 0.4362]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6790],\n",
      "        [0.1327, 0.4359]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6788],\n",
      "        [0.1326, 0.4357]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6786],\n",
      "        [0.1325, 0.4355]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6785],\n",
      "        [0.1324, 0.4353]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6783],\n",
      "        [0.1323, 0.4350]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6781],\n",
      "        [0.1322, 0.4348]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4002, 0.6779],\n",
      "        [0.1321, 0.4346]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6777],\n",
      "        [0.1320, 0.4344]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6776],\n",
      "        [0.1319, 0.4341]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6774],\n",
      "        [0.1318, 0.4339]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6772],\n",
      "        [0.1317, 0.4337]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6770],\n",
      "        [0.1316, 0.4335]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6769],\n",
      "        [0.1315, 0.4333]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6767],\n",
      "        [0.1314, 0.4330]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6765],\n",
      "        [0.1313, 0.4328]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4001, 0.6763],\n",
      "        [0.1312, 0.4326]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6762],\n",
      "        [0.1311, 0.4324]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6760],\n",
      "        [0.1310, 0.4321]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6758],\n",
      "        [0.1309, 0.4319]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6756],\n",
      "        [0.1308, 0.4317]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6755],\n",
      "        [0.1307, 0.4315]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6753],\n",
      "        [0.1306, 0.4312]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6751],\n",
      "        [0.1305, 0.4310]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6749],\n",
      "        [0.1304, 0.4308]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6748],\n",
      "        [0.1303, 0.4306]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6746],\n",
      "        [0.1303, 0.4304]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.4000, 0.6744],\n",
      "        [0.1302, 0.4301]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6743],\n",
      "        [0.1301, 0.4299]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6741],\n",
      "        [0.1300, 0.4297]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6739],\n",
      "        [0.1299, 0.4295]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6737],\n",
      "        [0.1298, 0.4293]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6736],\n",
      "        [0.1297, 0.4290]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6734],\n",
      "        [0.1296, 0.4288]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6732],\n",
      "        [0.1295, 0.4286]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6730],\n",
      "        [0.1294, 0.4284]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6729],\n",
      "        [0.1293, 0.4282]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6727],\n",
      "        [0.1292, 0.4279]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6725],\n",
      "        [0.1291, 0.4277]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6724],\n",
      "        [0.1290, 0.4275]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6722],\n",
      "        [0.1289, 0.4273]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6720],\n",
      "        [0.1288, 0.4271]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6718],\n",
      "        [0.1287, 0.4268]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3999, 0.6717],\n",
      "        [0.1286, 0.4266]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6715],\n",
      "        [0.1285, 0.4264]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6713],\n",
      "        [0.1285, 0.4262]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6712],\n",
      "        [0.1284, 0.4260]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6710],\n",
      "        [0.1283, 0.4257]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6708],\n",
      "        [0.1282, 0.4255]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6707],\n",
      "        [0.1281, 0.4253]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6705],\n",
      "        [0.1280, 0.4251]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6703],\n",
      "        [0.1279, 0.4249]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6702],\n",
      "        [0.1278, 0.4247]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6700],\n",
      "        [0.1277, 0.4244]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6698],\n",
      "        [0.1276, 0.4242]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6696],\n",
      "        [0.1275, 0.4240]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6695],\n",
      "        [0.1274, 0.4238]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6693],\n",
      "        [0.1273, 0.4236]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6691],\n",
      "        [0.1273, 0.4233]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6690],\n",
      "        [0.1272, 0.4231]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6688],\n",
      "        [0.1271, 0.4229]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6686],\n",
      "        [0.1270, 0.4227]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6685],\n",
      "        [0.1269, 0.4225]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6683],\n",
      "        [0.1268, 0.4223]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6681],\n",
      "        [0.1267, 0.4220]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6680],\n",
      "        [0.1266, 0.4218]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6678],\n",
      "        [0.1265, 0.4216]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6676],\n",
      "        [0.1264, 0.4214]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6675],\n",
      "        [0.1263, 0.4212]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6673],\n",
      "        [0.1263, 0.4210]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6671],\n",
      "        [0.1262, 0.4208]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6670],\n",
      "        [0.1261, 0.4205]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6668],\n",
      "        [0.1260, 0.4203]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6667],\n",
      "        [0.1259, 0.4201]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6665],\n",
      "        [0.1258, 0.4199]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6663],\n",
      "        [0.1257, 0.4197]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3998, 0.6662],\n",
      "        [0.1256, 0.4195]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6660],\n",
      "        [0.1255, 0.4193]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6658],\n",
      "        [0.1254, 0.4190]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6657],\n",
      "        [0.1254, 0.4188]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6655],\n",
      "        [0.1253, 0.4186]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6653],\n",
      "        [0.1252, 0.4184]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6652],\n",
      "        [0.1251, 0.4182]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6650],\n",
      "        [0.1250, 0.4180]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6649],\n",
      "        [0.1249, 0.4178]], grad_fn=<ClampBackward1>)\n",
      "Iteration 300: Loss = 126136048.0\n",
      "tensor([[0.3997, 0.6647],\n",
      "        [0.1248, 0.4175]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6645],\n",
      "        [0.1247, 0.4173]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6644],\n",
      "        [0.1247, 0.4171]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6642],\n",
      "        [0.1246, 0.4169]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6640],\n",
      "        [0.1245, 0.4167]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6639],\n",
      "        [0.1244, 0.4165]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6637],\n",
      "        [0.1243, 0.4163]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6636],\n",
      "        [0.1242, 0.4161]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6634],\n",
      "        [0.1241, 0.4158]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6632],\n",
      "        [0.1240, 0.4156]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6631],\n",
      "        [0.1240, 0.4154]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6629],\n",
      "        [0.1239, 0.4152]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6628],\n",
      "        [0.1238, 0.4150]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6626],\n",
      "        [0.1237, 0.4148]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6624],\n",
      "        [0.1236, 0.4146]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6623],\n",
      "        [0.1235, 0.4144]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6621],\n",
      "        [0.1234, 0.4141]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6620],\n",
      "        [0.1233, 0.4139]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6618],\n",
      "        [0.1233, 0.4137]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6617],\n",
      "        [0.1232, 0.4135]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6615],\n",
      "        [0.1231, 0.4133]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6613],\n",
      "        [0.1230, 0.4131]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6612],\n",
      "        [0.1229, 0.4129]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6610],\n",
      "        [0.1228, 0.4127]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6609],\n",
      "        [0.1228, 0.4125]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6607],\n",
      "        [0.1227, 0.4123]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6605],\n",
      "        [0.1226, 0.4120]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6604],\n",
      "        [0.1225, 0.4118]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6602],\n",
      "        [0.1224, 0.4116]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6601],\n",
      "        [0.1223, 0.4114]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6599],\n",
      "        [0.1222, 0.4112]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6598],\n",
      "        [0.1222, 0.4110]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6596],\n",
      "        [0.1221, 0.4108]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6595],\n",
      "        [0.1220, 0.4106]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6593],\n",
      "        [0.1219, 0.4104]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6591],\n",
      "        [0.1218, 0.4102]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6590],\n",
      "        [0.1217, 0.4100]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6588],\n",
      "        [0.1217, 0.4097]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6587],\n",
      "        [0.1216, 0.4095]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6585],\n",
      "        [0.1215, 0.4093]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6584],\n",
      "        [0.1214, 0.4091]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6582],\n",
      "        [0.1213, 0.4089]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6581],\n",
      "        [0.1212, 0.4087]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6579],\n",
      "        [0.1212, 0.4085]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6578],\n",
      "        [0.1211, 0.4083]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6576],\n",
      "        [0.1210, 0.4081]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6575],\n",
      "        [0.1209, 0.4079]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6573],\n",
      "        [0.1208, 0.4077]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6572],\n",
      "        [0.1207, 0.4075]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6570],\n",
      "        [0.1207, 0.4073]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6568],\n",
      "        [0.1206, 0.4070]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6567],\n",
      "        [0.1205, 0.4068]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6565],\n",
      "        [0.1204, 0.4066]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6564],\n",
      "        [0.1203, 0.4064]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6562],\n",
      "        [0.1203, 0.4062]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6561],\n",
      "        [0.1202, 0.4060]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6559],\n",
      "        [0.1201, 0.4058]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6558],\n",
      "        [0.1200, 0.4056]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6556],\n",
      "        [0.1199, 0.4054]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6555],\n",
      "        [0.1198, 0.4052]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6553],\n",
      "        [0.1198, 0.4050]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6552],\n",
      "        [0.1197, 0.4048]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6550],\n",
      "        [0.1196, 0.4046]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6549],\n",
      "        [0.1195, 0.4044]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6547],\n",
      "        [0.1194, 0.4042]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6546],\n",
      "        [0.1194, 0.4040]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6544],\n",
      "        [0.1193, 0.4038]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6543],\n",
      "        [0.1192, 0.4036]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6542],\n",
      "        [0.1191, 0.4034]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6540],\n",
      "        [0.1190, 0.4032]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6539],\n",
      "        [0.1190, 0.4029]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6537],\n",
      "        [0.1189, 0.4027]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6536],\n",
      "        [0.1188, 0.4025]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6534],\n",
      "        [0.1187, 0.4023]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6533],\n",
      "        [0.1186, 0.4021]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6531],\n",
      "        [0.1186, 0.4019]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6530],\n",
      "        [0.1185, 0.4017]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6528],\n",
      "        [0.1184, 0.4015]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6527],\n",
      "        [0.1183, 0.4013]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6525],\n",
      "        [0.1182, 0.4011]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6524],\n",
      "        [0.1182, 0.4009]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6522],\n",
      "        [0.1181, 0.4007]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6521],\n",
      "        [0.1180, 0.4005]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6520],\n",
      "        [0.1179, 0.4003]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6518],\n",
      "        [0.1179, 0.4001]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6517],\n",
      "        [0.1178, 0.3999]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6515],\n",
      "        [0.1177, 0.3997]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6514],\n",
      "        [0.1176, 0.3995]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6512],\n",
      "        [0.1175, 0.3993]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6511],\n",
      "        [0.1175, 0.3991]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6510],\n",
      "        [0.1174, 0.3989]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6508],\n",
      "        [0.1173, 0.3987]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6507],\n",
      "        [0.1172, 0.3985]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6505],\n",
      "        [0.1172, 0.3983]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6504],\n",
      "        [0.1171, 0.3981]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6502],\n",
      "        [0.1170, 0.3979]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6501],\n",
      "        [0.1169, 0.3977]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6500],\n",
      "        [0.1168, 0.3975]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6498],\n",
      "        [0.1168, 0.3973]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6497],\n",
      "        [0.1167, 0.3971]], grad_fn=<ClampBackward1>)\n",
      "Iteration 400: Loss = 112652528.0\n",
      "tensor([[0.3997, 0.6495],\n",
      "        [0.1166, 0.3969]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6494],\n",
      "        [0.1165, 0.3967]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6493],\n",
      "        [0.1165, 0.3965]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6491],\n",
      "        [0.1164, 0.3963]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6490],\n",
      "        [0.1163, 0.3961]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6488],\n",
      "        [0.1162, 0.3959]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6487],\n",
      "        [0.1162, 0.3957]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6486],\n",
      "        [0.1161, 0.3955]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6484],\n",
      "        [0.1160, 0.3953]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6483],\n",
      "        [0.1159, 0.3951]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6481],\n",
      "        [0.1159, 0.3949]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6480],\n",
      "        [0.1158, 0.3947]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6479],\n",
      "        [0.1157, 0.3945]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6477],\n",
      "        [0.1156, 0.3943]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6476],\n",
      "        [0.1156, 0.3941]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6474],\n",
      "        [0.1155, 0.3939]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6473],\n",
      "        [0.1154, 0.3937]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6472],\n",
      "        [0.1153, 0.3935]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6470],\n",
      "        [0.1153, 0.3933]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6469],\n",
      "        [0.1152, 0.3931]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6468],\n",
      "        [0.1151, 0.3929]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6466],\n",
      "        [0.1150, 0.3927]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6465],\n",
      "        [0.1150, 0.3925]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6464],\n",
      "        [0.1149, 0.3923]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6462],\n",
      "        [0.1148, 0.3922]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6461],\n",
      "        [0.1147, 0.3920]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6459],\n",
      "        [0.1147, 0.3918]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6458],\n",
      "        [0.1146, 0.3916]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6457],\n",
      "        [0.1145, 0.3914]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6455],\n",
      "        [0.1144, 0.3912]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6454],\n",
      "        [0.1144, 0.3910]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6453],\n",
      "        [0.1143, 0.3908]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6451],\n",
      "        [0.1142, 0.3906]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6450],\n",
      "        [0.1142, 0.3904]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6449],\n",
      "        [0.1141, 0.3902]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6447],\n",
      "        [0.1140, 0.3900]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6446],\n",
      "        [0.1139, 0.3898]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6445],\n",
      "        [0.1139, 0.3896]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6443],\n",
      "        [0.1138, 0.3894]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6442],\n",
      "        [0.1137, 0.3892]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6441],\n",
      "        [0.1136, 0.3890]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6439],\n",
      "        [0.1136, 0.3888]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6438],\n",
      "        [0.1135, 0.3886]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6437],\n",
      "        [0.1134, 0.3884]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6436],\n",
      "        [0.1134, 0.3883]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6434],\n",
      "        [0.1133, 0.3881]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6433],\n",
      "        [0.1132, 0.3879]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6432],\n",
      "        [0.1131, 0.3877]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6430],\n",
      "        [0.1131, 0.3875]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6429],\n",
      "        [0.1130, 0.3873]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6428],\n",
      "        [0.1129, 0.3871]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6426],\n",
      "        [0.1129, 0.3869]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6425],\n",
      "        [0.1128, 0.3867]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6424],\n",
      "        [0.1127, 0.3865]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6423],\n",
      "        [0.1126, 0.3863]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6421],\n",
      "        [0.1126, 0.3861]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6420],\n",
      "        [0.1125, 0.3859]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6419],\n",
      "        [0.1124, 0.3858]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6417],\n",
      "        [0.1124, 0.3856]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6416],\n",
      "        [0.1123, 0.3854]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6415],\n",
      "        [0.1122, 0.3852]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6414],\n",
      "        [0.1121, 0.3850]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6412],\n",
      "        [0.1121, 0.3848]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6411],\n",
      "        [0.1120, 0.3846]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6410],\n",
      "        [0.1119, 0.3844]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6409],\n",
      "        [0.1119, 0.3842]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6407],\n",
      "        [0.1118, 0.3840]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6406],\n",
      "        [0.1117, 0.3838]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6405],\n",
      "        [0.1117, 0.3837]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6404],\n",
      "        [0.1116, 0.3835]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6402],\n",
      "        [0.1115, 0.3833]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6401],\n",
      "        [0.1114, 0.3831]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6400],\n",
      "        [0.1114, 0.3829]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6399],\n",
      "        [0.1113, 0.3827]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6397],\n",
      "        [0.1112, 0.3825]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6396],\n",
      "        [0.1112, 0.3823]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6395],\n",
      "        [0.1111, 0.3821]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6394],\n",
      "        [0.1110, 0.3819]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6392],\n",
      "        [0.1110, 0.3818]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6391],\n",
      "        [0.1109, 0.3816]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6390],\n",
      "        [0.1108, 0.3814]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6389],\n",
      "        [0.1108, 0.3812]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6388],\n",
      "        [0.1107, 0.3810]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6386],\n",
      "        [0.1106, 0.3808]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6385],\n",
      "        [0.1106, 0.3806]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6384],\n",
      "        [0.1105, 0.3804]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6383],\n",
      "        [0.1104, 0.3803]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6381],\n",
      "        [0.1104, 0.3801]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6380],\n",
      "        [0.1103, 0.3799]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6379],\n",
      "        [0.1102, 0.3797]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6378],\n",
      "        [0.1102, 0.3795]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6377],\n",
      "        [0.1101, 0.3793]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6375],\n",
      "        [0.1100, 0.3791]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6374],\n",
      "        [0.1100, 0.3789]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6373],\n",
      "        [0.1099, 0.3788]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6372],\n",
      "        [0.1098, 0.3786]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6371],\n",
      "        [0.1097, 0.3784]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6369],\n",
      "        [0.1097, 0.3782]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6368],\n",
      "        [0.1096, 0.3780]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6367],\n",
      "        [0.1095, 0.3778]], grad_fn=<ClampBackward1>)\n",
      "Iteration 500: Loss = 101995872.0\n",
      "tensor([[0.3997, 0.6366],\n",
      "        [0.1095, 0.3776]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6365],\n",
      "        [0.1094, 0.3775]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6364],\n",
      "        [0.1094, 0.3773]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6362],\n",
      "        [0.1093, 0.3771]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6361],\n",
      "        [0.1092, 0.3769]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6360],\n",
      "        [0.1092, 0.3767]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6359],\n",
      "        [0.1091, 0.3765]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6358],\n",
      "        [0.1090, 0.3763]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6357],\n",
      "        [0.1090, 0.3762]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6355],\n",
      "        [0.1089, 0.3760]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6354],\n",
      "        [0.1088, 0.3758]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6353],\n",
      "        [0.1088, 0.3756]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6352],\n",
      "        [0.1087, 0.3754]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6351],\n",
      "        [0.1086, 0.3752]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6350],\n",
      "        [0.1086, 0.3750]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6349],\n",
      "        [0.1085, 0.3749]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6347],\n",
      "        [0.1084, 0.3747]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6346],\n",
      "        [0.1084, 0.3745]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6345],\n",
      "        [0.1083, 0.3743]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6344],\n",
      "        [0.1082, 0.3741]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6343],\n",
      "        [0.1082, 0.3739]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6342],\n",
      "        [0.1081, 0.3738]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6341],\n",
      "        [0.1080, 0.3736]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6339],\n",
      "        [0.1080, 0.3734]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6338],\n",
      "        [0.1079, 0.3732]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6337],\n",
      "        [0.1079, 0.3730]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6336],\n",
      "        [0.1078, 0.3729]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6335],\n",
      "        [0.1077, 0.3727]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6334],\n",
      "        [0.1077, 0.3725]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6333],\n",
      "        [0.1076, 0.3723]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6332],\n",
      "        [0.1075, 0.3721]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6331],\n",
      "        [0.1075, 0.3719]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6329],\n",
      "        [0.1074, 0.3718]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6328],\n",
      "        [0.1073, 0.3716]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6327],\n",
      "        [0.1073, 0.3714]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6326],\n",
      "        [0.1072, 0.3712]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6325],\n",
      "        [0.1072, 0.3710]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6324],\n",
      "        [0.1071, 0.3709]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6323],\n",
      "        [0.1070, 0.3707]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6322],\n",
      "        [0.1070, 0.3705]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6321],\n",
      "        [0.1069, 0.3703]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6320],\n",
      "        [0.1068, 0.3701]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6318],\n",
      "        [0.1068, 0.3700]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6317],\n",
      "        [0.1067, 0.3698]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6316],\n",
      "        [0.1066, 0.3696]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6315],\n",
      "        [0.1066, 0.3694]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6314],\n",
      "        [0.1065, 0.3692]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6313],\n",
      "        [0.1065, 0.3691]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6312],\n",
      "        [0.1064, 0.3689]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6311],\n",
      "        [0.1063, 0.3687]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6310],\n",
      "        [0.1063, 0.3685]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6309],\n",
      "        [0.1062, 0.3683]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6308],\n",
      "        [0.1062, 0.3682]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6307],\n",
      "        [0.1061, 0.3680]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6306],\n",
      "        [0.1060, 0.3678]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6305],\n",
      "        [0.1060, 0.3676]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6304],\n",
      "        [0.1059, 0.3674]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6303],\n",
      "        [0.1058, 0.3673]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6302],\n",
      "        [0.1058, 0.3671]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6300],\n",
      "        [0.1057, 0.3669]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6299],\n",
      "        [0.1057, 0.3667]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6298],\n",
      "        [0.1056, 0.3666]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6297],\n",
      "        [0.1055, 0.3664]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6296],\n",
      "        [0.1055, 0.3662]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6295],\n",
      "        [0.1054, 0.3660]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6294],\n",
      "        [0.1054, 0.3658]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6293],\n",
      "        [0.1053, 0.3657]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6292],\n",
      "        [0.1052, 0.3655]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6291],\n",
      "        [0.1052, 0.3653]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6290],\n",
      "        [0.1051, 0.3651]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6289],\n",
      "        [0.1051, 0.3650]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6288],\n",
      "        [0.1050, 0.3648]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6287],\n",
      "        [0.1049, 0.3646]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6286],\n",
      "        [0.1049, 0.3644]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6285],\n",
      "        [0.1048, 0.3643]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6284],\n",
      "        [0.1048, 0.3641]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6283],\n",
      "        [0.1047, 0.3639]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6282],\n",
      "        [0.1046, 0.3637]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6281],\n",
      "        [0.1046, 0.3636]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6280],\n",
      "        [0.1045, 0.3634]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6279],\n",
      "        [0.1045, 0.3632]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6278],\n",
      "        [0.1044, 0.3630]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6277],\n",
      "        [0.1043, 0.3629]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6276],\n",
      "        [0.1043, 0.3627]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6275],\n",
      "        [0.1042, 0.3625]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6274],\n",
      "        [0.1042, 0.3623]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6273],\n",
      "        [0.1041, 0.3622]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6272],\n",
      "        [0.1040, 0.3620]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6271],\n",
      "        [0.1040, 0.3618]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6270],\n",
      "        [0.1039, 0.3616]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6269],\n",
      "        [0.1039, 0.3615]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6268],\n",
      "        [0.1038, 0.3613]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6267],\n",
      "        [0.1037, 0.3611]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6266],\n",
      "        [0.1037, 0.3609]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6265],\n",
      "        [0.1036, 0.3608]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6264],\n",
      "        [0.1036, 0.3606]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6264],\n",
      "        [0.1035, 0.3604]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6263],\n",
      "        [0.1035, 0.3603]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6262],\n",
      "        [0.1034, 0.3601]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6261],\n",
      "        [0.1033, 0.3599]], grad_fn=<ClampBackward1>)\n",
      "Iteration 600: Loss = 93582752.0\n",
      "tensor([[0.3997, 0.6260],\n",
      "        [0.1033, 0.3597]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6259],\n",
      "        [0.1032, 0.3596]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6258],\n",
      "        [0.1032, 0.3594]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6257],\n",
      "        [0.1031, 0.3592]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6256],\n",
      "        [0.1031, 0.3590]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6255],\n",
      "        [0.1030, 0.3589]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6254],\n",
      "        [0.1029, 0.3587]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6253],\n",
      "        [0.1029, 0.3585]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6252],\n",
      "        [0.1028, 0.3584]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6251],\n",
      "        [0.1028, 0.3582]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6250],\n",
      "        [0.1027, 0.3580]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6249],\n",
      "        [0.1027, 0.3578]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6249],\n",
      "        [0.1026, 0.3577]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6248],\n",
      "        [0.1025, 0.3575]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6247],\n",
      "        [0.1025, 0.3573]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6246],\n",
      "        [0.1024, 0.3572]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6245],\n",
      "        [0.1024, 0.3570]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6244],\n",
      "        [0.1023, 0.3568]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6243],\n",
      "        [0.1023, 0.3567]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6242],\n",
      "        [0.1022, 0.3565]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6241],\n",
      "        [0.1021, 0.3563]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6240],\n",
      "        [0.1021, 0.3561]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6239],\n",
      "        [0.1020, 0.3560]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6239],\n",
      "        [0.1020, 0.3558]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6238],\n",
      "        [0.1019, 0.3556]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6237],\n",
      "        [0.1019, 0.3555]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6236],\n",
      "        [0.1018, 0.3553]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6235],\n",
      "        [0.1018, 0.3551]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6234],\n",
      "        [0.1017, 0.3550]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6233],\n",
      "        [0.1016, 0.3548]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6232],\n",
      "        [0.1016, 0.3546]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6231],\n",
      "        [0.1015, 0.3545]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6231],\n",
      "        [0.1015, 0.3543]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6230],\n",
      "        [0.1014, 0.3541]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6229],\n",
      "        [0.1014, 0.3540]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6228],\n",
      "        [0.1013, 0.3538]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6227],\n",
      "        [0.1013, 0.3536]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6226],\n",
      "        [0.1012, 0.3535]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6225],\n",
      "        [0.1011, 0.3533]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6224],\n",
      "        [0.1011, 0.3531]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6224],\n",
      "        [0.1010, 0.3529]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6223],\n",
      "        [0.1010, 0.3528]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6222],\n",
      "        [0.1009, 0.3526]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6221],\n",
      "        [0.1009, 0.3524]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6220],\n",
      "        [0.1008, 0.3523]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6219],\n",
      "        [0.1008, 0.3521]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6219],\n",
      "        [0.1007, 0.3519]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6218],\n",
      "        [0.1007, 0.3518]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6217],\n",
      "        [0.1006, 0.3516]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6216],\n",
      "        [0.1005, 0.3515]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6215],\n",
      "        [0.1005, 0.3513]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6214],\n",
      "        [0.1004, 0.3511]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6214],\n",
      "        [0.1004, 0.3510]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6213],\n",
      "        [0.1003, 0.3508]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6212],\n",
      "        [0.1003, 0.3506]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6211],\n",
      "        [0.1002, 0.3505]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6210],\n",
      "        [0.1002, 0.3503]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6209],\n",
      "        [0.1001, 0.3501]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6209],\n",
      "        [0.1001, 0.3500]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6208],\n",
      "        [0.1000, 0.3498]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6207],\n",
      "        [0.1000, 0.3496]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6206],\n",
      "        [0.0999, 0.3495]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6205],\n",
      "        [0.0999, 0.3493]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6204],\n",
      "        [0.0998, 0.3491]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6204],\n",
      "        [0.0997, 0.3490]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6203],\n",
      "        [0.0997, 0.3488]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6202],\n",
      "        [0.0996, 0.3487]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6201],\n",
      "        [0.0996, 0.3485]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6200],\n",
      "        [0.0995, 0.3483]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6200],\n",
      "        [0.0995, 0.3482]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6199],\n",
      "        [0.0994, 0.3480]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6198],\n",
      "        [0.0994, 0.3478]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6197],\n",
      "        [0.0993, 0.3477]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6197],\n",
      "        [0.0993, 0.3475]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6196],\n",
      "        [0.0992, 0.3473]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6195],\n",
      "        [0.0992, 0.3472]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6194],\n",
      "        [0.0991, 0.3470]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6193],\n",
      "        [0.0991, 0.3469]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6193],\n",
      "        [0.0990, 0.3467]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6192],\n",
      "        [0.0990, 0.3465]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6191],\n",
      "        [0.0989, 0.3464]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6190],\n",
      "        [0.0989, 0.3462]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6190],\n",
      "        [0.0988, 0.3461]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6189],\n",
      "        [0.0988, 0.3459]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6188],\n",
      "        [0.0987, 0.3457]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6187],\n",
      "        [0.0987, 0.3456]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6186],\n",
      "        [0.0986, 0.3454]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6186],\n",
      "        [0.0986, 0.3452]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6185],\n",
      "        [0.0985, 0.3451]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6184],\n",
      "        [0.0985, 0.3449]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6183],\n",
      "        [0.0984, 0.3448]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6183],\n",
      "        [0.0984, 0.3446]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6182],\n",
      "        [0.0983, 0.3444]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6181],\n",
      "        [0.0982, 0.3443]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6180],\n",
      "        [0.0982, 0.3441]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6180],\n",
      "        [0.0981, 0.3440]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6179],\n",
      "        [0.0981, 0.3438]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6178],\n",
      "        [0.0980, 0.3436]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6178],\n",
      "        [0.0980, 0.3435]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6177],\n",
      "        [0.0979, 0.3433]], grad_fn=<ClampBackward1>)\n",
      "Iteration 700: Loss = 86915712.0\n",
      "tensor([[0.3997, 0.6176],\n",
      "        [0.0979, 0.3432]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6175],\n",
      "        [0.0978, 0.3430]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6175],\n",
      "        [0.0978, 0.3428]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6174],\n",
      "        [0.0977, 0.3427]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6173],\n",
      "        [0.0977, 0.3425]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6172],\n",
      "        [0.0976, 0.3424]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6172],\n",
      "        [0.0976, 0.3422]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6171],\n",
      "        [0.0975, 0.3421]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6170],\n",
      "        [0.0975, 0.3419]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6170],\n",
      "        [0.0974, 0.3417]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6169],\n",
      "        [0.0974, 0.3416]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6168],\n",
      "        [0.0973, 0.3414]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6167],\n",
      "        [0.0973, 0.3413]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6167],\n",
      "        [0.0972, 0.3411]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6166],\n",
      "        [0.0972, 0.3409]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6165],\n",
      "        [0.0972, 0.3408]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6165],\n",
      "        [0.0971, 0.3406]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6164],\n",
      "        [0.0971, 0.3405]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6163],\n",
      "        [0.0970, 0.3403]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6163],\n",
      "        [0.0970, 0.3402]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6162],\n",
      "        [0.0969, 0.3400]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6161],\n",
      "        [0.0969, 0.3398]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6161],\n",
      "        [0.0968, 0.3397]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6160],\n",
      "        [0.0968, 0.3395]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6159],\n",
      "        [0.0967, 0.3394]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6158],\n",
      "        [0.0967, 0.3392]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6158],\n",
      "        [0.0966, 0.3391]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6157],\n",
      "        [0.0966, 0.3389]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6156],\n",
      "        [0.0965, 0.3388]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6156],\n",
      "        [0.0965, 0.3386]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6155],\n",
      "        [0.0964, 0.3384]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6154],\n",
      "        [0.0964, 0.3383]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6154],\n",
      "        [0.0963, 0.3381]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6153],\n",
      "        [0.0963, 0.3380]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6152],\n",
      "        [0.0962, 0.3378]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6152],\n",
      "        [0.0962, 0.3377]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6151],\n",
      "        [0.0961, 0.3375]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6151],\n",
      "        [0.0961, 0.3374]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6150],\n",
      "        [0.0960, 0.3372]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6149],\n",
      "        [0.0960, 0.3371]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6149],\n",
      "        [0.0959, 0.3369]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6148],\n",
      "        [0.0959, 0.3367]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6147],\n",
      "        [0.0958, 0.3366]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6147],\n",
      "        [0.0958, 0.3364]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6146],\n",
      "        [0.0958, 0.3363]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6145],\n",
      "        [0.0957, 0.3361]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6145],\n",
      "        [0.0957, 0.3360]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6144],\n",
      "        [0.0956, 0.3358]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6143],\n",
      "        [0.0956, 0.3357]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6143],\n",
      "        [0.0955, 0.3355]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6142],\n",
      "        [0.0955, 0.3354]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6142],\n",
      "        [0.0954, 0.3352]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6141],\n",
      "        [0.0954, 0.3351]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6140],\n",
      "        [0.0953, 0.3349]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6140],\n",
      "        [0.0953, 0.3348]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6139],\n",
      "        [0.0952, 0.3346]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6138],\n",
      "        [0.0952, 0.3344]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6138],\n",
      "        [0.0951, 0.3343]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6137],\n",
      "        [0.0951, 0.3341]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6137],\n",
      "        [0.0951, 0.3340]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6136],\n",
      "        [0.0950, 0.3338]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6135],\n",
      "        [0.0950, 0.3337]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6135],\n",
      "        [0.0949, 0.3335]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6134],\n",
      "        [0.0949, 0.3334]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6134],\n",
      "        [0.0948, 0.3332]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6133],\n",
      "        [0.0948, 0.3331]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6132],\n",
      "        [0.0947, 0.3329]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6132],\n",
      "        [0.0947, 0.3328]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6131],\n",
      "        [0.0946, 0.3326]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6131],\n",
      "        [0.0946, 0.3325]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6130],\n",
      "        [0.0946, 0.3323]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6129],\n",
      "        [0.0945, 0.3322]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6129],\n",
      "        [0.0945, 0.3320]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6128],\n",
      "        [0.0944, 0.3319]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6128],\n",
      "        [0.0944, 0.3317]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6127],\n",
      "        [0.0943, 0.3316]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6126],\n",
      "        [0.0943, 0.3314]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6126],\n",
      "        [0.0942, 0.3313]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6125],\n",
      "        [0.0942, 0.3311]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6125],\n",
      "        [0.0941, 0.3310]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6124],\n",
      "        [0.0941, 0.3308]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6124],\n",
      "        [0.0941, 0.3307]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6123],\n",
      "        [0.0940, 0.3305]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6122],\n",
      "        [0.0940, 0.3304]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6122],\n",
      "        [0.0939, 0.3302]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6121],\n",
      "        [0.0939, 0.3301]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6121],\n",
      "        [0.0938, 0.3299]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6120],\n",
      "        [0.0938, 0.3298]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6120],\n",
      "        [0.0937, 0.3296]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6119],\n",
      "        [0.0937, 0.3295]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6119],\n",
      "        [0.0937, 0.3294]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6118],\n",
      "        [0.0936, 0.3292]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6117],\n",
      "        [0.0936, 0.3291]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6117],\n",
      "        [0.0935, 0.3289]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6116],\n",
      "        [0.0935, 0.3288]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6116],\n",
      "        [0.0934, 0.3286]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6115],\n",
      "        [0.0934, 0.3285]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6115],\n",
      "        [0.0933, 0.3283]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6114],\n",
      "        [0.0933, 0.3282]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6114],\n",
      "        [0.0933, 0.3280]], grad_fn=<ClampBackward1>)\n",
      "Iteration 800: Loss = 81595224.0\n",
      "tensor([[0.3997, 0.6113],\n",
      "        [0.0932, 0.3279]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6113],\n",
      "        [0.0932, 0.3277]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6112],\n",
      "        [0.0931, 0.3276]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6111],\n",
      "        [0.0931, 0.3274]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6111],\n",
      "        [0.0930, 0.3273]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6110],\n",
      "        [0.0930, 0.3271]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6110],\n",
      "        [0.0930, 0.3270]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6109],\n",
      "        [0.0929, 0.3269]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6109],\n",
      "        [0.0929, 0.3267]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6108],\n",
      "        [0.0928, 0.3266]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6108],\n",
      "        [0.0928, 0.3264]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6107],\n",
      "        [0.0927, 0.3263]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6107],\n",
      "        [0.0927, 0.3261]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6106],\n",
      "        [0.0927, 0.3260]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6106],\n",
      "        [0.0926, 0.3258]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6105],\n",
      "        [0.0926, 0.3257]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6105],\n",
      "        [0.0925, 0.3255]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6104],\n",
      "        [0.0925, 0.3254]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6104],\n",
      "        [0.0924, 0.3253]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6103],\n",
      "        [0.0924, 0.3251]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6103],\n",
      "        [0.0924, 0.3250]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6102],\n",
      "        [0.0923, 0.3248]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6102],\n",
      "        [0.0923, 0.3247]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6101],\n",
      "        [0.0922, 0.3245]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6101],\n",
      "        [0.0922, 0.3244]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6100],\n",
      "        [0.0921, 0.3243]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6100],\n",
      "        [0.0921, 0.3241]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6099],\n",
      "        [0.0921, 0.3240]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6099],\n",
      "        [0.0920, 0.3238]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6098],\n",
      "        [0.0920, 0.3237]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6098],\n",
      "        [0.0919, 0.3235]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6097],\n",
      "        [0.0919, 0.3234]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6097],\n",
      "        [0.0919, 0.3233]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6096],\n",
      "        [0.0918, 0.3231]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6096],\n",
      "        [0.0918, 0.3230]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6095],\n",
      "        [0.0917, 0.3228]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6095],\n",
      "        [0.0917, 0.3227]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6094],\n",
      "        [0.0916, 0.3225]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6094],\n",
      "        [0.0916, 0.3224]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6093],\n",
      "        [0.0916, 0.3223]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6093],\n",
      "        [0.0915, 0.3221]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6093],\n",
      "        [0.0915, 0.3220]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6092],\n",
      "        [0.0914, 0.3218]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6092],\n",
      "        [0.0914, 0.3217]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6091],\n",
      "        [0.0914, 0.3215]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6091],\n",
      "        [0.0913, 0.3214]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6090],\n",
      "        [0.0913, 0.3213]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6090],\n",
      "        [0.0912, 0.3211]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6089],\n",
      "        [0.0912, 0.3210]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6089],\n",
      "        [0.0912, 0.3208]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6088],\n",
      "        [0.0911, 0.3207]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6088],\n",
      "        [0.0911, 0.3206]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6087],\n",
      "        [0.0910, 0.3204]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6087],\n",
      "        [0.0910, 0.3203]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6087],\n",
      "        [0.0909, 0.3201]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6086],\n",
      "        [0.0909, 0.3200]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6086],\n",
      "        [0.0909, 0.3199]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6085],\n",
      "        [0.0908, 0.3197]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6085],\n",
      "        [0.0908, 0.3196]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6084],\n",
      "        [0.0907, 0.3194]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6084],\n",
      "        [0.0907, 0.3193]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6083],\n",
      "        [0.0907, 0.3192]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6083],\n",
      "        [0.0906, 0.3190]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6083],\n",
      "        [0.0906, 0.3189]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6082],\n",
      "        [0.0905, 0.3187]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6082],\n",
      "        [0.0905, 0.3186]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6081],\n",
      "        [0.0905, 0.3185]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6081],\n",
      "        [0.0904, 0.3183]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6080],\n",
      "        [0.0904, 0.3182]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6080],\n",
      "        [0.0903, 0.3181]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6080],\n",
      "        [0.0903, 0.3179]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6079],\n",
      "        [0.0903, 0.3178]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6079],\n",
      "        [0.0902, 0.3176]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6078],\n",
      "        [0.0902, 0.3175]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6078],\n",
      "        [0.0902, 0.3174]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6078],\n",
      "        [0.0901, 0.3172]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6077],\n",
      "        [0.0901, 0.3171]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6077],\n",
      "        [0.0900, 0.3170]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6076],\n",
      "        [0.0900, 0.3168]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6076],\n",
      "        [0.0900, 0.3167]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6076],\n",
      "        [0.0899, 0.3165]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6075],\n",
      "        [0.0899, 0.3164]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6075],\n",
      "        [0.0898, 0.3163]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6074],\n",
      "        [0.0898, 0.3161]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6074],\n",
      "        [0.0898, 0.3160]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6074],\n",
      "        [0.0897, 0.3159]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6073],\n",
      "        [0.0897, 0.3157]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6073],\n",
      "        [0.0896, 0.3156]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6072],\n",
      "        [0.0896, 0.3155]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6072],\n",
      "        [0.0896, 0.3153]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6072],\n",
      "        [0.0895, 0.3152]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6071],\n",
      "        [0.0895, 0.3150]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6071],\n",
      "        [0.0895, 0.3149]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6070],\n",
      "        [0.0894, 0.3148]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6070],\n",
      "        [0.0894, 0.3146]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6070],\n",
      "        [0.0893, 0.3145]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6069],\n",
      "        [0.0893, 0.3144]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6069],\n",
      "        [0.0893, 0.3142]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6068],\n",
      "        [0.0892, 0.3141]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6068],\n",
      "        [0.0892, 0.3140]], grad_fn=<ClampBackward1>)\n",
      "Iteration 900: Loss = 77316592.0\n",
      "tensor([[0.3997, 0.6068],\n",
      "        [0.0892, 0.3138]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6067],\n",
      "        [0.0891, 0.3137]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6067],\n",
      "        [0.0891, 0.3136]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6067],\n",
      "        [0.0890, 0.3134]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6066],\n",
      "        [0.0890, 0.3133]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6066],\n",
      "        [0.0890, 0.3132]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6065],\n",
      "        [0.0889, 0.3130]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6065],\n",
      "        [0.0889, 0.3129]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6065],\n",
      "        [0.0889, 0.3128]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6064],\n",
      "        [0.0888, 0.3126]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6064],\n",
      "        [0.0888, 0.3125]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6064],\n",
      "        [0.0887, 0.3124]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6063],\n",
      "        [0.0887, 0.3122]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6063],\n",
      "        [0.0887, 0.3121]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6063],\n",
      "        [0.0886, 0.3120]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6062],\n",
      "        [0.0886, 0.3118]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6062],\n",
      "        [0.0886, 0.3117]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6061],\n",
      "        [0.0885, 0.3116]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6061],\n",
      "        [0.0885, 0.3114]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6061],\n",
      "        [0.0884, 0.3113]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6060],\n",
      "        [0.0884, 0.3112]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6060],\n",
      "        [0.0884, 0.3110]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6060],\n",
      "        [0.0883, 0.3109]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6059],\n",
      "        [0.0883, 0.3108]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6059],\n",
      "        [0.0883, 0.3106]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6059],\n",
      "        [0.0882, 0.3105]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6058],\n",
      "        [0.0882, 0.3104]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6058],\n",
      "        [0.0882, 0.3102]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6058],\n",
      "        [0.0881, 0.3101]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6057],\n",
      "        [0.0881, 0.3100]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6057],\n",
      "        [0.0880, 0.3098]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6057],\n",
      "        [0.0880, 0.3097]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6056],\n",
      "        [0.0880, 0.3096]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6056],\n",
      "        [0.0879, 0.3095]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6056],\n",
      "        [0.0879, 0.3093]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6055],\n",
      "        [0.0879, 0.3092]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6055],\n",
      "        [0.0878, 0.3091]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6055],\n",
      "        [0.0878, 0.3089]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6054],\n",
      "        [0.0878, 0.3088]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6054],\n",
      "        [0.0877, 0.3087]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6054],\n",
      "        [0.0877, 0.3085]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6053],\n",
      "        [0.0876, 0.3084]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6053],\n",
      "        [0.0876, 0.3083]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6053],\n",
      "        [0.0876, 0.3081]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6052],\n",
      "        [0.0875, 0.3080]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6052],\n",
      "        [0.0875, 0.3079]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6052],\n",
      "        [0.0875, 0.3078]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6051],\n",
      "        [0.0874, 0.3076]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6051],\n",
      "        [0.0874, 0.3075]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6051],\n",
      "        [0.0874, 0.3074]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6051],\n",
      "        [0.0873, 0.3072]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6050],\n",
      "        [0.0873, 0.3071]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6050],\n",
      "        [0.0873, 0.3070]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6050],\n",
      "        [0.0872, 0.3069]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6049],\n",
      "        [0.0872, 0.3067]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6049],\n",
      "        [0.0872, 0.3066]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6049],\n",
      "        [0.0871, 0.3065]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6048],\n",
      "        [0.0871, 0.3063]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6048],\n",
      "        [0.0870, 0.3062]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6048],\n",
      "        [0.0870, 0.3061]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6048],\n",
      "        [0.0870, 0.3060]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6047],\n",
      "        [0.0869, 0.3058]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6047],\n",
      "        [0.0869, 0.3057]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6047],\n",
      "        [0.0869, 0.3056]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6046],\n",
      "        [0.0868, 0.3055]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6046],\n",
      "        [0.0868, 0.3053]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6046],\n",
      "        [0.0868, 0.3052]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6045],\n",
      "        [0.0867, 0.3051]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6045],\n",
      "        [0.0867, 0.3049]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6045],\n",
      "        [0.0867, 0.3048]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6045],\n",
      "        [0.0866, 0.3047]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6044],\n",
      "        [0.0866, 0.3046]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6044],\n",
      "        [0.0866, 0.3044]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6044],\n",
      "        [0.0865, 0.3043]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6043],\n",
      "        [0.0865, 0.3042]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6043],\n",
      "        [0.0865, 0.3041]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6043],\n",
      "        [0.0864, 0.3039]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6043],\n",
      "        [0.0864, 0.3038]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6042],\n",
      "        [0.0864, 0.3037]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6042],\n",
      "        [0.0863, 0.3036]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6042],\n",
      "        [0.0863, 0.3034]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6042],\n",
      "        [0.0863, 0.3033]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6041],\n",
      "        [0.0862, 0.3032]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6041],\n",
      "        [0.0862, 0.3031]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6041],\n",
      "        [0.0862, 0.3029]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6040],\n",
      "        [0.0861, 0.3028]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6040],\n",
      "        [0.0861, 0.3027]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6040],\n",
      "        [0.0861, 0.3026]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6040],\n",
      "        [0.0860, 0.3024]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6039],\n",
      "        [0.0860, 0.3023]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6039],\n",
      "        [0.0860, 0.3022]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6039],\n",
      "        [0.0859, 0.3021]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6039],\n",
      "        [0.0859, 0.3019]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6038],\n",
      "        [0.0859, 0.3018]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6038],\n",
      "        [0.0858, 0.3017]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6038],\n",
      "        [0.0858, 0.3016]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6038],\n",
      "        [0.0858, 0.3014]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6037],\n",
      "        [0.0857, 0.3013]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6037],\n",
      "        [0.0857, 0.3012]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6037],\n",
      "        [0.0857, 0.3011]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1000: Loss = 73855960.0\n",
      "tensor([[0.3997, 0.6037],\n",
      "        [0.0856, 0.3009]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6036],\n",
      "        [0.0856, 0.3008]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6036],\n",
      "        [0.0856, 0.3007]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6036],\n",
      "        [0.0855, 0.3006]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6036],\n",
      "        [0.0855, 0.3005]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6035],\n",
      "        [0.0855, 0.3003]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6035],\n",
      "        [0.0854, 0.3002]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6035],\n",
      "        [0.0854, 0.3001]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6035],\n",
      "        [0.0854, 0.3000]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6034],\n",
      "        [0.0853, 0.2998]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6034],\n",
      "        [0.0853, 0.2997]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6034],\n",
      "        [0.0853, 0.2996]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6034],\n",
      "        [0.0852, 0.2995]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6033],\n",
      "        [0.0852, 0.2994]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6033],\n",
      "        [0.0852, 0.2992]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6033],\n",
      "        [0.0851, 0.2991]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6033],\n",
      "        [0.0851, 0.2990]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6032],\n",
      "        [0.0851, 0.2989]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6032],\n",
      "        [0.0850, 0.2987]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6032],\n",
      "        [0.0850, 0.2986]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6032],\n",
      "        [0.0850, 0.2985]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6031],\n",
      "        [0.0850, 0.2984]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6031],\n",
      "        [0.0849, 0.2983]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6031],\n",
      "        [0.0849, 0.2981]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6031],\n",
      "        [0.0849, 0.2980]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6031],\n",
      "        [0.0848, 0.2979]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6030],\n",
      "        [0.0848, 0.2978]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6030],\n",
      "        [0.0848, 0.2977]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6030],\n",
      "        [0.0847, 0.2975]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6030],\n",
      "        [0.0847, 0.2974]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6029],\n",
      "        [0.0847, 0.2973]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6029],\n",
      "        [0.0846, 0.2972]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6029],\n",
      "        [0.0846, 0.2971]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6029],\n",
      "        [0.0846, 0.2969]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6029],\n",
      "        [0.0845, 0.2968]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6028],\n",
      "        [0.0845, 0.2967]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6028],\n",
      "        [0.0845, 0.2966]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6028],\n",
      "        [0.0845, 0.2965]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6028],\n",
      "        [0.0844, 0.2963]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6027],\n",
      "        [0.0844, 0.2962]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6027],\n",
      "        [0.0844, 0.2961]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6027],\n",
      "        [0.0843, 0.2960]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6027],\n",
      "        [0.0843, 0.2959]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6027],\n",
      "        [0.0843, 0.2958]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6026],\n",
      "        [0.0842, 0.2956]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6026],\n",
      "        [0.0842, 0.2955]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6026],\n",
      "        [0.0842, 0.2954]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6026],\n",
      "        [0.0841, 0.2953]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6026],\n",
      "        [0.0841, 0.2952]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6025],\n",
      "        [0.0841, 0.2950]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6025],\n",
      "        [0.0841, 0.2949]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6025],\n",
      "        [0.0840, 0.2948]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6025],\n",
      "        [0.0840, 0.2947]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6025],\n",
      "        [0.0840, 0.2946]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6024],\n",
      "        [0.0839, 0.2945]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6024],\n",
      "        [0.0839, 0.2943]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6024],\n",
      "        [0.0839, 0.2942]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6024],\n",
      "        [0.0838, 0.2941]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6024],\n",
      "        [0.0838, 0.2940]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6023],\n",
      "        [0.0838, 0.2939]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6023],\n",
      "        [0.0838, 0.2938]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6023],\n",
      "        [0.0837, 0.2936]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6023],\n",
      "        [0.0837, 0.2935]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6023],\n",
      "        [0.0837, 0.2934]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6022],\n",
      "        [0.0836, 0.2933]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6022],\n",
      "        [0.0836, 0.2932]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6022],\n",
      "        [0.0836, 0.2931]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6022],\n",
      "        [0.0835, 0.2929]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6022],\n",
      "        [0.0835, 0.2928]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0835, 0.2927]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0835, 0.2926]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0834, 0.2925]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0834, 0.2924]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0834, 0.2922]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6021],\n",
      "        [0.0833, 0.2921]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6020],\n",
      "        [0.0833, 0.2920]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6020],\n",
      "        [0.0833, 0.2919]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6020],\n",
      "        [0.0832, 0.2918]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6020],\n",
      "        [0.0832, 0.2917]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6020],\n",
      "        [0.0832, 0.2916]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0832, 0.2914]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0831, 0.2913]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0831, 0.2912]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0831, 0.2911]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0830, 0.2910]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6019],\n",
      "        [0.0830, 0.2909]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0830, 0.2908]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0830, 0.2906]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0829, 0.2905]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0829, 0.2904]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0829, 0.2903]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6018],\n",
      "        [0.0828, 0.2902]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0828, 0.2901]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0828, 0.2900]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0828, 0.2899]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0827, 0.2897]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0827, 0.2896]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6017],\n",
      "        [0.0827, 0.2895]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0826, 0.2894]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0826, 0.2893]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1100: Loss = 71049760.0\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0826, 0.2892]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0826, 0.2891]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0825, 0.2890]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6016],\n",
      "        [0.0825, 0.2888]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0825, 0.2887]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0824, 0.2886]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0824, 0.2885]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0824, 0.2884]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0824, 0.2883]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0823, 0.2882]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6015],\n",
      "        [0.0823, 0.2881]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0823, 0.2879]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0823, 0.2878]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0822, 0.2877]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0822, 0.2876]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0822, 0.2875]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6014],\n",
      "        [0.0821, 0.2874]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0821, 0.2873]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0821, 0.2872]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0821, 0.2871]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0820, 0.2870]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0820, 0.2868]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0820, 0.2867]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6013],\n",
      "        [0.0819, 0.2866]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0819, 0.2865]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0819, 0.2864]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0819, 0.2863]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0818, 0.2862]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0818, 0.2861]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0818, 0.2860]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6012],\n",
      "        [0.0818, 0.2859]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0817, 0.2857]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0817, 0.2856]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0817, 0.2855]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0816, 0.2854]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0816, 0.2853]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0816, 0.2852]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6011],\n",
      "        [0.0816, 0.2851]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0815, 0.2850]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0815, 0.2849]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0815, 0.2848]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0815, 0.2847]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0814, 0.2845]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0814, 0.2844]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0814, 0.2843]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6010],\n",
      "        [0.0814, 0.2842]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0813, 0.2841]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0813, 0.2840]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0813, 0.2839]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0813, 0.2838]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0812, 0.2837]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0812, 0.2836]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0812, 0.2835]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6009],\n",
      "        [0.0811, 0.2834]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0811, 0.2833]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0811, 0.2832]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0811, 0.2830]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0810, 0.2829]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0810, 0.2828]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0810, 0.2827]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0810, 0.2826]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6008],\n",
      "        [0.0809, 0.2825]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0809, 0.2824]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0809, 0.2823]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0809, 0.2822]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0808, 0.2821]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0808, 0.2820]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0808, 0.2819]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0808, 0.2818]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0807, 0.2817]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6007],\n",
      "        [0.0807, 0.2816]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0807, 0.2815]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0807, 0.2814]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0806, 0.2812]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0806, 0.2811]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0806, 0.2810]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0806, 0.2809]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0805, 0.2808]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0805, 0.2807]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6006],\n",
      "        [0.0805, 0.2806]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0805, 0.2805]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0804, 0.2804]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0804, 0.2803]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0804, 0.2802]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0804, 0.2801]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0803, 0.2800]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0803, 0.2799]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0803, 0.2798]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6005],\n",
      "        [0.0803, 0.2797]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0802, 0.2796]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0802, 0.2795]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0802, 0.2794]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0802, 0.2793]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0801, 0.2792]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0801, 0.2791]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0801, 0.2790]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0801, 0.2789]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0800, 0.2788]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6004],\n",
      "        [0.0800, 0.2787]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0800, 0.2786]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1200: Loss = 68775904.0\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0800, 0.2785]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0799, 0.2784]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0799, 0.2782]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0799, 0.2781]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0799, 0.2780]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0798, 0.2779]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0798, 0.2778]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0798, 0.2777]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6003],\n",
      "        [0.0798, 0.2776]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0797, 0.2775]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0797, 0.2774]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0797, 0.2773]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0797, 0.2772]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0797, 0.2771]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0796, 0.2770]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0796, 0.2769]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0796, 0.2768]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0796, 0.2767]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0795, 0.2766]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6002],\n",
      "        [0.0795, 0.2765]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0795, 0.2764]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0795, 0.2763]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0794, 0.2762]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0794, 0.2761]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0794, 0.2760]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0794, 0.2759]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0793, 0.2758]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0793, 0.2757]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0793, 0.2756]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0793, 0.2755]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0793, 0.2754]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6001],\n",
      "        [0.0792, 0.2753]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0792, 0.2752]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0792, 0.2751]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0792, 0.2750]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0791, 0.2749]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0791, 0.2748]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0791, 0.2747]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0791, 0.2746]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0790, 0.2745]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0790, 0.2744]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0790, 0.2743]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0790, 0.2742]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.6000],\n",
      "        [0.0790, 0.2741]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0789, 0.2740]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0789, 0.2740]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0789, 0.2739]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0789, 0.2738]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0788, 0.2737]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0788, 0.2736]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0788, 0.2735]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0788, 0.2734]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0787, 0.2733]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0787, 0.2732]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0787, 0.2731]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0787, 0.2730]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0787, 0.2729]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5999],\n",
      "        [0.0786, 0.2728]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0786, 0.2727]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0786, 0.2726]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0786, 0.2725]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0785, 0.2724]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0785, 0.2723]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0785, 0.2722]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0785, 0.2721]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0785, 0.2720]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0784, 0.2719]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0784, 0.2718]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0784, 0.2717]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0784, 0.2716]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0784, 0.2715]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5998],\n",
      "        [0.0783, 0.2714]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0783, 0.2713]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0783, 0.2712]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0783, 0.2712]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0782, 0.2711]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0782, 0.2710]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0782, 0.2709]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0782, 0.2708]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0782, 0.2707]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0781, 0.2706]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0781, 0.2705]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0781, 0.2704]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0781, 0.2703]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0780, 0.2702]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0780, 0.2701]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0780, 0.2700]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5997],\n",
      "        [0.0780, 0.2699]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0780, 0.2698]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0779, 0.2697]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0779, 0.2696]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0779, 0.2695]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0779, 0.2695]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0779, 0.2694]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0778, 0.2693]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0778, 0.2692]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0778, 0.2691]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0778, 0.2690]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0778, 0.2689]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0777, 0.2688]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1300: Loss = 66940216.0\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0777, 0.2687]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0777, 0.2686]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0777, 0.2685]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0777, 0.2684]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5996],\n",
      "        [0.0776, 0.2683]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0776, 0.2682]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0776, 0.2682]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0776, 0.2681]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0775, 0.2680]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0775, 0.2679]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0775, 0.2678]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0775, 0.2677]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0775, 0.2676]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0774, 0.2675]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0774, 0.2674]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0774, 0.2673]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0774, 0.2672]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0774, 0.2671]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0773, 0.2671]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0773, 0.2670]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0773, 0.2669]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0773, 0.2668]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0773, 0.2667]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5995],\n",
      "        [0.0772, 0.2666]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0772, 0.2665]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0772, 0.2664]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0772, 0.2663]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0772, 0.2662]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0771, 0.2661]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0771, 0.2661]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0771, 0.2660]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0771, 0.2659]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0771, 0.2658]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0770, 0.2657]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0770, 0.2656]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0770, 0.2655]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0770, 0.2654]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0770, 0.2653]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0769, 0.2653]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0769, 0.2652]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0769, 0.2651]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0769, 0.2650]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0769, 0.2649]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0768, 0.2648]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5994],\n",
      "        [0.0768, 0.2647]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0768, 0.2646]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0768, 0.2645]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0768, 0.2644]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0768, 0.2644]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0767, 0.2643]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0767, 0.2642]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0767, 0.2641]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0767, 0.2640]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0767, 0.2639]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0766, 0.2638]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0766, 0.2637]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0766, 0.2637]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0766, 0.2636]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0766, 0.2635]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0765, 0.2634]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0765, 0.2633]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0765, 0.2632]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0765, 0.2631]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0765, 0.2630]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2630]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2629]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2628]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2627]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2626]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5993],\n",
      "        [0.0764, 0.2625]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0763, 0.2624]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0763, 0.2624]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0763, 0.2623]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0763, 0.2622]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0763, 0.2621]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2620]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2619]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2618]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2617]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2617]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0762, 0.2616]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0761, 0.2615]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0761, 0.2614]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0761, 0.2613]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0761, 0.2612]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0761, 0.2612]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2611]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2610]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2609]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2608]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2607]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0760, 0.2606]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0759, 0.2606]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0759, 0.2605]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0759, 0.2604]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0759, 0.2603]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0759, 0.2602]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0758, 0.2601]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5992],\n",
      "        [0.0758, 0.2601]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0758, 0.2600]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1400: Loss = 65466712.0\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0758, 0.2599]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0758, 0.2598]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0758, 0.2597]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0757, 0.2596]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0757, 0.2595]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0757, 0.2595]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0757, 0.2594]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0757, 0.2593]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2592]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2591]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2590]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2590]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2589]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0756, 0.2588]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2587]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2586]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2586]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2585]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2584]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0755, 0.2583]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2582]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2581]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2581]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2580]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2579]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0754, 0.2578]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2577]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2576]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2576]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2575]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2574]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0753, 0.2573]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0752, 0.2572]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5991],\n",
      "        [0.0752, 0.2572]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0752, 0.2571]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0752, 0.2570]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0752, 0.2569]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0752, 0.2568]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2568]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2567]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2566]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2565]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2564]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0751, 0.2564]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2563]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2562]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2561]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2560]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2560]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0750, 0.2559]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2558]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2557]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2556]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2556]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2555]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0749, 0.2554]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2553]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2552]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2552]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2551]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2550]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0748, 0.2549]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2548]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2548]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2547]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2546]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2545]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2545]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0747, 0.2544]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2543]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2542]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2541]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2541]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2540]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0746, 0.2539]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0745, 0.2538]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0745, 0.2538]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0745, 0.2537]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0745, 0.2536]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5990],\n",
      "        [0.0745, 0.2535]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0745, 0.2534]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2534]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2533]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2532]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2531]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2531]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2530]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0744, 0.2529]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2528]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2528]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2527]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2526]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2525]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0743, 0.2524]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2524]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2523]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2522]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2521]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2521]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2520]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1500: Loss = 64292568.0\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0742, 0.2519]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2518]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2518]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2517]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2516]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2515]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2515]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0741, 0.2514]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2513]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2512]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2512]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2511]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2510]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2509]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0740, 0.2509]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2508]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2507]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2506]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2506]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2505]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0739, 0.2504]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2503]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2503]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2502]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2501]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2500]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2500]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0738, 0.2499]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2498]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2498]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2497]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2496]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2495]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2495]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0737, 0.2494]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2493]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2492]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2492]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2491]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2490]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2490]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2489]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0736, 0.2488]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0735, 0.2487]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5989],\n",
      "        [0.0735, 0.2487]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0735, 0.2486]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0735, 0.2485]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0735, 0.2484]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0735, 0.2484]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0735, 0.2483]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2482]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2482]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2481]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2480]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2479]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2479]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0734, 0.2478]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2477]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2477]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2476]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2475]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2474]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2474]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2473]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0733, 0.2472]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2472]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2471]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2470]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2470]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2469]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2468]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0732, 0.2467]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2467]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2466]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2465]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2465]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2464]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2463]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2463]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0731, 0.2462]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2461]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2460]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2460]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2459]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2458]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2458]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0730, 0.2457]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2456]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2456]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2455]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2454]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2454]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2453]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2452]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0729, 0.2452]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2451]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2450]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2449]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2449]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2448]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1600: Loss = 63364600.0\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2447]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2447]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0728, 0.2446]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2445]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2445]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2444]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2443]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2443]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2442]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2441]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0727, 0.2441]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2440]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2439]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2439]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2438]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2437]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2437]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2436]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0726, 0.2435]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2435]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2434]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2433]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2433]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2432]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2431]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2431]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2430]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0725, 0.2429]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2429]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2428]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2427]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2427]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2426]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2425]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2425]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0724, 0.2424]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2423]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2423]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2422]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2422]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2421]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2420]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2420]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2419]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0723, 0.2418]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2418]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2417]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2416]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2416]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2415]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2414]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2414]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0722, 0.2413]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2412]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2412]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2411]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2411]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2410]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2409]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2409]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2408]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0721, 0.2407]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2407]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2406]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2405]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2405]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2404]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2404]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2403]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2402]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0720, 0.2402]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5988],\n",
      "        [0.0719, 0.2401]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2400]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2400]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2399]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2399]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2398]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2397]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2397]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0719, 0.2396]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2395]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2395]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2394]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2394]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2393]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2392]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2392]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2391]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0718, 0.2391]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2390]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2389]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2389]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2388]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2387]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2387]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2386]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2386]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2385]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0717, 0.2384]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2384]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1700: Loss = 62638032.0\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2383]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2383]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2382]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2381]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2381]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2380]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2380]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0716, 0.2379]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2378]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2378]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2377]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2377]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2376]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2375]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2375]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2374]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2374]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0715, 0.2373]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2372]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2372]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2371]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2371]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2370]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2369]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2369]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2368]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2368]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0714, 0.2367]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2366]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2366]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2365]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2365]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2364]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2363]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2363]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2362]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2362]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0713, 0.2361]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2361]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2360]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2359]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2359]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2358]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2358]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2357]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2357]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2356]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2355]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0712, 0.2355]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2354]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2354]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2353]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2353]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2352]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2351]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2351]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2350]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2350]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0711, 0.2349]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2349]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2348]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2347]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2347]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2346]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2346]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2345]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2345]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2344]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2343]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0710, 0.2343]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2342]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2342]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2341]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2341]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2340]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2340]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2339]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2338]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2338]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2337]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0709, 0.2337]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2336]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2336]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2335]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2335]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2334]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2333]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2333]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2332]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2332]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2331]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0708, 0.2331]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2330]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2330]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2329]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2328]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2328]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2327]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2327]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2326]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1800: Loss = 62074788.0\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2326]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2325]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2325]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0707, 0.2324]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2324]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2323]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2323]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2322]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2321]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2321]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2320]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2320]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2319]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2319]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0706, 0.2318]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2318]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2317]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2317]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2316]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2316]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2315]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2315]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2314]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2314]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2313]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2312]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0705, 0.2312]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2311]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2311]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2310]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2310]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2309]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2309]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2308]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2308]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2307]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2307]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2306]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2306]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0704, 0.2305]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2305]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2304]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2304]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2303]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2303]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2302]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2302]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2301]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2301]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2300]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2300]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2299]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0703, 0.2298]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2298]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2297]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2297]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2296]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2296]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2295]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2295]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2294]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2294]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2293]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2293]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2292]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0702, 0.2292]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2291]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2291]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2290]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2290]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2289]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2289]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2288]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2288]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2287]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2287]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2286]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2286]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0701, 0.2285]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2285]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2284]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2284]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2284]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2283]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2283]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2282]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2282]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2281]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2281]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2280]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2280]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2279]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0700, 0.2279]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2278]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2278]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2277]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2277]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2276]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2276]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2275]], grad_fn=<ClampBackward1>)\n",
      "Iteration 1900: Loss = 61643032.0\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2275]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2274]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2274]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2273]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2273]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2272]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0699, 0.2272]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2271]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2271]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2270]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2270]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2270]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2269]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2269]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2268]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2268]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2267]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2267]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2266]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2266]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0698, 0.2265]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2265]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2264]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2264]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2263]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2263]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2263]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2262]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2262]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2261]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2261]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2260]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2260]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2259]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2259]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0697, 0.2258]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2258]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2257]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2257]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2257]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2256]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2256]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2255]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2255]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2254]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2254]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2253]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2253]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2252]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2252]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2252]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0696, 0.2251]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2251]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2250]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2250]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2249]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2249]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2248]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2248]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2247]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2247]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2247]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2246]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2246]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2245]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2245]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2244]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0695, 0.2244]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2244]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2243]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2243]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2242]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2242]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2241]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2241]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2240]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2240]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2240]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2239]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2239]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2238]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2238]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2237]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2237]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0694, 0.2237]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2236]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2236]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2235]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2235]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2234]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2234]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2234]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2233]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2233]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2232]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2232]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2231]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2231]], grad_fn=<ClampBackward1>)\n",
      "tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2231]], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "pyro.clear_param_store()\n",
    "svi = pyro.infer.SVI(m_binom_model, m_binom_guide, pyro.optim.Adam({\"lr\": 0.001}), pyro.infer.TraceGraph_ELBO())\n",
    "num_iterations = 2000\n",
    "for i in range(num_iterations):\n",
    "    loss = svi.step(m_example, K=2)\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration {}: Loss = {}\".format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5e63c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_param tensor([0.6667, 0.3333], grad_fn=<DivBackward0>)\n",
      "probs_param tensor([[0.3997, 0.5987],\n",
      "        [0.0693, 0.2230]], grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "77cedd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of success binomial component:  [[0.39970666 0.598696  ]\n",
      " [0.06926379 0.22301088]]\n",
      "Mmixing proportions:  [0.6666667  0.33333334]\n"
     ]
    }
   ],
   "source": [
    "# Extract the learned parameters\n",
    "probs_bin = pyro.param(\"probs_param\").detach().numpy()\n",
    "weights = pyro.param(\"weights_param\").detach().numpy()\n",
    "\n",
    "print(\"Probabilities of success binomial component: \", probs_bin) # First row = component 1, second row = component 2\n",
    "print(\"Mmixing proportions: \", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7e790967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of data\n",
    "\n",
    "DP = 130\n",
    "NV_S1 = m_example[:,0]\n",
    "NV_S2 = m_example[:,1]\n",
    "plt.scatter(NV_S1/DP, NV_S2/DP, c = 'b', label = \"Original data\")\n",
    "\n",
    "# Plot samples from fitted densities\n",
    "x = np.linspace(0, 150, 1000)\n",
    "n = 130\n",
    "\n",
    "f1 = torch.ones([1000, 2])\n",
    "f1[:,0] = dist.Binomial(total_count=n, probs=probs_bin[0,0]).sample([1000]).squeeze(-1)\n",
    "f1[:,1] = dist.Binomial(total_count=n, probs=probs_bin[0,1]).sample([1000]).squeeze(-1)\n",
    "plt.scatter(f1[:,0]/DP, f1[:,1]/DP, c = 'r', label = \"Samples from fitted beta components\")\n",
    "\n",
    "f2 = torch.ones([1000, 2])\n",
    "f2[:,0] = dist.Binomial(total_count=n, probs=probs_bin[1,0]).sample([1000]).squeeze(-1)\n",
    "f2[:,1] = dist.Binomial(total_count=n, probs=probs_bin[1,1]).sample([1000]).squeeze(-1)\n",
    "plt.scatter(f2[:,0]/DP, f2[:,1]/DP, c = 'r')\n",
    "\n",
    "plt.title('2D binomial mixture model')\n",
    "plt.xlabel('VAF')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
